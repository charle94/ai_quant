[0m15:26:19.841838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97fc323770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97fd985a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97fb193d90>]}


============================== 15:26:19.844214 | 2f9e1454-b404-41fc-b1e0-45b93a99f7c8 ==============================
[0m15:26:19.844214 [info ] [MainThread]: Running with dbt=1.10.9
[0m15:26:19.844552 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'static_parser': 'True', 'use_experimental_parser': 'False', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'quiet': 'False', 'log_format': 'default', 'log_cache_events': 'False', 'profiles_dir': '/workspace/dbt_project', 'cache_selected_only': 'False', 'use_colors': 'True', 'target_path': 'None', 'introspect': 'True', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None', 'partial_parse': 'True', 'log_path': '/workspace/dbt_project/logs', 'invocation_command': 'dbt seed', 'indirect_selection': 'eager', 'empty': 'None', 'version_check': 'True', 'fail_fast': 'False', 'no_print': 'None'}
[0m15:26:19.978648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '2f9e1454-b404-41fc-b1e0-45b93a99f7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97fbeaa650>]}
[0m15:26:20.020083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '2f9e1454-b404-41fc-b1e0-45b93a99f7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97fb28ebe0>]}
[0m15:26:20.021116 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m15:26:20.049913 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m15:26:20.050328 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m15:26:20.050536 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '2f9e1454-b404-41fc-b1e0-45b93a99f7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97f7aa4e50>]}
[0m15:26:21.075943 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values`. Arguments to generic tests
should be nested under the `arguments` property.`
[0m15:26:21.076257 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '2f9e1454-b404-41fc-b1e0-45b93a99f7c8', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97f6e45220>]}
[0m15:26:21.279041 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2f9e1454-b404-41fc-b1e0-45b93a99f7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97f617dd30>]}
[0m15:26:21.344765 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:26:21.345874 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:26:21.356022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2f9e1454-b404-41fc-b1e0-45b93a99f7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97f62f8ae0>]}
[0m15:26:21.356352 [info ] [MainThread]: Found 15 models, 2 seeds, 37 data tests, 1 source, 565 macros
[0m15:26:21.356587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2f9e1454-b404-41fc-b1e0-45b93a99f7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97f6dd3710>]}
[0m15:26:21.358081 [info ] [MainThread]: 
[0m15:26:21.358347 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:26:21.358517 [info ] [MainThread]: 
[0m15:26:21.358797 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:26:21.362031 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m15:26:21.376764 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m15:26:21.377026 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m15:26:21.377203 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:26:21.393160 [debug] [ThreadPool]: SQL status: OK in 0.016 seconds
[0m15:26:21.394033 [debug] [ThreadPool]: On list_quant_features: Close
[0m15:26:21.394722 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m15:26:21.395039 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m15:26:21.399138 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:21.399391 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m15:26:21.399568 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:26:21.400251 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m15:26:21.401105 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:21.401310 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m15:26:21.401604 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:21.401769 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:21.401926 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m15:26:21.402211 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:21.402722 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:26:21.402913 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:21.403093 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:26:21.403425 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:21.403604 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m15:26:21.405348 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m15:26:21.409211 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:26:21.409448 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m15:26:21.409603 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:26:21.410052 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:21.410245 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:26:21.410402 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m15:26:21.416486 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m15:26:21.417267 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m15:26:21.417847 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m15:26:21.418070 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m15:26:21.418894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2f9e1454-b404-41fc-b1e0-45b93a99f7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97f6067c20>]}
[0m15:26:21.419398 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:21.419593 [debug] [MainThread]: On master: BEGIN
[0m15:26:21.419747 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:26:21.420175 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:21.420379 [debug] [MainThread]: On master: COMMIT
[0m15:26:21.420533 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:21.420677 [debug] [MainThread]: On master: COMMIT
[0m15:26:21.420938 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:21.421125 [debug] [MainThread]: On master: Close
[0m15:26:21.423527 [debug] [Thread-1 (]: Began running node seed.quant_features.market_data
[0m15:26:21.423932 [debug] [Thread-2 (]: Began running node seed.quant_features.raw_stock_prices
[0m15:26:21.424437 [info ] [Thread-1 (]: 1 of 2 START seed file main.market_data ........................................ [RUN]
[0m15:26:21.424950 [info ] [Thread-2 (]: 2 of 2 START seed file main.raw_stock_prices ................................... [RUN]
[0m15:26:21.425467 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now seed.quant_features.market_data)
[0m15:26:21.426034 [debug] [Thread-2 (]: Acquiring new duckdb connection 'seed.quant_features.raw_stock_prices'
[0m15:26:21.426564 [debug] [Thread-1 (]: Began compiling node seed.quant_features.market_data
[0m15:26:21.426921 [debug] [Thread-2 (]: Began compiling node seed.quant_features.raw_stock_prices
[0m15:26:21.427275 [debug] [Thread-1 (]: Began executing node seed.quant_features.market_data
[0m15:26:21.427579 [debug] [Thread-2 (]: Began executing node seed.quant_features.raw_stock_prices
[0m15:26:21.447246 [debug] [Thread-1 (]: Using duckdb connection "seed.quant_features.market_data"
[0m15:26:21.447517 [debug] [Thread-1 (]: On seed.quant_features.market_data: BEGIN
[0m15:26:21.447701 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:26:21.449650 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:21.450009 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m15:26:21.450385 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: BEGIN
[0m15:26:21.450734 [debug] [Thread-1 (]: Using duckdb connection "seed.quant_features.market_data"
[0m15:26:21.451037 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:26:21.451302 [debug] [Thread-1 (]: On seed.quant_features.market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "seed.quant_features.market_data"} */

    create table "quant_features"."main"."market_data" ("date" date,"symbol" text,"market_cap" integer,"pe_ratio" float8,"dividend_yield" float8,"sector" text)
  
[0m15:26:21.451917 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m15:26:21.452172 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:21.452421 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:26:21.452676 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "seed.quant_features.raw_stock_prices"} */

    create table "quant_features"."main"."raw_stock_prices" ("date" date,"symbol" text,"open" float8,"high" float8,"low" float8,"close" float8,"volume" integer)
  
[0m15:26:21.459497 [debug] [Thread-1 (]: Using duckdb connection "seed.quant_features.market_data"
[0m15:26:21.459940 [debug] [Thread-1 (]: On seed.quant_features.market_data: 
          COPY "quant_features"."main"."market_data" FROM '/workspace/dbt_project/seeds/market_data.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m15:26:21.460315 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m15:26:21.461158 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:21.461381 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: 
          COPY "quant_features"."main"."raw_stock_prices" FROM '/workspace/dbt_project/seeds/raw_stock_prices.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m15:26:21.464417 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m15:26:21.464849 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: 
          COPY "quant_features"."main"."market_data" FROM '/workspace/dbt_project/seeds/market_data.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        
[0m15:26:21.468535 [debug] [Thread-2 (]: Writing runtime SQL for node "seed.quant_features.raw_stock_prices"
[0m15:26:21.468882 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:26:21.469762 [debug] [Thread-1 (]: On seed.quant_features.market_data: ROLLBACK
[0m15:26:21.479561 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: COMMIT
[0m15:26:21.479845 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:21.480057 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: COMMIT
[0m15:26:21.482852 [debug] [Thread-1 (]: Failed to rollback 'seed.quant_features.market_data'
[0m15:26:21.483137 [debug] [Thread-1 (]: On seed.quant_features.market_data: Close
[0m15:26:21.485823 [debug] [Thread-1 (]: Runtime Error in seed market_data (seeds/market_data.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 2024-01-01,AAPL,3000000000000,28.5,0.44,Technology
  Error when converting column "market_cap". Could not convert string "3000000000000" to 'INTEGER'
  
  Column market_cap is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  * Check whether the null string value is set correctly (e.g., nullstr = 'N/A')
  
    file = /workspace/dbt_project/seeds/market_data.csv
    delimiter = , (Set By User)
    quote = (empty) (Auto-Detected)
    escape = (empty) (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = (empty) (Auto-Detected)
    strict_mode = true (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 2 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m15:26:21.486875 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2f9e1454-b404-41fc-b1e0-45b93a99f7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97fbe6cb90>]}
[0m15:26:21.487234 [debug] [Thread-2 (]: SQL status: OK in 0.007 seconds
[0m15:26:21.487697 [error] [Thread-1 (]: 1 of 2 ERROR loading seed file main.market_data ................................ [[31mERROR[0m in 0.06s]
[0m15:26:21.489035 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: Close
[0m15:26:21.489724 [debug] [Thread-1 (]: Finished running node seed.quant_features.market_data
[0m15:26:21.490259 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2f9e1454-b404-41fc-b1e0-45b93a99f7c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97f54e1550>]}
[0m15:26:21.490868 [debug] [Thread-7 (]: Marking all children of 'seed.quant_features.market_data' to be skipped because of status 'error'.  Reason: Runtime Error in seed market_data (seeds/market_data.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 2024-01-01,AAPL,3000000000000,28.5,0.44,Technology
  Error when converting column "market_cap". Could not convert string "3000000000000" to 'INTEGER'
  
  Column market_cap is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  * Check whether the null string value is set correctly (e.g., nullstr = 'N/A')
  
    file = /workspace/dbt_project/seeds/market_data.csv
    delimiter = , (Set By User)
    quote = (empty) (Auto-Detected)
    escape = (empty) (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = (empty) (Auto-Detected)
    strict_mode = true (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 2 Set type: INTEGER Sniffed type: BIGINT
  
  .
[0m15:26:21.491301 [info ] [Thread-2 (]: 2 of 2 OK loaded seed file main.raw_stock_prices ............................... [[32mINSERT 32[0m in 0.06s]
[0m15:26:21.492173 [debug] [Thread-2 (]: Finished running node seed.quant_features.raw_stock_prices
[0m15:26:21.493687 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:21.494762 [debug] [MainThread]: On master: BEGIN
[0m15:26:21.494952 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:26:21.495342 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:21.495533 [debug] [MainThread]: On master: COMMIT
[0m15:26:21.495696 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:21.495846 [debug] [MainThread]: On master: COMMIT
[0m15:26:21.496106 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:21.496270 [debug] [MainThread]: On master: Close
[0m15:26:21.496549 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:26:21.496717 [debug] [MainThread]: Connection 'seed.quant_features.market_data' was properly closed.
[0m15:26:21.496859 [debug] [MainThread]: Connection 'seed.quant_features.raw_stock_prices' was properly closed.
[0m15:26:21.497042 [info ] [MainThread]: 
[0m15:26:21.497219 [info ] [MainThread]: Finished running 2 seeds in 0 hours 0 minutes and 0.14 seconds (0.14s).
[0m15:26:21.497683 [debug] [MainThread]: Command end result
[0m15:26:21.519309 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:26:21.520404 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:26:21.523885 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m15:26:21.524122 [info ] [MainThread]: 
[0m15:26:21.524336 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:26:21.524536 [info ] [MainThread]: 
[0m15:26:21.524748 [error] [MainThread]: [31mFailure in seed market_data (seeds/market_data.csv)[0m
[0m15:26:21.524985 [error] [MainThread]:   Runtime Error in seed market_data (seeds/market_data.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 2024-01-01,AAPL,3000000000000,28.5,0.44,Technology
  Error when converting column "market_cap". Could not convert string "3000000000000" to 'INTEGER'
  
  Column market_cap is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  * Check whether the null string value is set correctly (e.g., nullstr = 'N/A')
  
    file = /workspace/dbt_project/seeds/market_data.csv
    delimiter = , (Set By User)
    quote = (empty) (Auto-Detected)
    escape = (empty) (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = (empty) (Auto-Detected)
    strict_mode = true (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 2 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m15:26:21.525193 [info ] [MainThread]: 
[0m15:26:21.525368 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[0m15:26:21.525653 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 12 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m15:26:21.526202 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 1.7209142, "process_in_blocks": "0", "process_kernel_time": 0.163583, "process_mem_max_rss": "163496", "process_out_blocks": "4920", "process_user_time": 2.429802}
[0m15:26:21.526485 [debug] [MainThread]: Command `dbt seed` failed at 15:26:21.526427 after 1.72 seconds
[0m15:26:21.526698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97fb1bdda0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97ff3a5400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f97f54cd250>]}
[0m15:26:21.526905 [debug] [MainThread]: Flushing usage events
[0m15:26:21.578850 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:26:34.299965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f8338f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f849e5a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f821cbd90>]}


============================== 15:26:34.302378 | 5807ed42-b7c8-43f4-9682-a91126bcf7fc ==============================
[0m15:26:34.302378 [info ] [MainThread]: Running with dbt=1.10.9
[0m15:26:34.302711 [debug] [MainThread]: running dbt with arguments {'no_print': 'None', 'version_check': 'True', 'fail_fast': 'False', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'target_path': 'None', 'profiles_dir': '/workspace/dbt_project', 'cache_selected_only': 'False', 'debug': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'use_colors': 'True', 'quiet': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'log_path': '/workspace/dbt_project/logs', 'introspect': 'True', 'empty': 'None', 'log_format': 'default', 'printer_width': '80', 'write_json': 'True', 'warn_error': 'None', 'invocation_command': 'dbt seed --full-refresh'}
[0m15:26:34.437089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '5807ed42-b7c8-43f4-9682-a91126bcf7fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f82f16650>]}
[0m15:26:34.478235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '5807ed42-b7c8-43f4-9682-a91126bcf7fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f822cabe0>]}
[0m15:26:34.479248 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m15:26:34.508354 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m15:26:34.595504 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m15:26:34.595967 [debug] [MainThread]: Partial parsing: added file: quant_features://seeds/schema.yml
[0m15:26:34.693065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5807ed42-b7c8-43f4-9682-a91126bcf7fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7defe350>]}
[0m15:26:34.788652 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:26:34.789801 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:26:34.799721 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5807ed42-b7c8-43f4-9682-a91126bcf7fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7de654f0>]}
[0m15:26:34.800056 [info ] [MainThread]: Found 15 models, 2 seeds, 37 data tests, 1 source, 565 macros
[0m15:26:34.800266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5807ed42-b7c8-43f4-9682-a91126bcf7fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f821ad2b0>]}
[0m15:26:34.801738 [info ] [MainThread]: 
[0m15:26:34.802042 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:26:34.802234 [info ] [MainThread]: 
[0m15:26:34.802544 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:26:34.805709 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m15:26:34.820392 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m15:26:34.820649 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m15:26:34.820825 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:26:34.830716 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m15:26:34.831607 [debug] [ThreadPool]: On list_quant_features: Close
[0m15:26:34.832166 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m15:26:34.832481 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m15:26:34.836591 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:34.836847 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m15:26:34.837027 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:26:34.837677 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m15:26:34.838519 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:34.838735 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m15:26:34.839056 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:34.839230 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:34.839386 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m15:26:34.839678 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:34.840207 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:26:34.840421 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:34.840581 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:26:34.840864 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:34.841064 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m15:26:34.842916 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m15:26:34.846840 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:26:34.847096 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m15:26:34.847259 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:26:34.847684 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:34.847888 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:26:34.848055 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m15:26:34.854194 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m15:26:34.855054 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m15:26:34.855654 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m15:26:34.855866 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m15:26:34.857044 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5807ed42-b7c8-43f4-9682-a91126bcf7fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7d158bb0>]}
[0m15:26:34.857439 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:34.857634 [debug] [MainThread]: On master: BEGIN
[0m15:26:34.857792 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:26:34.858210 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:34.858402 [debug] [MainThread]: On master: COMMIT
[0m15:26:34.858555 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:34.858702 [debug] [MainThread]: On master: COMMIT
[0m15:26:34.859132 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:34.859326 [debug] [MainThread]: On master: Close
[0m15:26:34.861375 [debug] [Thread-2 (]: Began running node seed.quant_features.raw_stock_prices
[0m15:26:34.861767 [debug] [Thread-1 (]: Began running node seed.quant_features.market_data
[0m15:26:34.862275 [info ] [Thread-2 (]: 2 of 2 START seed file main.raw_stock_prices ................................... [RUN]
[0m15:26:34.862787 [info ] [Thread-1 (]: 1 of 2 START seed file main.market_data ........................................ [RUN]
[0m15:26:34.863224 [debug] [Thread-2 (]: Acquiring new duckdb connection 'seed.quant_features.raw_stock_prices'
[0m15:26:34.863583 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now seed.quant_features.market_data)
[0m15:26:34.863867 [debug] [Thread-2 (]: Began compiling node seed.quant_features.raw_stock_prices
[0m15:26:34.864141 [debug] [Thread-1 (]: Began compiling node seed.quant_features.market_data
[0m15:26:34.864429 [debug] [Thread-2 (]: Began executing node seed.quant_features.raw_stock_prices
[0m15:26:34.864725 [debug] [Thread-1 (]: Began executing node seed.quant_features.market_data
[0m15:26:34.884816 [debug] [Thread-1 (]: Using duckdb connection "seed.quant_features.market_data"
[0m15:26:34.885102 [debug] [Thread-1 (]: On seed.quant_features.market_data: BEGIN
[0m15:26:34.885297 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:26:34.885797 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:26:34.886046 [debug] [Thread-1 (]: Using duckdb connection "seed.quant_features.market_data"
[0m15:26:34.886238 [debug] [Thread-1 (]: On seed.quant_features.market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "seed.quant_features.market_data"} */

    create table "quant_features"."main"."market_data" ("date" date,"symbol" text,"market_cap" integer,"pe_ratio" float8,"dividend_yield" float8,"sector" text)
  
[0m15:26:34.893615 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:34.893915 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "seed.quant_features.raw_stock_prices"} */

      drop table if exists "quant_features"."main"."raw_stock_prices" cascade
    
[0m15:26:34.894121 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:26:34.894585 [debug] [Thread-1 (]: SQL status: OK in 0.008 seconds
[0m15:26:34.901658 [debug] [Thread-1 (]: Using duckdb connection "seed.quant_features.market_data"
[0m15:26:34.902000 [debug] [Thread-2 (]: SQL status: OK in 0.008 seconds
[0m15:26:34.902436 [debug] [Thread-1 (]: On seed.quant_features.market_data: 
          COPY "quant_features"."main"."market_data" FROM '/workspace/dbt_project/seeds/market_data.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m15:26:34.903634 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:34.904045 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: BEGIN
[0m15:26:34.904459 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m15:26:34.904672 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:34.904854 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "seed.quant_features.raw_stock_prices"} */

    create table "quant_features"."main"."raw_stock_prices" ("date" date,"symbol" text,"open" float8,"high" float8,"low" float8,"close" float8,"volume" integer)
  
[0m15:26:34.905337 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m15:26:34.906069 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:34.906296 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: 
          COPY "quant_features"."main"."raw_stock_prices" FROM '/workspace/dbt_project/seeds/raw_stock_prices.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m15:26:34.907924 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: 
          COPY "quant_features"."main"."market_data" FROM '/workspace/dbt_project/seeds/market_data.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        
[0m15:26:34.908194 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m15:26:34.908470 [debug] [Thread-1 (]: On seed.quant_features.market_data: ROLLBACK
[0m15:26:34.909585 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m15:26:34.913142 [debug] [Thread-2 (]: Writing runtime SQL for node "seed.quant_features.raw_stock_prices"
[0m15:26:34.923403 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: COMMIT
[0m15:26:34.923679 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:34.923888 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: COMMIT
[0m15:26:34.926895 [debug] [Thread-1 (]: Failed to rollback 'seed.quant_features.market_data'
[0m15:26:34.927201 [debug] [Thread-1 (]: On seed.quant_features.market_data: Close
[0m15:26:34.927537 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m15:26:34.928996 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: Close
[0m15:26:34.930896 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5807ed42-b7c8-43f4-9682-a91126bcf7fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7d2456d0>]}
[0m15:26:34.933030 [debug] [Thread-1 (]: Runtime Error in seed market_data (seeds/market_data.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 2024-01-01,AAPL,3000000000000,28.5,0.44,Technology
  Error when converting column "market_cap". Could not convert string "3000000000000" to 'INTEGER'
  
  Column market_cap is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  * Check whether the null string value is set correctly (e.g., nullstr = 'N/A')
  
    file = /workspace/dbt_project/seeds/market_data.csv
    delimiter = , (Set By User)
    quote = (empty) (Auto-Detected)
    escape = (empty) (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = (empty) (Auto-Detected)
    strict_mode = true (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 2 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m15:26:34.933618 [info ] [Thread-2 (]: 2 of 2 OK loaded seed file main.raw_stock_prices ............................... [[32mCREATE 32[0m in 0.07s]
[0m15:26:34.934143 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5807ed42-b7c8-43f4-9682-a91126bcf7fc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7dc826d0>]}
[0m15:26:34.934693 [debug] [Thread-2 (]: Finished running node seed.quant_features.raw_stock_prices
[0m15:26:34.935166 [error] [Thread-1 (]: 1 of 2 ERROR loading seed file main.market_data ................................ [[31mERROR[0m in 0.07s]
[0m15:26:34.935870 [debug] [Thread-1 (]: Finished running node seed.quant_features.market_data
[0m15:26:34.936325 [debug] [Thread-7 (]: Marking all children of 'seed.quant_features.market_data' to be skipped because of status 'error'.  Reason: Runtime Error in seed market_data (seeds/market_data.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 2024-01-01,AAPL,3000000000000,28.5,0.44,Technology
  Error when converting column "market_cap". Could not convert string "3000000000000" to 'INTEGER'
  
  Column market_cap is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  * Check whether the null string value is set correctly (e.g., nullstr = 'N/A')
  
    file = /workspace/dbt_project/seeds/market_data.csv
    delimiter = , (Set By User)
    quote = (empty) (Auto-Detected)
    escape = (empty) (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = (empty) (Auto-Detected)
    strict_mode = true (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 2 Set type: INTEGER Sniffed type: BIGINT
  
  .
[0m15:26:34.938611 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:34.938860 [debug] [MainThread]: On master: BEGIN
[0m15:26:34.939043 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:26:34.939396 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:34.939573 [debug] [MainThread]: On master: COMMIT
[0m15:26:34.939728 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:34.939872 [debug] [MainThread]: On master: COMMIT
[0m15:26:34.940188 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:34.940387 [debug] [MainThread]: On master: Close
[0m15:26:34.940661 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:26:34.940823 [debug] [MainThread]: Connection 'seed.quant_features.market_data' was properly closed.
[0m15:26:34.940971 [debug] [MainThread]: Connection 'seed.quant_features.raw_stock_prices' was properly closed.
[0m15:26:34.941140 [info ] [MainThread]: 
[0m15:26:34.941310 [info ] [MainThread]: Finished running 2 seeds in 0 hours 0 minutes and 0.14 seconds (0.14s).
[0m15:26:34.941776 [debug] [MainThread]: Command end result
[0m15:26:34.963683 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:26:34.964831 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:26:34.968372 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m15:26:34.968600 [info ] [MainThread]: 
[0m15:26:34.968811 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:26:34.968994 [info ] [MainThread]: 
[0m15:26:34.969204 [error] [MainThread]: [31mFailure in seed market_data (seeds/market_data.csv)[0m
[0m15:26:34.969418 [error] [MainThread]:   Runtime Error in seed market_data (seeds/market_data.csv)
  Conversion Error: CSV Error on Line: 2
  Original Line: 2024-01-01,AAPL,3000000000000,28.5,0.44,Technology
  Error when converting column "market_cap". Could not convert string "3000000000000" to 'INTEGER'
  
  Column market_cap is being converted as type INTEGER
  This type was either manually set or derived from an existing table. Select a different type to correctly parse this column.
  * Check whether the null string value is set correctly (e.g., nullstr = 'N/A')
  
    file = /workspace/dbt_project/seeds/market_data.csv
    delimiter = , (Set By User)
    quote = (empty) (Auto-Detected)
    escape = (empty) (Auto-Detected)
    new_line = \n (Auto-Detected)
    header = true (Set By User)
    skip_rows = 0 (Auto-Detected)
    comment = (empty) (Auto-Detected)
    strict_mode = true (Auto-Detected)
    date_format =  (Auto-Detected)
    timestamp_format =  (Auto-Detected)
    null_padding = 0
    sample_size = 20480
    ignore_errors = false
    all_varchar = 0
  The Column types set by the user do not match the ones found by the sniffer. 
  Column at position: 2 Set type: INTEGER Sniffed type: BIGINT
  
  
[0m15:26:34.969605 [info ] [MainThread]: 
[0m15:26:34.969771 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=2
[0m15:26:34.970294 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": false, "command_wall_clock_time": 0.70694566, "process_in_blocks": "0", "process_kernel_time": 0.163698, "process_mem_max_rss": "155708", "process_out_blocks": "4920", "process_user_time": 1.441296}
[0m15:26:34.970569 [debug] [MainThread]: Command `dbt seed` failed at 15:26:34.970513 after 0.71 seconds
[0m15:26:34.970771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7d2e7a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7ddcc9e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8f7eb368d0>]}
[0m15:26:34.970979 [debug] [MainThread]: Flushing usage events
[0m15:26:34.998342 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:26:48.899990 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd9667770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facdacbda90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd849fd90>]}


============================== 15:26:48.902308 | eb21f7a4-8bd1-4ba5-9b26-576fcbe93fb2 ==============================
[0m15:26:48.902308 [info ] [MainThread]: Running with dbt=1.10.9
[0m15:26:48.902635 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/workspace/dbt_project', 'target_path': 'None', 'log_path': '/workspace/dbt_project/logs', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_cache_events': 'False', 'introspect': 'True', 'debug': 'False', 'use_experimental_parser': 'False', 'invocation_command': 'dbt seed --full-refresh', 'use_colors': 'True', 'empty': 'None', 'write_json': 'True', 'fail_fast': 'False', 'version_check': 'True', 'log_format': 'default', 'partial_parse': 'True', 'printer_width': '80', 'no_print': 'None', 'indirect_selection': 'eager'}
[0m15:26:49.042437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'eb21f7a4-8bd1-4ba5-9b26-576fcbe93fb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd91ee650>]}
[0m15:26:49.083719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'eb21f7a4-8bd1-4ba5-9b26-576fcbe93fb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd859ebe0>]}
[0m15:26:49.084724 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m15:26:49.113876 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m15:26:49.192220 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m15:26:49.192527 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'eb21f7a4-8bd1-4ba5-9b26-576fcbe93fb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd856f550>]}
[0m15:26:50.181177 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values`. Arguments to generic tests
should be nested under the `arguments` property.`
[0m15:26:50.181490 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'eb21f7a4-8bd1-4ba5-9b26-576fcbe93fb2', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd373f980>]}
[0m15:26:50.390067 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eb21f7a4-8bd1-4ba5-9b26-576fcbe93fb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd34fd8d0>]}
[0m15:26:50.453451 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:26:50.454641 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:26:50.465155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eb21f7a4-8bd1-4ba5-9b26-576fcbe93fb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd33d7520>]}
[0m15:26:50.465490 [info ] [MainThread]: Found 15 models, 2 seeds, 37 data tests, 1 source, 565 macros
[0m15:26:50.465696 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eb21f7a4-8bd1-4ba5-9b26-576fcbe93fb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd42ecb90>]}
[0m15:26:50.467245 [info ] [MainThread]: 
[0m15:26:50.467523 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:26:50.467695 [info ] [MainThread]: 
[0m15:26:50.467998 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:26:50.471441 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m15:26:50.485948 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m15:26:50.486203 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m15:26:50.486385 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:26:50.496227 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m15:26:50.497162 [debug] [ThreadPool]: On list_quant_features: Close
[0m15:26:50.497881 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m15:26:50.498174 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m15:26:50.502318 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:50.502575 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m15:26:50.502745 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:26:50.503411 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m15:26:50.504262 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:50.504487 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m15:26:50.504788 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:50.504968 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:50.505121 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m15:26:50.505497 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:50.506055 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:26:50.506244 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:50.506402 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:26:50.506697 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:50.506899 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m15:26:50.508677 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m15:26:50.512443 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:26:50.512691 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m15:26:50.512869 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:26:50.513267 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:50.513454 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:26:50.513612 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m15:26:50.519737 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m15:26:50.520610 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m15:26:50.521230 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m15:26:50.521440 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m15:26:50.522430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eb21f7a4-8bd1-4ba5-9b26-576fcbe93fb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd33936a0>]}
[0m15:26:50.522789 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:50.522988 [debug] [MainThread]: On master: BEGIN
[0m15:26:50.523139 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:26:50.523520 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:50.523705 [debug] [MainThread]: On master: COMMIT
[0m15:26:50.523872 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:50.524017 [debug] [MainThread]: On master: COMMIT
[0m15:26:50.524276 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:50.524486 [debug] [MainThread]: On master: Close
[0m15:26:50.527101 [debug] [Thread-1 (]: Began running node seed.quant_features.market_data
[0m15:26:50.527518 [debug] [Thread-2 (]: Began running node seed.quant_features.raw_stock_prices
[0m15:26:50.528052 [info ] [Thread-1 (]: 1 of 2 START seed file main.market_data ........................................ [RUN]
[0m15:26:50.528529 [info ] [Thread-2 (]: 2 of 2 START seed file main.raw_stock_prices ................................... [RUN]
[0m15:26:50.529111 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now seed.quant_features.market_data)
[0m15:26:50.529620 [debug] [Thread-2 (]: Acquiring new duckdb connection 'seed.quant_features.raw_stock_prices'
[0m15:26:50.529974 [debug] [Thread-1 (]: Began compiling node seed.quant_features.market_data
[0m15:26:50.530283 [debug] [Thread-2 (]: Began compiling node seed.quant_features.raw_stock_prices
[0m15:26:50.530585 [debug] [Thread-1 (]: Began executing node seed.quant_features.market_data
[0m15:26:50.530870 [debug] [Thread-2 (]: Began executing node seed.quant_features.raw_stock_prices
[0m15:26:50.563685 [debug] [Thread-1 (]: Using duckdb connection "seed.quant_features.market_data"
[0m15:26:50.566174 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:50.566654 [debug] [Thread-1 (]: On seed.quant_features.market_data: BEGIN
[0m15:26:50.567026 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "seed.quant_features.raw_stock_prices"} */

      drop table if exists "quant_features"."main"."raw_stock_prices" cascade
    
[0m15:26:50.567699 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:26:50.567382 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:26:50.568613 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:26:50.569074 [debug] [Thread-1 (]: Using duckdb connection "seed.quant_features.market_data"
[0m15:26:50.569420 [debug] [Thread-1 (]: On seed.quant_features.market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "seed.quant_features.market_data"} */

    create table "quant_features"."main"."market_data" ("date" date,"symbol" text,"market_cap" BIGINT,"pe_ratio" DECIMAL(10,2),"dividend_yield" DECIMAL(5,2),"sector" text)
  
[0m15:26:50.570004 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m15:26:50.570992 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:50.571235 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: BEGIN
[0m15:26:50.571617 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m15:26:50.571822 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:50.572017 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "seed.quant_features.raw_stock_prices"} */

    create table "quant_features"."main"."raw_stock_prices" ("date" date,"symbol" text,"open" DECIMAL(10,2),"high" DECIMAL(10,2),"low" DECIMAL(10,2),"close" DECIMAL(10,2),"volume" BIGINT)
  
[0m15:26:50.572519 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:26:50.579426 [debug] [Thread-1 (]: Using duckdb connection "seed.quant_features.market_data"
[0m15:26:50.579720 [debug] [Thread-1 (]: On seed.quant_features.market_data: 
          COPY "quant_features"."main"."market_data" FROM '/workspace/dbt_project/seeds/market_data.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m15:26:50.580176 [debug] [Thread-2 (]: SQL status: OK in 0.008 seconds
[0m15:26:50.581003 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:50.581240 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: 
          COPY "quant_features"."main"."raw_stock_prices" FROM '/workspace/dbt_project/seeds/raw_stock_prices.csv' (FORMAT CSV, HEADER TRUE, DELIMITER ',')
        ...
[0m15:26:50.584001 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m15:26:50.587542 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.quant_features.market_data"
[0m15:26:50.588037 [debug] [Thread-2 (]: SQL status: OK in 0.007 seconds
[0m15:26:50.593712 [debug] [Thread-2 (]: Writing runtime SQL for node "seed.quant_features.raw_stock_prices"
[0m15:26:50.597242 [debug] [Thread-1 (]: On seed.quant_features.market_data: COMMIT
[0m15:26:50.597764 [debug] [Thread-1 (]: Using duckdb connection "seed.quant_features.market_data"
[0m15:26:50.598026 [debug] [Thread-1 (]: On seed.quant_features.market_data: COMMIT
[0m15:26:50.600516 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: COMMIT
[0m15:26:50.600800 [debug] [Thread-2 (]: Using duckdb connection "seed.quant_features.raw_stock_prices"
[0m15:26:50.601006 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: COMMIT
[0m15:26:50.601341 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:26:50.602754 [debug] [Thread-1 (]: On seed.quant_features.market_data: Close
[0m15:26:50.603241 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m15:26:50.603800 [debug] [Thread-2 (]: On seed.quant_features.raw_stock_prices: Close
[0m15:26:50.605049 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb21f7a4-8bd1-4ba5-9b26-576fcbe93fb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd91b0b90>]}
[0m15:26:50.605427 [info ] [Thread-1 (]: 1 of 2 OK loaded seed file main.market_data .................................... [[32mCREATE 32[0m in 0.08s]
[0m15:26:50.605890 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eb21f7a4-8bd1-4ba5-9b26-576fcbe93fb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd28c0850>]}
[0m15:26:50.606320 [debug] [Thread-1 (]: Finished running node seed.quant_features.market_data
[0m15:26:50.606716 [info ] [Thread-2 (]: 2 of 2 OK loaded seed file main.raw_stock_prices ............................... [[32mCREATE 32[0m in 0.08s]
[0m15:26:50.607575 [debug] [Thread-2 (]: Finished running node seed.quant_features.raw_stock_prices
[0m15:26:50.608973 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:50.609230 [debug] [MainThread]: On master: BEGIN
[0m15:26:50.609399 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:26:50.609801 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:50.610009 [debug] [MainThread]: On master: COMMIT
[0m15:26:50.610168 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:50.610315 [debug] [MainThread]: On master: COMMIT
[0m15:26:50.610568 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:50.610740 [debug] [MainThread]: On master: Close
[0m15:26:50.611016 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:26:50.611173 [debug] [MainThread]: Connection 'seed.quant_features.market_data' was properly closed.
[0m15:26:50.611302 [debug] [MainThread]: Connection 'seed.quant_features.raw_stock_prices' was properly closed.
[0m15:26:50.611468 [info ] [MainThread]: 
[0m15:26:50.611654 [info ] [MainThread]: Finished running 2 seeds in 0 hours 0 minutes and 0.14 seconds (0.14s).
[0m15:26:50.612102 [debug] [MainThread]: Command end result
[0m15:26:50.632560 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:26:50.633698 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:26:50.637276 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m15:26:50.637513 [info ] [MainThread]: 
[0m15:26:50.637732 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:26:50.637910 [info ] [MainThread]: 
[0m15:26:50.638086 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=2
[0m15:26:50.638372 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 12 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m15:26:50.638961 [debug] [MainThread]: Resource report: {"command_name": "seed", "command_success": true, "command_wall_clock_time": 1.7758723, "process_in_blocks": "0", "process_kernel_time": 0.151495, "process_mem_max_rss": "163276", "process_out_blocks": "4896", "process_user_time": 2.503625}
[0m15:26:50.639278 [debug] [MainThread]: Command `dbt seed` succeeded at 15:26:50.639211 after 1.78 seconds
[0m15:26:50.639477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd84cdda0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facdc6e5400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7facd348a330>]}
[0m15:26:50.639688 [debug] [MainThread]: Flushing usage events
[0m15:26:50.686796 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:26:56.448294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05b31f3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05b482da90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05b206fd90>]}


============================== 15:26:56.450578 | b9de5e66-0c9a-407b-8ac2-3599d5e61949 ==============================
[0m15:26:56.450578 [info ] [MainThread]: Running with dbt=1.10.9
[0m15:26:56.451338 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'invocation_command': 'dbt run', 'debug': 'False', 'indirect_selection': 'eager', 'profiles_dir': '/workspace/dbt_project', 'empty': 'False', 'printer_width': '80', 'target_path': 'None', 'quiet': 'False', 'fail_fast': 'False', 'use_experimental_parser': 'False', 'log_path': '/workspace/dbt_project/logs', 'log_format': 'default', 'cache_selected_only': 'False', 'write_json': 'True', 'version_check': 'True', 'introspect': 'True', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'use_colors': 'True'}
[0m15:26:56.594082 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'b9de5e66-0c9a-407b-8ac2-3599d5e61949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05b2d86650>]}
[0m15:26:56.635228 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'b9de5e66-0c9a-407b-8ac2-3599d5e61949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05b216abe0>]}
[0m15:26:56.636306 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m15:26:56.665055 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m15:26:56.751531 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:26:56.751775 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:26:56.788097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b9de5e66-0c9a-407b-8ac2-3599d5e61949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05ae139450>]}
[0m15:26:56.857650 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:26:56.858834 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:26:56.869282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b9de5e66-0c9a-407b-8ac2-3599d5e61949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05ae16d220>]}
[0m15:26:56.869630 [info ] [MainThread]: Found 15 models, 2 seeds, 37 data tests, 1 source, 565 macros
[0m15:26:56.869856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9de5e66-0c9a-407b-8ac2-3599d5e61949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05ae1ac130>]}
[0m15:26:56.871454 [info ] [MainThread]: 
[0m15:26:56.871714 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:26:56.871904 [info ] [MainThread]: 
[0m15:26:56.872186 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:26:56.875782 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m15:26:56.893799 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m15:26:56.894069 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m15:26:56.894251 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:26:56.905772 [debug] [ThreadPool]: SQL status: OK in 0.011 seconds
[0m15:26:56.906684 [debug] [ThreadPool]: On list_quant_features: Close
[0m15:26:56.907398 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m15:26:56.907708 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m15:26:56.912007 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:56.912265 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m15:26:56.912466 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:26:56.913153 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m15:26:56.913996 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:56.914210 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m15:26:56.914572 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:56.914752 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:56.914921 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m15:26:56.915251 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:56.915772 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:26:56.915989 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:26:56.916153 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:26:56.916467 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:56.916651 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m15:26:56.918736 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m15:26:56.953161 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:26:56.953411 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m15:26:56.953581 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:26:56.954003 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:26:56.954211 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:26:56.954378 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m15:26:56.960875 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m15:26:56.961726 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m15:26:56.962325 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m15:26:56.962528 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m15:26:56.963759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b9de5e66-0c9a-407b-8ac2-3599d5e61949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05b212b520>]}
[0m15:26:56.964220 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:56.964428 [debug] [MainThread]: On master: BEGIN
[0m15:26:56.964582 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:26:56.964979 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:56.965169 [debug] [MainThread]: On master: COMMIT
[0m15:26:56.965315 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:56.965452 [debug] [MainThread]: On master: COMMIT
[0m15:26:56.965708 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:56.965900 [debug] [MainThread]: On master: Close
[0m15:26:56.968114 [debug] [Thread-1 (]: Began running node model.quant_features.stg_market_data
[0m15:26:56.968488 [debug] [Thread-2 (]: Began running node model.quant_features.stg_ohlc_data
[0m15:26:56.968960 [debug] [Thread-3 (]: Began running node model.quant_features.stg_stock_prices
[0m15:26:56.969504 [info ] [Thread-1 (]: 1 of 15 START sql view model main.stg_market_data .............................. [RUN]
[0m15:26:56.970031 [info ] [Thread-2 (]: 2 of 15 START sql view model main.stg_ohlc_data ................................ [RUN]
[0m15:26:56.970559 [info ] [Thread-3 (]: 3 of 15 START sql view model main.stg_stock_prices ............................. [RUN]
[0m15:26:56.971119 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.stg_market_data)
[0m15:26:56.971718 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.quant_features.stg_ohlc_data'
[0m15:26:56.972189 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.quant_features.stg_stock_prices'
[0m15:26:56.972485 [debug] [Thread-1 (]: Began compiling node model.quant_features.stg_market_data
[0m15:26:56.972766 [debug] [Thread-2 (]: Began compiling node model.quant_features.stg_ohlc_data
[0m15:26:56.973255 [debug] [Thread-3 (]: Began compiling node model.quant_features.stg_stock_prices
[0m15:26:56.978076 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.stg_market_data"
[0m15:26:56.980913 [debug] [Thread-2 (]: Writing injected SQL for node "model.quant_features.stg_ohlc_data"
[0m15:26:56.983137 [debug] [Thread-3 (]: Writing injected SQL for node "model.quant_features.stg_stock_prices"
[0m15:26:56.984175 [debug] [Thread-2 (]: Began executing node model.quant_features.stg_ohlc_data
[0m15:26:56.996465 [debug] [Thread-1 (]: Began executing node model.quant_features.stg_market_data
[0m15:26:57.010009 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.stg_market_data"
[0m15:26:57.011624 [debug] [Thread-2 (]: Writing runtime sql for node "model.quant_features.stg_ohlc_data"
[0m15:26:57.012118 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:26:57.012407 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: BEGIN
[0m15:26:57.012621 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:26:57.013239 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m15:26:57.013517 [debug] [Thread-2 (]: On model.quant_features.stg_ohlc_data: BEGIN
[0m15:26:57.013704 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:26:57.014131 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m15:26:57.014464 [debug] [Thread-3 (]: Began executing node model.quant_features.stg_stock_prices
[0m15:26:57.014802 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m15:26:57.015156 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m15:26:57.016994 [debug] [Thread-3 (]: Writing runtime sql for node "model.quant_features.stg_stock_prices"
[0m15:26:57.017521 [debug] [Thread-2 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

  
  create view "quant_features"."main"."stg_ohlc_data__dbt_tmp" as (
    

with raw_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 数据清洗和验证
        case 
            when open <= 0 or high <= 0 or low <= 0 or close <= 0 then null
            when high < greatest(open, close, low) then null
            when low > least(open, close, high) then null
            else timestamp
        end as valid_timestamp
    from "quant_features"."raw"."ohlc_data"
),

cleaned_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础指标
        (high + low + close) / 3 as typical_price,
        (high - low) as daily_range,
        case when open != 0 then (close - open) / open else 0 end as daily_return,
        case when close != 0 then volume / close else 0 end as volume_price_ratio
    from raw_ohlc
    where valid_timestamp is not null
      and timestamp >= '2020-01-01'
      and timestamp <= '2024-12-31'
)

select * from cleaned_ohlc
  );

[0m15:26:57.017953 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:26:57.018902 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_market_data"} */

  
  create view "quant_features"."main"."stg_market_data__dbt_tmp" as (
    

with source_data as (
    select
        date,
        symbol,
        market_cap,
        pe_ratio,
        dividend_yield,
        sector,
        -- 添加计算字段
        case 
            when pe_ratio > 0 then market_cap / pe_ratio 
            else null 
        end as estimated_earnings,
        case 
            when dividend_yield > 0 then market_cap * dividend_yield / 100 
            else 0 
        end as estimated_dividend_payout
    from "quant_features"."main"."market_data"
    where date is not null
      and symbol is not null
      and market_cap > 0
)

select * from source_data
  );

[0m15:26:57.019335 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:26:57.019753 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: BEGIN
[0m15:26:57.020125 [debug] [Thread-2 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

  
  create view "quant_features"."main"."stg_ohlc_data__dbt_tmp" as (
    

with raw_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 数据清洗和验证
        case 
            when open <= 0 or high <= 0 or low <= 0 or close <= 0 then null
            when high < greatest(open, close, low) then null
            when low > least(open, close, high) then null
            else timestamp
        end as valid_timestamp
    from "quant_features"."raw"."ohlc_data"
),

cleaned_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础指标
        (high + low + close) / 3 as typical_price,
        (high - low) as daily_range,
        case when open != 0 then (close - open) / open else 0 end as daily_return,
        case when close != 0 then volume / close else 0 end as volume_price_ratio
    from raw_ohlc
    where valid_timestamp is not null
      and timestamp >= '2020-01-01'
      and timestamp <= '2024-12-31'
)

select * from cleaned_ohlc
  );

[0m15:26:57.020452 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:26:57.020764 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:26:57.021280 [debug] [Thread-2 (]: DuckDB adapter: Rolling back transaction.
[0m15:26:57.025646 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:26:57.026148 [debug] [Thread-2 (]: On model.quant_features.stg_ohlc_data: ROLLBACK
[0m15:26:57.026473 [debug] [Thread-3 (]: SQL status: OK in 0.006 seconds
[0m15:26:57.026857 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_market_data"} */
alter view "quant_features"."main"."stg_market_data__dbt_tmp" rename to "stg_market_data"
[0m15:26:57.027925 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:26:57.028621 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_stock_prices"} */

  
  create view "quant_features"."main"."stg_stock_prices__dbt_tmp" as (
    

with source_data as (
    select
        date,
        symbol,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础技术指标
        (high - low) as daily_range,
        (close - open) as daily_change,
        (close - open) / open as daily_return,
        -- 添加数据质量检查
        case 
            when high >= low and high >= open and high >= close 
                 and low <= open and low <= close 
            then true 
            else false 
        end as is_valid_ohlc
    from "quant_features"."main"."raw_stock_prices"
    where date is not null
      and symbol is not null
      and open > 0
      and high > 0
      and low > 0
      and close > 0
      and volume >= 0
)

select * from source_data
where is_valid_ohlc = true
  );

[0m15:26:57.029208 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:26:57.034733 [debug] [Thread-3 (]: SQL status: OK in 0.006 seconds
[0m15:26:57.036589 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:26:57.037124 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_stock_prices"} */
alter view "quant_features"."main"."stg_stock_prices__dbt_tmp" rename to "stg_stock_prices"
[0m15:26:57.038697 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: COMMIT
[0m15:26:57.039577 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:26:57.040047 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: COMMIT
[0m15:26:57.040537 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m15:26:57.041441 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: COMMIT
[0m15:26:57.041678 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:26:57.041941 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: COMMIT
[0m15:26:57.042359 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m15:26:57.045881 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:26:57.046159 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_market_data"} */

      drop view if exists "quant_features"."main"."stg_market_data__dbt_backup" cascade
    
[0m15:26:57.046529 [debug] [Thread-3 (]: SQL status: OK in 0.004 seconds
[0m15:26:57.047988 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:26:57.048276 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m15:26:57.048631 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_stock_prices"} */

      drop view if exists "quant_features"."main"."stg_stock_prices__dbt_backup" cascade
    
[0m15:26:57.050931 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: Close
[0m15:26:57.051812 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m15:26:57.052913 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: Close
[0m15:26:57.054499 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9de5e66-0c9a-407b-8ac2-3599d5e61949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05ac4947d0>]}
[0m15:26:57.054825 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9de5e66-0c9a-407b-8ac2-3599d5e61949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05adb552e0>]}
[0m15:26:57.056884 [debug] [Thread-2 (]: Failed to rollback 'model.quant_features.stg_ohlc_data'
[0m15:26:57.057550 [info ] [Thread-3 (]: 3 of 15 OK created sql view model main.stg_stock_prices ........................ [[32mOK[0m in 0.08s]
[0m15:26:57.058125 [info ] [Thread-1 (]: 1 of 15 OK created sql view model main.stg_market_data ......................... [[32mOK[0m in 0.08s]
[0m15:26:57.058548 [debug] [Thread-2 (]: On model.quant_features.stg_ohlc_data: Close
[0m15:26:57.059023 [debug] [Thread-3 (]: Finished running node model.quant_features.stg_stock_prices
[0m15:26:57.059524 [debug] [Thread-1 (]: Finished running node model.quant_features.stg_market_data
[0m15:26:57.062310 [debug] [Thread-2 (]: Runtime Error in model stg_ohlc_data (models/staging/stg_ohlc_data.sql)
  Catalog Error: Table with name ohlc_data does not exist!
  Did you mean "pg_catalog.pg_database"?
  
  LINE 23:     from "quant_features"."raw"."ohlc_data"
                    ^
[0m15:26:57.062636 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9de5e66-0c9a-407b-8ac2-3599d5e61949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05ad0e9450>]}
[0m15:26:57.063084 [error] [Thread-2 (]: 2 of 15 ERROR creating sql view model main.stg_ohlc_data ....................... [[31mERROR[0m in 0.09s]
[0m15:26:57.063430 [debug] [Thread-2 (]: Finished running node model.quant_features.stg_ohlc_data
[0m15:26:57.063848 [debug] [Thread-7 (]: Marking all children of 'model.quant_features.stg_ohlc_data' to be skipped because of status 'error'.  Reason: Runtime Error in model stg_ohlc_data (models/staging/stg_ohlc_data.sql)
  Catalog Error: Table with name ohlc_data does not exist!
  Did you mean "pg_catalog.pg_database"?
  
  LINE 23:     from "quant_features"."raw"."ohlc_data"
                    ^.
[0m15:26:57.064720 [debug] [Thread-4 (]: Began running node model.quant_features.daily_stock_summary
[0m15:26:57.065116 [info ] [Thread-4 (]: 4 of 15 START sql table model main.daily_stock_summary ......................... [RUN]
[0m15:26:57.065652 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.quant_features.daily_stock_summary'
[0m15:26:57.065987 [debug] [Thread-4 (]: Began compiling node model.quant_features.daily_stock_summary
[0m15:26:57.066238 [debug] [Thread-3 (]: Began running node model.quant_features.alpha_base_data
[0m15:26:57.068309 [debug] [Thread-4 (]: Writing injected SQL for node "model.quant_features.daily_stock_summary"
[0m15:26:57.068679 [debug] [Thread-1 (]: Began running node model.quant_features.mart_technical_indicators
[0m15:26:57.069079 [info ] [Thread-3 (]: 5 of 15 SKIP relation main.alpha_base_data ..................................... [[33mSKIP[0m]
[0m15:26:57.069607 [info ] [Thread-1 (]: 6 of 15 SKIP relation main.mart_technical_indicators ........................... [[33mSKIP[0m]
[0m15:26:57.070036 [debug] [Thread-3 (]: Finished running node model.quant_features.alpha_base_data
[0m15:26:57.070453 [debug] [Thread-1 (]: Finished running node model.quant_features.mart_technical_indicators
[0m15:26:57.070994 [debug] [Thread-3 (]: Began running node model.quant_features.alpha_factors_021_050
[0m15:26:57.071240 [info ] [Thread-3 (]: 8 of 15 SKIP relation main.alpha_factors_021_050 ............................... [[33mSKIP[0m]
[0m15:26:57.071535 [debug] [Thread-1 (]: Began running node model.quant_features.alpha_factors_051_075
[0m15:26:57.071894 [debug] [Thread-2 (]: Began running node model.quant_features.alpha_factors_001_020
[0m15:26:57.072194 [debug] [Thread-3 (]: Finished running node model.quant_features.alpha_factors_021_050
[0m15:26:57.072532 [debug] [Thread-4 (]: Began executing node model.quant_features.daily_stock_summary
[0m15:26:57.072936 [info ] [Thread-1 (]: 9 of 15 SKIP relation main.alpha_factors_051_075 ............................... [[33mSKIP[0m]
[0m15:26:57.073355 [info ] [Thread-2 (]: 7 of 15 SKIP relation main.alpha_factors_001_020 ............................... [[33mSKIP[0m]
[0m15:26:57.073985 [debug] [Thread-3 (]: Began running node model.quant_features.alpha_factors_076_101
[0m15:26:57.084594 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha_factors_051_075
[0m15:26:57.087120 [debug] [Thread-4 (]: Writing runtime sql for node "model.quant_features.daily_stock_summary"
[0m15:26:57.087669 [debug] [Thread-2 (]: Finished running node model.quant_features.alpha_factors_001_020
[0m15:26:57.088056 [info ] [Thread-3 (]: 10 of 15 SKIP relation main.alpha_factors_076_101 .............................. [[33mSKIP[0m]
[0m15:26:57.088423 [debug] [Thread-1 (]: Began running node model.quant_features.alpha_factors_advanced
[0m15:26:57.088903 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:26:57.089413 [debug] [Thread-2 (]: Began running node model.quant_features.features_ohlc_technical
[0m15:26:57.089753 [debug] [Thread-3 (]: Finished running node model.quant_features.alpha_factors_076_101
[0m15:26:57.090340 [info ] [Thread-1 (]: 11 of 15 SKIP relation main.alpha_factors_advanced ............................. [[33mSKIP[0m]
[0m15:26:57.090710 [debug] [Thread-4 (]: On model.quant_features.daily_stock_summary: BEGIN
[0m15:26:57.091061 [info ] [Thread-2 (]: 12 of 15 SKIP relation main.features_ohlc_technical ............................ [[33mSKIP[0m]
[0m15:26:57.091521 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha_factors_advanced
[0m15:26:57.091839 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m15:26:57.092123 [debug] [Thread-2 (]: Finished running node model.quant_features.features_ohlc_technical
[0m15:26:57.092561 [debug] [Thread-3 (]: Began running node model.quant_features.alpha101_complete
[0m15:26:57.092827 [debug] [Thread-1 (]: Began running node model.quant_features.alpha_factors_final
[0m15:26:57.093574 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m15:26:57.093915 [info ] [Thread-3 (]: 13 of 15 SKIP relation main.alpha101_complete .................................. [[33mSKIP[0m]
[0m15:26:57.094250 [info ] [Thread-1 (]: 14 of 15 SKIP relation main.alpha_factors_final ................................ [[33mSKIP[0m]
[0m15:26:57.094688 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:26:57.095068 [debug] [Thread-3 (]: Finished running node model.quant_features.alpha101_complete
[0m15:26:57.095451 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha_factors_final
[0m15:26:57.095897 [debug] [Thread-4 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */

  
    
    

    create  table
      "quant_features"."main"."daily_stock_summary__dbt_tmp"
  
    as (
      

with price_data as (
    select * from "quant_features"."main"."stg_stock_prices"
),

market_data as (
    select * from "quant_features"."main"."stg_market_data"
),

combined_data as (
    select
        p.date,
        p.symbol,
        p.open,
        p.high,
        p.low,
        p.close,
        p.volume,
        p.daily_range,
        p.daily_change,
        p.daily_return,
        m.market_cap,
        m.pe_ratio,
        m.dividend_yield,
        m.sector,
        m.estimated_earnings,
        m.estimated_dividend_payout,
        -- 计算额外的技术指标
        (p.high + p.low + p.close) / 3 as typical_price,
        p.volume * p.close as dollar_volume,
        case 
            when p.daily_return > 0.05 then 'Strong Up'
            when p.daily_return > 0.02 then 'Up'
            when p.daily_return > -0.02 then 'Flat'
            when p.daily_return > -0.05 then 'Down'
            else 'Strong Down'
        end as price_movement_category
    from price_data p
    left join market_data m
        on p.date = m.date
        and p.symbol = m.symbol
)

select * from combined_data
    );
  
  
[0m15:26:57.100755 [debug] [Thread-4 (]: SQL status: OK in 0.004 seconds
[0m15:26:57.102478 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:26:57.102747 [debug] [Thread-4 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */
alter table "quant_features"."main"."daily_stock_summary__dbt_tmp" rename to "daily_stock_summary"
[0m15:26:57.103219 [debug] [Thread-4 (]: SQL status: OK in 0.000 seconds
[0m15:26:57.106267 [debug] [Thread-4 (]: On model.quant_features.daily_stock_summary: COMMIT
[0m15:26:57.106542 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:26:57.106733 [debug] [Thread-4 (]: On model.quant_features.daily_stock_summary: COMMIT
[0m15:26:57.108696 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m15:26:57.110402 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:26:57.110668 [debug] [Thread-4 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */

      drop table if exists "quant_features"."main"."daily_stock_summary__dbt_backup" cascade
    
[0m15:26:57.111086 [debug] [Thread-4 (]: SQL status: OK in 0.000 seconds
[0m15:26:57.111915 [debug] [Thread-4 (]: On model.quant_features.daily_stock_summary: Close
[0m15:26:57.112392 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9de5e66-0c9a-407b-8ac2-3599d5e61949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05b206b550>]}
[0m15:26:57.112774 [info ] [Thread-4 (]: 4 of 15 OK created sql table model main.daily_stock_summary .................... [[32mOK[0m in 0.05s]
[0m15:26:57.113141 [debug] [Thread-4 (]: Finished running node model.quant_features.daily_stock_summary
[0m15:26:57.113624 [debug] [Thread-2 (]: Began running node model.quant_features.stock_features
[0m15:26:57.113924 [info ] [Thread-2 (]: 15 of 15 START sql table model main.stock_features ............................. [RUN]
[0m15:26:57.114253 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.quant_features.stg_ohlc_data, now model.quant_features.stock_features)
[0m15:26:57.114462 [debug] [Thread-2 (]: Began compiling node model.quant_features.stock_features
[0m15:26:57.116280 [debug] [Thread-2 (]: Writing injected SQL for node "model.quant_features.stock_features"
[0m15:26:57.116757 [debug] [Thread-2 (]: Began executing node model.quant_features.stock_features
[0m15:26:57.118763 [debug] [Thread-2 (]: Writing runtime sql for node "model.quant_features.stock_features"
[0m15:26:57.119225 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:26:57.119445 [debug] [Thread-2 (]: On model.quant_features.stock_features: BEGIN
[0m15:26:57.119626 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m15:26:57.120020 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m15:26:57.120226 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:26:57.120469 [debug] [Thread-2 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */

  
    
    

    create  table
      "quant_features"."main"."stock_features__dbt_tmp"
  
    as (
      

with daily_data as (
    select * from "quant_features"."main"."daily_stock_summary"
),

windowed_features as (
    select
        *,
        -- 移动平均
        avg(close) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as ma_5d,
        
        avg(close) over (
            partition by symbol 
            order by date 
            rows between 9 preceding and current row
        ) as ma_10d,
        
        -- 波动率（标准差）
        stddev(daily_return) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as volatility_5d,
        
        -- 价格相对位置
        (close - min(low) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        )) / (max(high) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) - min(low) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        )) as price_position_5d,
        
        -- 成交量相对强度
        volume / avg(volume) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as volume_ratio_5d
        
    from daily_data
),

final_features as (
    select
        *,
        -- 技术信号
        case 
            when close > ma_5d and ma_5d > ma_10d then 'Bullish'
            when close < ma_5d and ma_5d < ma_10d then 'Bearish'
            else 'Neutral'
        end as trend_signal,
        
        case 
            when volatility_5d > 0.03 then 'High'
            when volatility_5d > 0.01 then 'Medium'
            else 'Low'
        end as volatility_category
        
    from windowed_features
)

select * from final_features
    );
  
  
[0m15:26:57.125899 [debug] [Thread-2 (]: SQL status: OK in 0.005 seconds
[0m15:26:57.127592 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:26:57.127864 [debug] [Thread-2 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */
alter table "quant_features"."main"."stock_features__dbt_tmp" rename to "stock_features"
[0m15:26:57.128348 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m15:26:57.129195 [debug] [Thread-2 (]: On model.quant_features.stock_features: COMMIT
[0m15:26:57.129440 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:26:57.129635 [debug] [Thread-2 (]: On model.quant_features.stock_features: COMMIT
[0m15:26:57.131312 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m15:26:57.132683 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:26:57.132943 [debug] [Thread-2 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */

      drop table if exists "quant_features"."main"."stock_features__dbt_backup" cascade
    
[0m15:26:57.133348 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m15:26:57.134170 [debug] [Thread-2 (]: On model.quant_features.stock_features: Close
[0m15:26:57.134813 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b9de5e66-0c9a-407b-8ac2-3599d5e61949', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05ac56f9a0>]}
[0m15:26:57.135208 [info ] [Thread-2 (]: 15 of 15 OK created sql table model main.stock_features ........................ [[32mOK[0m in 0.02s]
[0m15:26:57.135513 [debug] [Thread-2 (]: Finished running node model.quant_features.stock_features
[0m15:26:57.136653 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:57.136926 [debug] [MainThread]: On master: BEGIN
[0m15:26:57.137089 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:26:57.137439 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:57.137616 [debug] [MainThread]: On master: COMMIT
[0m15:26:57.137772 [debug] [MainThread]: Using duckdb connection "master"
[0m15:26:57.137934 [debug] [MainThread]: On master: COMMIT
[0m15:26:57.138188 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:26:57.138357 [debug] [MainThread]: On master: Close
[0m15:26:57.138631 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:26:57.138790 [debug] [MainThread]: Connection 'model.quant_features.stg_market_data' was properly closed.
[0m15:26:57.138941 [debug] [MainThread]: Connection 'model.quant_features.stock_features' was properly closed.
[0m15:26:57.139072 [debug] [MainThread]: Connection 'model.quant_features.stg_stock_prices' was properly closed.
[0m15:26:57.139204 [debug] [MainThread]: Connection 'model.quant_features.daily_stock_summary' was properly closed.
[0m15:26:57.139419 [info ] [MainThread]: 
[0m15:26:57.139618 [info ] [MainThread]: Finished running 12 table models, 3 view models in 0 hours 0 minutes and 0.27 seconds (0.27s).
[0m15:26:57.140395 [debug] [MainThread]: Command end result
[0m15:26:57.163073 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:26:57.164191 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:26:57.168089 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m15:26:57.168322 [info ] [MainThread]: 
[0m15:26:57.168544 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:26:57.168715 [info ] [MainThread]: 
[0m15:26:57.168931 [error] [MainThread]: [31mFailure in model stg_ohlc_data (models/staging/stg_ohlc_data.sql)[0m
[0m15:26:57.169129 [error] [MainThread]:   Runtime Error in model stg_ohlc_data (models/staging/stg_ohlc_data.sql)
  Catalog Error: Table with name ohlc_data does not exist!
  Did you mean "pg_catalog.pg_database"?
  
  LINE 23:     from "quant_features"."raw"."ohlc_data"
                    ^
[0m15:26:57.169279 [info ] [MainThread]: 
[0m15:26:57.169469 [info ] [MainThread]:   compiled code at target/compiled/quant_features/models/staging/stg_ohlc_data.sql
[0m15:26:57.169618 [info ] [MainThread]: 
[0m15:26:57.169780 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=10 NO-OP=0 TOTAL=15
[0m15:26:57.170320 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.757745, "process_in_blocks": "0", "process_kernel_time": 0.148485, "process_mem_max_rss": "160840", "process_out_blocks": "3680", "process_user_time": 1.504961}
[0m15:26:57.170611 [debug] [MainThread]: Command `dbt run` failed at 15:26:57.170551 after 0.76 seconds
[0m15:26:57.170830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05adb3c0b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05b2166570>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f05ae03fdd0>]}
[0m15:26:57.171039 [debug] [MainThread]: Flushing usage events
[0m15:26:57.212220 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:27:19.361235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90cfad3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90d1105a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90ce947d90>]}


============================== 15:27:19.363613 | 546a7400-bea5-4d62-9693-c27be28811e4 ==============================
[0m15:27:19.363613 [info ] [MainThread]: Running with dbt=1.10.9
[0m15:27:19.363934 [debug] [MainThread]: running dbt with arguments {'log_path': '/workspace/dbt_project/logs', 'static_parser': 'True', 'fail_fast': 'False', 'no_print': 'None', 'version_check': 'True', 'use_colors': 'True', 'introspect': 'True', 'target_path': 'None', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run', 'cache_selected_only': 'False', 'debug': 'False', 'indirect_selection': 'eager', 'warn_error': 'None', 'profiles_dir': '/workspace/dbt_project', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'log_cache_events': 'False', 'empty': 'False', 'printer_width': '80', 'write_json': 'True', 'log_format': 'default', 'quiet': 'False', 'partial_parse': 'True'}
[0m15:27:19.499701 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90cf65e650>]}
[0m15:27:19.541214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90cea42be0>]}
[0m15:27:19.542209 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m15:27:19.571543 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m15:27:19.657453 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m15:27:19.657918 [debug] [MainThread]: Partial parsing: updated file: quant_features://models/staging/stg_ohlc_data.sql
[0m15:27:19.977364 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90ca51e250>]}
[0m15:27:20.046399 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:27:20.047614 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:27:20.058917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90cb28d220>]}
[0m15:27:20.059292 [info ] [MainThread]: Found 15 models, 2 seeds, 37 data tests, 1 source, 565 macros
[0m15:27:20.059507 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90ca99ab30>]}
[0m15:27:20.061329 [info ] [MainThread]: 
[0m15:27:20.061604 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:27:20.061773 [info ] [MainThread]: 
[0m15:27:20.062049 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:27:20.066050 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m15:27:20.081967 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m15:27:20.082237 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m15:27:20.082417 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:27:20.092613 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m15:27:20.093480 [debug] [ThreadPool]: On list_quant_features: Close
[0m15:27:20.094266 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m15:27:20.094651 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m15:27:20.098933 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:27:20.099206 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m15:27:20.099388 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:27:20.100314 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m15:27:20.101150 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:27:20.101370 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m15:27:20.101689 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:27:20.101851 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:27:20.101997 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m15:27:20.102327 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:27:20.102866 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:27:20.103090 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:27:20.103312 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:27:20.103715 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:27:20.103905 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m15:27:20.105485 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m15:27:20.109256 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:27:20.109509 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m15:27:20.109684 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:27:20.110095 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:27:20.110300 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:27:20.110472 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m15:27:20.117055 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m15:27:20.117986 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m15:27:20.118624 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m15:27:20.118838 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m15:27:20.120386 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90c9137790>]}
[0m15:27:20.120813 [debug] [MainThread]: Using duckdb connection "master"
[0m15:27:20.121011 [debug] [MainThread]: On master: BEGIN
[0m15:27:20.121166 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:27:20.121589 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:27:20.121783 [debug] [MainThread]: On master: COMMIT
[0m15:27:20.121940 [debug] [MainThread]: Using duckdb connection "master"
[0m15:27:20.122090 [debug] [MainThread]: On master: COMMIT
[0m15:27:20.122404 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:27:20.122604 [debug] [MainThread]: On master: Close
[0m15:27:20.124560 [debug] [Thread-3 (]: Began running node model.quant_features.stg_stock_prices
[0m15:27:20.124925 [info ] [Thread-3 (]: 3 of 15 START sql view model main.stg_stock_prices ............................. [RUN]
[0m15:27:20.125253 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.quant_features.stg_stock_prices'
[0m15:27:20.125459 [debug] [Thread-3 (]: Began compiling node model.quant_features.stg_stock_prices
[0m15:27:20.125826 [debug] [Thread-2 (]: Began running node model.quant_features.stg_ohlc_data
[0m15:27:20.130600 [debug] [Thread-3 (]: Writing injected SQL for node "model.quant_features.stg_stock_prices"
[0m15:27:20.131020 [debug] [Thread-1 (]: Began running node model.quant_features.stg_market_data
[0m15:27:20.131594 [info ] [Thread-2 (]: 2 of 15 START sql view model main.stg_ohlc_data ................................ [RUN]
[0m15:27:20.132248 [info ] [Thread-1 (]: 1 of 15 START sql view model main.stg_market_data .............................. [RUN]
[0m15:27:20.132824 [debug] [Thread-3 (]: Began executing node model.quant_features.stg_stock_prices
[0m15:27:20.133424 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.quant_features.stg_ohlc_data'
[0m15:27:20.133934 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.stg_market_data)
[0m15:27:20.144896 [debug] [Thread-2 (]: Began compiling node model.quant_features.stg_ohlc_data
[0m15:27:20.154445 [debug] [Thread-3 (]: Writing runtime sql for node "model.quant_features.stg_stock_prices"
[0m15:27:20.154963 [debug] [Thread-1 (]: Began compiling node model.quant_features.stg_market_data
[0m15:27:20.157774 [debug] [Thread-2 (]: Writing injected SQL for node "model.quant_features.stg_ohlc_data"
[0m15:27:20.158265 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:20.160312 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.stg_market_data"
[0m15:27:20.160967 [debug] [Thread-2 (]: Began executing node model.quant_features.stg_ohlc_data
[0m15:27:20.161395 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: BEGIN
[0m15:27:20.162053 [debug] [Thread-1 (]: Began executing node model.quant_features.stg_market_data
[0m15:27:20.164518 [debug] [Thread-2 (]: Writing runtime sql for node "model.quant_features.stg_ohlc_data"
[0m15:27:20.165045 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:27:20.167085 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.stg_market_data"
[0m15:27:20.167716 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m15:27:20.168256 [debug] [Thread-2 (]: On model.quant_features.stg_ohlc_data: BEGIN
[0m15:27:20.168480 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:27:20.168930 [debug] [Thread-3 (]: SQL status: OK in 0.004 seconds
[0m15:27:20.169229 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:20.169462 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_stock_prices"} */

  
  create view "quant_features"."main"."stg_stock_prices__dbt_tmp" as (
    

with source_data as (
    select
        date,
        symbol,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础技术指标
        (high - low) as daily_range,
        (close - open) as daily_change,
        (close - open) / open as daily_return,
        -- 添加数据质量检查
        case 
            when high >= low and high >= open and high >= close 
                 and low <= open and low <= close 
            then true 
            else false 
        end as is_valid_ohlc
    from "quant_features"."main"."raw_stock_prices"
    where date is not null
      and symbol is not null
      and open > 0
      and high > 0
      and low > 0
      and close > 0
      and volume >= 0
)

select * from source_data
where is_valid_ohlc = true
  );

[0m15:27:20.169953 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:20.170325 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m15:27:20.170661 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: BEGIN
[0m15:27:20.171022 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m15:27:20.171342 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m15:27:20.171613 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:27:20.175825 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:20.176390 [debug] [Thread-2 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

  
  create view "quant_features"."main"."stg_ohlc_data__dbt_tmp" as (
    

with raw_ohlc as (
    select 
        symbol,
        date as timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 数据清洗和验证
        case 
            when open <= 0 or high <= 0 or low <= 0 or close <= 0 then null
            when high < greatest(open, close, low) then null
            when low > least(open, close, high) then null
            else date
        end as valid_timestamp
    from "quant_features"."main"."raw_stock_prices"
),

cleaned_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础指标
        (high + low + close) / 3 as typical_price,
        (high - low) as daily_range,
        case when open != 0 then (close - open) / open else 0 end as daily_return,
        case when close != 0 then volume / close else 0 end as volume_price_ratio
    from raw_ohlc
    where valid_timestamp is not null
      and timestamp >= '2020-01-01'
      and timestamp <= '2024-12-31'
)

select * from cleaned_ohlc
  );

[0m15:27:20.177210 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_stock_prices"} */
alter view "quant_features"."main"."stg_stock_prices" rename to "stg_stock_prices__dbt_backup"
[0m15:27:20.177747 [debug] [Thread-1 (]: SQL status: OK in 0.006 seconds
[0m15:27:20.178489 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:20.178818 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_market_data"} */

  
  create view "quant_features"."main"."stg_market_data__dbt_tmp" as (
    

with source_data as (
    select
        date,
        symbol,
        market_cap,
        pe_ratio,
        dividend_yield,
        sector,
        -- 添加计算字段
        case 
            when pe_ratio > 0 then market_cap / pe_ratio 
            else null 
        end as estimated_earnings,
        case 
            when dividend_yield > 0 then market_cap * dividend_yield / 100 
            else 0 
        end as estimated_dividend_payout
    from "quant_features"."main"."market_data"
    where date is not null
      and symbol is not null
      and market_cap > 0
)

select * from source_data
  );

[0m15:27:20.179124 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m15:27:20.179464 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m15:27:20.181248 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:20.183879 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m15:27:20.184214 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_stock_prices"} */
alter view "quant_features"."main"."stg_stock_prices__dbt_tmp" rename to "stg_stock_prices"
[0m15:27:20.184510 [debug] [Thread-2 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */
alter view "quant_features"."main"."stg_ohlc_data__dbt_tmp" rename to "stg_ohlc_data"
[0m15:27:20.185035 [debug] [Thread-1 (]: SQL status: OK in 0.006 seconds
[0m15:27:20.186012 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m15:27:20.188116 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:20.188495 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m15:27:20.196317 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: COMMIT
[0m15:27:20.196830 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_market_data"} */
alter view "quant_features"."main"."stg_market_data" rename to "stg_market_data__dbt_backup"
[0m15:27:20.197910 [debug] [Thread-2 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m15:27:20.198382 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:20.199157 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m15:27:20.199665 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:27:20.200144 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: COMMIT
[0m15:27:20.200656 [debug] [Thread-2 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m15:27:20.202875 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:20.203709 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_market_data"} */
alter view "quant_features"."main"."stg_market_data__dbt_tmp" rename to "stg_market_data"
[0m15:27:20.204289 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:27:20.205121 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: COMMIT
[0m15:27:20.205463 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m15:27:20.205842 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:20.206256 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m15:27:20.209777 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:20.210325 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: COMMIT
[0m15:27:20.212346 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m15:27:20.212913 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_stock_prices"} */

      drop view if exists "quant_features"."main"."stg_stock_prices__dbt_backup" cascade
    
[0m15:27:20.213583 [debug] [Thread-2 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

      drop view if exists "quant_features"."main"."stg_ohlc_data__dbt_backup" cascade
    
[0m15:27:20.214765 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:27:20.216161 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:20.216507 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m15:27:20.216818 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_market_data"} */

      drop view if exists "quant_features"."main"."stg_market_data__dbt_backup" cascade
    
[0m15:27:20.218644 [debug] [Thread-3 (]: On model.quant_features.stg_stock_prices: Close
[0m15:27:20.219117 [debug] [Thread-2 (]: SQL status: OK in 0.005 seconds
[0m15:27:20.220217 [debug] [Thread-2 (]: On model.quant_features.stg_ohlc_data: Close
[0m15:27:20.221364 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90c90b2210>]}
[0m15:27:20.221786 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:27:20.222337 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90ca4dad00>]}
[0m15:27:20.222823 [info ] [Thread-3 (]: 3 of 15 OK created sql view model main.stg_stock_prices ........................ [[32mOK[0m in 0.10s]
[0m15:27:20.223817 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: Close
[0m15:27:20.224236 [info ] [Thread-2 (]: 2 of 15 OK created sql view model main.stg_ohlc_data ........................... [[32mOK[0m in 0.09s]
[0m15:27:20.224671 [debug] [Thread-3 (]: Finished running node model.quant_features.stg_stock_prices
[0m15:27:20.225073 [debug] [Thread-2 (]: Finished running node model.quant_features.stg_ohlc_data
[0m15:27:20.225422 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90cb2dfc50>]}
[0m15:27:20.226378 [debug] [Thread-4 (]: Began running node model.quant_features.alpha_base_data
[0m15:27:20.226769 [info ] [Thread-1 (]: 1 of 15 OK created sql view model main.stg_market_data ......................... [[32mOK[0m in 0.09s]
[0m15:27:20.227295 [debug] [Thread-3 (]: Began running node model.quant_features.mart_technical_indicators
[0m15:27:20.227700 [info ] [Thread-4 (]: 4 of 15 START sql table model main.alpha_base_data ............................. [RUN]
[0m15:27:20.228072 [debug] [Thread-1 (]: Finished running node model.quant_features.stg_market_data
[0m15:27:20.228836 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.quant_features.alpha_base_data'
[0m15:27:20.229220 [debug] [Thread-4 (]: Began compiling node model.quant_features.alpha_base_data
[0m15:27:20.228493 [info ] [Thread-3 (]: 5 of 15 START sql table model main.mart_technical_indicators ................... [RUN]
[0m15:27:20.240134 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.quant_features.stg_stock_prices, now model.quant_features.mart_technical_indicators)
[0m15:27:20.240474 [debug] [Thread-3 (]: Began compiling node model.quant_features.mart_technical_indicators
[0m15:27:20.242500 [debug] [Thread-3 (]: Writing injected SQL for node "model.quant_features.mart_technical_indicators"
[0m15:27:20.252238 [debug] [Thread-4 (]: Writing injected SQL for node "model.quant_features.alpha_base_data"
[0m15:27:20.252607 [debug] [Thread-3 (]: Began executing node model.quant_features.mart_technical_indicators
[0m15:27:20.258414 [debug] [Thread-2 (]: Began running node model.quant_features.daily_stock_summary
[0m15:27:20.258819 [info ] [Thread-2 (]: 6 of 15 START sql table model main.daily_stock_summary ......................... [RUN]
[0m15:27:20.266248 [debug] [Thread-3 (]: Writing runtime sql for node "model.quant_features.mart_technical_indicators"
[0m15:27:20.266795 [debug] [Thread-4 (]: Began executing node model.quant_features.alpha_base_data
[0m15:27:20.267315 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.quant_features.stg_ohlc_data, now model.quant_features.daily_stock_summary)
[0m15:27:20.269501 [debug] [Thread-4 (]: Writing runtime sql for node "model.quant_features.alpha_base_data"
[0m15:27:20.270020 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m15:27:20.270592 [debug] [Thread-2 (]: Began compiling node model.quant_features.daily_stock_summary
[0m15:27:20.271076 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: BEGIN
[0m15:27:20.275681 [debug] [Thread-2 (]: Writing injected SQL for node "model.quant_features.daily_stock_summary"
[0m15:27:20.276155 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m15:27:20.276618 [debug] [Thread-2 (]: Began executing node model.quant_features.daily_stock_summary
[0m15:27:20.278814 [debug] [Thread-2 (]: Writing runtime sql for node "model.quant_features.daily_stock_summary"
[0m15:27:20.279331 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m15:27:20.279736 [debug] [Thread-3 (]: SQL status: OK in 0.004 seconds
[0m15:27:20.280092 [debug] [Thread-4 (]: On model.quant_features.alpha_base_data: BEGIN
[0m15:27:20.280437 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:20.280859 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m15:27:20.281227 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m15:27:20.281725 [debug] [Thread-2 (]: On model.quant_features.daily_stock_summary: BEGIN
[0m15:27:20.282233 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */

  
    
    

    create  table
      "quant_features"."main"."mart_technical_indicators__dbt_tmp"
  
    as (
      

with base_data as (
    select * from "quant_features"."main"."stg_ohlc_data"
),

technical_indicators as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        typical_price,
        daily_range,
        daily_return,
        volume_price_ratio,
        
        -- 移动平均线
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 4 preceding and current row
        ) as ma_5,
        
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 9 preceding and current row
        ) as ma_10,
        
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as ma_20,
        
        -- 波动率 (标准差)
        stddev(daily_return) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as volatility_20d,
        
        -- RSI相关计算
        case when daily_return > 0 then daily_return else 0 end as gain,
        case when daily_return < 0 then abs(daily_return) else 0 end as loss,
        
        -- 价格位置指标
        (close - min(low) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        )) / nullif((max(high) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) - min(low) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        )), 0) as stoch_k_14,
        
        -- 成交量指标
        avg(volume) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as avg_volume_20d
        
    from base_data
),

rsi_calculation as (
    select *,
        -- RSI计算
        avg(gain) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) as avg_gain_14,
        
        avg(loss) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) as avg_loss_14
    from technical_indicators
),

final_indicators as (
    select *,
        case 
            when avg_loss_14 = 0 then 100
            when avg_gain_14 = 0 then 0
            else 100 - (100 / (1 + (avg_gain_14 / avg_loss_14)))
        end as rsi_14,
        
        -- 布林带
        ma_20 + (2 * stddev(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        )) as bollinger_upper,
        
        ma_20 - (2 * stddev(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        )) as bollinger_lower,
        
        -- 价格动量
        case when lag(close, 5) over (partition by symbol order by timestamp) != 0 
            then (close - lag(close, 5) over (partition by symbol order by timestamp)) / 
                 lag(close, 5) over (partition by symbol order by timestamp)
            else 0 
        end as momentum_5d,
        
        case when lag(close, 10) over (partition by symbol order by timestamp) != 0 
            then (close - lag(close, 10) over (partition by symbol order by timestamp)) / 
                 lag(close, 10) over (partition by symbol order by timestamp)
            else 0 
        end as momentum_10d
        
    from rsi_calculation
)

select * from final_indicators
    );
  
  
[0m15:27:20.282922 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m15:27:20.283291 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m15:27:20.284098 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m15:27:20.284587 [debug] [Thread-4 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_base_data__dbt_tmp"
  
    as (
      

-- Alpha 101 基础数据准备
-- 为Alpha因子计算准备所有必要的基础数据

WITH base_ohlc AS (
    SELECT 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算VWAP (简化版本，假设等权重)
        (high + low + close) / 3 AS vwap,
        -- 计算returns
        CASE 
            WHEN LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp) IS NOT NULL
            THEN (close - LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)) / 
                 LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)
            ELSE 0
        END AS returns
    FROM "quant_features"."main"."stg_ohlc_data"
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
),

enhanced_data AS (
    SELECT 
        *,
        -- 计算ADV (Average Daily Volume)
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 AS adv20,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

 AS adv10,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

 AS adv5,
        
        -- 预计算一些常用的时间序列指标
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_ma5,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ma10,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_ma20,
        
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_ma20,
        
        -- 预计算滚动标准差
        
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_std20,
        
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS returns_std20,
        
        -- 预计算一些延迟项
        
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag1,
        
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag2,
        
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag5,
        
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag10,
        
    LAG(close, 20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag20,
        
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS volume_lag1,
        
    LAG(high, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS high_lag1,
        
    LAG(low, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS low_lag1,
        
    LAG(vwap, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS vwap_lag5,
        
        -- 预计算一些差值项
        
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta1,
        
    close - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta2,
        
    close - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta3,
        
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta5,
        
    close - 
    LAG(close, 7) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta7,
        
    close - 
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta10,
        
    volume - 
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta1,
        
    volume - 
    LAG(volume, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta3,
        
    high - 
    LAG(high, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS high_delta2,
        
        -- 预计算一些排序项
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
 AS close_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
 AS volume_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
 AS high_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
 AS low_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
 AS vwap_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns
    )
 AS returns_rank,
        
        -- 预计算时间序列排序
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ts_rank10,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_ts_rank5,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY high
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_ts_rank5,
        
        -- 预计算一些最值项
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_min100,
        
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS close_max3,
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_min5,
        
    MAX(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_max5,
        
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS low_min5,
        
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS high_max3,
        
        -- 预计算一些求和项
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_sum5,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS close_sum8,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_sum20,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_sum100,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
    )
 AS close_sum200,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_sum5,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_sum20,
        
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 AS returns_sum250,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_sum5,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS high_sum20,
        
        -- 预计算一些相关性
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_close_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(open, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_open_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS corr_high_volume_5,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS corr_vwap_volume_6,
        
        -- 预计算一些协方差
        
    COVAR_SAMP(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_close_volume_5,
        
    COVAR_SAMP(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_high_volume_5
        
    FROM base_ohlc
    WHERE timestamp >= '2020-01-01' - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数据
),

-- 过滤回原始时间范围
final_data AS (
    SELECT *
    FROM enhanced_data
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
)

SELECT * FROM final_data
    );
  
  
[0m15:27:20.285755 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m15:27:20.286068 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:20.286382 [debug] [Thread-2 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */

  
    
    

    create  table
      "quant_features"."main"."daily_stock_summary__dbt_tmp"
  
    as (
      

with price_data as (
    select * from "quant_features"."main"."stg_stock_prices"
),

market_data as (
    select * from "quant_features"."main"."stg_market_data"
),

combined_data as (
    select
        p.date,
        p.symbol,
        p.open,
        p.high,
        p.low,
        p.close,
        p.volume,
        p.daily_range,
        p.daily_change,
        p.daily_return,
        m.market_cap,
        m.pe_ratio,
        m.dividend_yield,
        m.sector,
        m.estimated_earnings,
        m.estimated_dividend_payout,
        -- 计算额外的技术指标
        (p.high + p.low + p.close) / 3 as typical_price,
        p.volume * p.close as dollar_volume,
        case 
            when p.daily_return > 0.05 then 'Strong Up'
            when p.daily_return > 0.02 then 'Up'
            when p.daily_return > -0.02 then 'Flat'
            when p.daily_return > -0.05 then 'Down'
            else 'Strong Down'
        end as price_movement_category
    from price_data p
    left join market_data m
        on p.date = m.date
        and p.symbol = m.symbol
)

select * from combined_data
    );
  
  
[0m15:27:20.287316 [debug] [Thread-4 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_base_data__dbt_tmp"
  
    as (
      

-- Alpha 101 基础数据准备
-- 为Alpha因子计算准备所有必要的基础数据

WITH base_ohlc AS (
    SELECT 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算VWAP (简化版本，假设等权重)
        (high + low + close) / 3 AS vwap,
        -- 计算returns
        CASE 
            WHEN LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp) IS NOT NULL
            THEN (close - LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)) / 
                 LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)
            ELSE 0
        END AS returns
    FROM "quant_features"."main"."stg_ohlc_data"
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
),

enhanced_data AS (
    SELECT 
        *,
        -- 计算ADV (Average Daily Volume)
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 AS adv20,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

 AS adv10,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

 AS adv5,
        
        -- 预计算一些常用的时间序列指标
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_ma5,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ma10,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_ma20,
        
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_ma20,
        
        -- 预计算滚动标准差
        
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_std20,
        
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS returns_std20,
        
        -- 预计算一些延迟项
        
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag1,
        
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag2,
        
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag5,
        
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag10,
        
    LAG(close, 20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag20,
        
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS volume_lag1,
        
    LAG(high, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS high_lag1,
        
    LAG(low, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS low_lag1,
        
    LAG(vwap, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS vwap_lag5,
        
        -- 预计算一些差值项
        
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta1,
        
    close - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta2,
        
    close - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta3,
        
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta5,
        
    close - 
    LAG(close, 7) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta7,
        
    close - 
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta10,
        
    volume - 
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta1,
        
    volume - 
    LAG(volume, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta3,
        
    high - 
    LAG(high, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS high_delta2,
        
        -- 预计算一些排序项
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
 AS close_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
 AS volume_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
 AS high_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
 AS low_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
 AS vwap_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns
    )
 AS returns_rank,
        
        -- 预计算时间序列排序
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ts_rank10,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_ts_rank5,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY high
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_ts_rank5,
        
        -- 预计算一些最值项
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_min100,
        
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS close_max3,
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_min5,
        
    MAX(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_max5,
        
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS low_min5,
        
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS high_max3,
        
        -- 预计算一些求和项
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_sum5,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS close_sum8,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_sum20,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_sum100,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
    )
 AS close_sum200,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_sum5,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_sum20,
        
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 AS returns_sum250,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_sum5,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS high_sum20,
        
        -- 预计算一些相关性
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_close_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(open, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_open_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS corr_high_volume_5,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS corr_vwap_volume_6,
        
        -- 预计算一些协方差
        
    COVAR_SAMP(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_close_volume_5,
        
    COVAR_SAMP(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_high_volume_5
        
    FROM base_ohlc
    WHERE timestamp >= '2020-01-01' - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数据
),

-- 过滤回原始时间范围
final_data AS (
    SELECT *
    FROM enhanced_data
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
)

SELECT * FROM final_data
    );
  
  
[0m15:27:20.287984 [debug] [Thread-4 (]: DuckDB adapter: Rolling back transaction.
[0m15:27:20.288307 [debug] [Thread-4 (]: On model.quant_features.alpha_base_data: ROLLBACK
[0m15:27:20.291607 [debug] [Thread-4 (]: Failed to rollback 'model.quant_features.alpha_base_data'
[0m15:27:20.291931 [debug] [Thread-4 (]: On model.quant_features.alpha_base_data: Close
[0m15:27:20.292472 [debug] [Thread-2 (]: SQL status: OK in 0.006 seconds
[0m15:27:20.295281 [debug] [Thread-4 (]: Runtime Error in model alpha_base_data (models/alpha101/alpha_base_data.sql)
  Binder Error: Could not choose a best candidate function for the function call "-(STRING_LITERAL, INTERVAL)". In order to select one, please add explicit type casts.
  	Candidate functions:
  	-(DATE, INTERVAL) -> TIMESTAMP
  	-(TIME, INTERVAL) -> TIME
  	-(TIMESTAMP, INTERVAL) -> TIMESTAMP
  	-(TIME WITH TIME ZONE, INTERVAL) -> TIME WITH TIME ZONE
  	-(TIMESTAMP WITH TIME ZONE, INTERVAL) -> TIMESTAMP WITH TIME ZONE
  	-(INTERVAL, INTERVAL) -> INTERVAL
  
  
  LINE 475:     WHERE timestamp >= '2020-01-01' - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数...
                                                ^
[0m15:27:20.297214 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:20.297779 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90c8f8c3d0>]}
[0m15:27:20.298178 [debug] [Thread-3 (]: SQL status: OK in 0.015 seconds
[0m15:27:20.298512 [debug] [Thread-2 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */
alter table "quant_features"."main"."daily_stock_summary" rename to "daily_stock_summary__dbt_backup"
[0m15:27:20.299003 [error] [Thread-4 (]: 4 of 15 ERROR creating sql table model main.alpha_base_data .................... [[31mERROR[0m in 0.07s]
[0m15:27:20.301779 [debug] [Thread-4 (]: Finished running node model.quant_features.alpha_base_data
[0m15:27:20.300906 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m15:27:20.302099 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m15:27:20.302663 [debug] [Thread-7 (]: Marking all children of 'model.quant_features.alpha_base_data' to be skipped because of status 'error'.  Reason: Runtime Error in model alpha_base_data (models/alpha101/alpha_base_data.sql)
  Binder Error: Could not choose a best candidate function for the function call "-(STRING_LITERAL, INTERVAL)". In order to select one, please add explicit type casts.
  	Candidate functions:
  	-(DATE, INTERVAL) -> TIMESTAMP
  	-(TIME, INTERVAL) -> TIME
  	-(TIMESTAMP, INTERVAL) -> TIMESTAMP
  	-(TIME WITH TIME ZONE, INTERVAL) -> TIME WITH TIME ZONE
  	-(TIMESTAMP WITH TIME ZONE, INTERVAL) -> TIMESTAMP WITH TIME ZONE
  	-(INTERVAL, INTERVAL) -> INTERVAL
  
  
  LINE 475:     WHERE timestamp >= '2020-01-01' - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数...
                                                ^.
[0m15:27:20.303027 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */
alter table "quant_features"."main"."mart_technical_indicators__dbt_tmp" rename to "mart_technical_indicators"
[0m15:27:20.305162 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:20.306419 [debug] [Thread-1 (]: Began running node model.quant_features.alpha_factors_001_020
[0m15:27:20.306818 [debug] [Thread-4 (]: Began running node model.quant_features.alpha_factors_021_050
[0m15:27:20.307225 [debug] [Thread-2 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */
alter table "quant_features"."main"."daily_stock_summary__dbt_tmp" rename to "daily_stock_summary"
[0m15:27:20.307609 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m15:27:20.307945 [info ] [Thread-1 (]: 7 of 15 SKIP relation main.alpha_factors_001_020 ............................... [[33mSKIP[0m]
[0m15:27:20.308301 [info ] [Thread-4 (]: 8 of 15 SKIP relation main.alpha_factors_021_050 ............................... [[33mSKIP[0m]
[0m15:27:20.311660 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: COMMIT
[0m15:27:20.312098 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha_factors_001_020
[0m15:27:20.312510 [debug] [Thread-2 (]: SQL status: OK in 0.004 seconds
[0m15:27:20.312814 [debug] [Thread-4 (]: Finished running node model.quant_features.alpha_factors_021_050
[0m15:27:20.313318 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m15:27:20.313690 [debug] [Thread-1 (]: Began running node model.quant_features.alpha_factors_051_075
[0m15:27:20.314857 [debug] [Thread-2 (]: On model.quant_features.daily_stock_summary: COMMIT
[0m15:27:20.315184 [debug] [Thread-4 (]: Began running node model.quant_features.alpha_factors_076_101
[0m15:27:20.315470 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: COMMIT
[0m15:27:20.315757 [info ] [Thread-1 (]: 9 of 15 SKIP relation main.alpha_factors_051_075 ............................... [[33mSKIP[0m]
[0m15:27:20.316060 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:20.316333 [info ] [Thread-4 (]: 10 of 15 SKIP relation main.alpha_factors_076_101 .............................. [[33mSKIP[0m]
[0m15:27:20.316795 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha_factors_051_075
[0m15:27:20.317127 [debug] [Thread-2 (]: On model.quant_features.daily_stock_summary: COMMIT
[0m15:27:20.317803 [debug] [Thread-4 (]: Finished running node model.quant_features.alpha_factors_076_101
[0m15:27:20.318057 [debug] [Thread-1 (]: Began running node model.quant_features.alpha_factors_advanced
[0m15:27:20.318459 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m15:27:20.319017 [info ] [Thread-1 (]: 11 of 15 SKIP relation main.alpha_factors_advanced ............................. [[33mSKIP[0m]
[0m15:27:20.319452 [debug] [Thread-4 (]: Began running node model.quant_features.alpha101_complete
[0m15:27:20.320924 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m15:27:20.321291 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m15:27:20.321860 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha_factors_advanced
[0m15:27:20.322284 [info ] [Thread-4 (]: 12 of 15 SKIP relation main.alpha101_complete .................................. [[33mSKIP[0m]
[0m15:27:20.322658 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */

      drop table if exists "quant_features"."main"."mart_technical_indicators__dbt_backup" cascade
    
[0m15:27:20.324516 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:20.325260 [debug] [Thread-4 (]: Finished running node model.quant_features.alpha101_complete
[0m15:27:20.325859 [debug] [Thread-1 (]: Began running node model.quant_features.alpha_factors_final
[0m15:27:20.326219 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m15:27:20.326723 [debug] [Thread-2 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */

      drop table if exists "quant_features"."main"."daily_stock_summary__dbt_backup" cascade
    
[0m15:27:20.327146 [info ] [Thread-1 (]: 13 of 15 SKIP relation main.alpha_factors_final ................................ [[33mSKIP[0m]
[0m15:27:20.328100 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: Close
[0m15:27:20.328711 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha_factors_final
[0m15:27:20.330150 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90c810b850>]}
[0m15:27:20.330515 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m15:27:20.330997 [info ] [Thread-3 (]: 5 of 15 OK created sql table model main.mart_technical_indicators .............. [[32mOK[0m in 0.09s]
[0m15:27:20.331963 [debug] [Thread-2 (]: On model.quant_features.daily_stock_summary: Close
[0m15:27:20.332460 [debug] [Thread-3 (]: Finished running node model.quant_features.mart_technical_indicators
[0m15:27:20.333022 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90ca44c3b0>]}
[0m15:27:20.333386 [debug] [Thread-4 (]: Began running node model.quant_features.features_ohlc_technical
[0m15:27:20.334039 [info ] [Thread-2 (]: 6 of 15 OK created sql table model main.daily_stock_summary .................... [[32mOK[0m in 0.07s]
[0m15:27:20.334494 [info ] [Thread-4 (]: 14 of 15 START sql table model main.features_ohlc_technical .................... [RUN]
[0m15:27:20.334878 [debug] [Thread-2 (]: Finished running node model.quant_features.daily_stock_summary
[0m15:27:20.335305 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.quant_features.alpha_base_data, now model.quant_features.features_ohlc_technical)
[0m15:27:20.335711 [debug] [Thread-4 (]: Began compiling node model.quant_features.features_ohlc_technical
[0m15:27:20.337847 [debug] [Thread-4 (]: Writing injected SQL for node "model.quant_features.features_ohlc_technical"
[0m15:27:20.338452 [debug] [Thread-1 (]: Began running node model.quant_features.stock_features
[0m15:27:20.338796 [debug] [Thread-4 (]: Began executing node model.quant_features.features_ohlc_technical
[0m15:27:20.339187 [info ] [Thread-1 (]: 15 of 15 START sql table model main.stock_features ............................. [RUN]
[0m15:27:20.341399 [debug] [Thread-4 (]: Writing runtime sql for node "model.quant_features.features_ohlc_technical"
[0m15:27:20.341988 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.quant_features.stg_market_data, now model.quant_features.stock_features)
[0m15:27:20.342427 [debug] [Thread-1 (]: Began compiling node model.quant_features.stock_features
[0m15:27:20.344388 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.stock_features"
[0m15:27:20.344790 [debug] [Thread-1 (]: Began executing node model.quant_features.stock_features
[0m15:27:20.346808 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.stock_features"
[0m15:27:20.347273 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:20.347650 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m15:27:20.347957 [debug] [Thread-1 (]: On model.quant_features.stock_features: BEGIN
[0m15:27:20.348260 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: BEGIN
[0m15:27:20.348794 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:27:20.349286 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m15:27:20.350071 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:27:20.350376 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:20.350661 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m15:27:20.351028 [debug] [Thread-1 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */

  
    
    

    create  table
      "quant_features"."main"."stock_features__dbt_tmp"
  
    as (
      

with daily_data as (
    select * from "quant_features"."main"."daily_stock_summary"
),

windowed_features as (
    select
        *,
        -- 移动平均
        avg(close) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as ma_5d,
        
        avg(close) over (
            partition by symbol 
            order by date 
            rows between 9 preceding and current row
        ) as ma_10d,
        
        -- 波动率（标准差）
        stddev(daily_return) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as volatility_5d,
        
        -- 价格相对位置
        (close - min(low) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        )) / (max(high) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) - min(low) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        )) as price_position_5d,
        
        -- 成交量相对强度
        volume / avg(volume) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as volume_ratio_5d
        
    from daily_data
),

final_features as (
    select
        *,
        -- 技术信号
        case 
            when close > ma_5d and ma_5d > ma_10d then 'Bullish'
            when close < ma_5d and ma_5d < ma_10d then 'Bearish'
            else 'Neutral'
        end as trend_signal,
        
        case 
            when volatility_5d > 0.03 then 'High'
            when volatility_5d > 0.01 then 'Medium'
            else 'Low'
        end as volatility_category
        
    from windowed_features
)

select * from final_features
    );
  
  
[0m15:27:20.351388 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m15:27:20.351927 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

  
    
    

    create  table
      "quant_features"."main"."features_ohlc_technical__dbt_tmp"
  
    as (
      

with technical_data as (
    select * from "quant_features"."main"."mart_technical_indicators"
),

feature_engineering as (
    select 
        symbol,
        timestamp,
        
        -- 基础价格特征
        close as price,
        daily_return,
        volatility_20d,
        
        -- 趋势特征
        ma_5,
        ma_10,
        ma_20,
        case when close > ma_5 then 1 else 0 end as price_above_ma5,
        case when close > ma_10 then 1 else 0 end as price_above_ma10,
        case when close > ma_20 then 1 else 0 end as price_above_ma20,
        case when ma_5 > ma_10 then 1 else 0 end as ma5_above_ma10,
        case when ma_10 > ma_20 then 1 else 0 end as ma10_above_ma20,
        
        -- 技术指标特征
        rsi_14,
        case when rsi_14 > 70 then 1 else 0 end as rsi_overbought,
        case when rsi_14 < 30 then 1 else 0 end as rsi_oversold,
        
        stoch_k_14,
        case when stoch_k_14 > 0.8 then 1 else 0 end as stoch_overbought,
        case when stoch_k_14 < 0.2 then 1 else 0 end as stoch_oversold,
        
        -- 布林带特征
        bollinger_upper,
        bollinger_lower,
        case when close > bollinger_upper then 1 else 0 end as price_above_bb_upper,
        case when close < bollinger_lower then 1 else 0 end as price_below_bb_lower,
        case 
            when bollinger_upper - bollinger_lower != 0 
            then (close - bollinger_lower) / (bollinger_upper - bollinger_lower)
            else 0.5
        end as bb_position,
        
        -- 动量特征
        momentum_5d,
        momentum_10d,
        case when momentum_5d > 0 then 1 else 0 end as momentum_5d_positive,
        case when momentum_10d > 0 then 1 else 0 end as momentum_10d_positive,
        
        -- 成交量特征
        volume,
        avg_volume_20d,
        case when avg_volume_20d != 0 then volume / avg_volume_20d else 0 end as volume_ratio,
        case when volume > avg_volume_20d * 1.5 then 1 else 0 end as high_volume,
        
        -- 价格范围特征
        daily_range,
        case when lag(close) over (partition by symbol order by timestamp) != 0 
            then daily_range / lag(close) over (partition by symbol order by timestamp)
            else 0
        end as range_ratio,
        
        -- 组合特征
        case when rsi_14 > 70 and stoch_k_14 > 0.8 then 1 else 0 end as double_overbought,
        case when rsi_14 < 30 and stoch_k_14 < 0.2 then 1 else 0 end as double_oversold,
        
        -- 时间特征
        extract(hour from timestamp) as hour,
        extract(dow from timestamp) as day_of_week,
        extract(month from timestamp) as month,
        
        -- 标识特征用于Feast
        concat(symbol, '_', date_trunc('day', timestamp)::string) as entity_id,
        timestamp as event_timestamp
        
    from technical_data
    where timestamp >= current_date - interval '20' days
)

select * from feature_engineering
    );
  
  
[0m15:27:20.355005 [debug] [Thread-4 (]: SQL status: OK in 0.003 seconds
[0m15:27:20.356799 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m15:27:20.357064 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */
alter table "quant_features"."main"."features_ohlc_technical__dbt_tmp" rename to "features_ohlc_technical"
[0m15:27:20.357612 [debug] [Thread-1 (]: SQL status: OK in 0.006 seconds
[0m15:27:20.359424 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:20.359727 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m15:27:20.360040 [debug] [Thread-1 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */
alter table "quant_features"."main"."stock_features" rename to "stock_features__dbt_backup"
[0m15:27:20.361008 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m15:27:20.361646 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m15:27:20.362000 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:27:20.362577 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m15:27:20.364673 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:20.365061 [debug] [Thread-1 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */
alter table "quant_features"."main"."stock_features__dbt_tmp" rename to "stock_features"
[0m15:27:20.365807 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:27:20.366840 [debug] [Thread-1 (]: On model.quant_features.stock_features: COMMIT
[0m15:27:20.367093 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:20.367358 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m15:27:20.367643 [debug] [Thread-1 (]: On model.quant_features.stock_features: COMMIT
[0m15:27:20.369025 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m15:27:20.369438 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

      drop table if exists "quant_features"."main"."features_ohlc_technical__dbt_backup" cascade
    
[0m15:27:20.371090 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m15:27:20.372742 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:20.373000 [debug] [Thread-1 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */

      drop table if exists "quant_features"."main"."stock_features__dbt_backup" cascade
    
[0m15:27:20.373440 [debug] [Thread-4 (]: SQL status: OK in 0.004 seconds
[0m15:27:20.374503 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: Close
[0m15:27:20.374821 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m15:27:20.376215 [debug] [Thread-1 (]: On model.quant_features.stock_features: Close
[0m15:27:20.376619 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90c9b15e50>]}
[0m15:27:20.377156 [info ] [Thread-4 (]: 14 of 15 OK created sql table model main.features_ohlc_technical ............... [[32mOK[0m in 0.04s]
[0m15:27:20.377497 [debug] [Thread-4 (]: Finished running node model.quant_features.features_ohlc_technical
[0m15:27:20.377937 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '546a7400-bea5-4d62-9693-c27be28811e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90c9b15c70>]}
[0m15:27:20.378542 [info ] [Thread-1 (]: 15 of 15 OK created sql table model main.stock_features ........................ [[32mOK[0m in 0.04s]
[0m15:27:20.378901 [debug] [Thread-1 (]: Finished running node model.quant_features.stock_features
[0m15:27:20.380396 [debug] [MainThread]: Using duckdb connection "master"
[0m15:27:20.380628 [debug] [MainThread]: On master: BEGIN
[0m15:27:20.380788 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:27:20.381147 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:27:20.381362 [debug] [MainThread]: On master: COMMIT
[0m15:27:20.381523 [debug] [MainThread]: Using duckdb connection "master"
[0m15:27:20.381671 [debug] [MainThread]: On master: COMMIT
[0m15:27:20.381951 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:27:20.382121 [debug] [MainThread]: On master: Close
[0m15:27:20.382403 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:27:20.382595 [debug] [MainThread]: Connection 'model.quant_features.stock_features' was properly closed.
[0m15:27:20.382741 [debug] [MainThread]: Connection 'model.quant_features.mart_technical_indicators' was properly closed.
[0m15:27:20.382876 [debug] [MainThread]: Connection 'model.quant_features.daily_stock_summary' was properly closed.
[0m15:27:20.383007 [debug] [MainThread]: Connection 'model.quant_features.features_ohlc_technical' was properly closed.
[0m15:27:20.383232 [info ] [MainThread]: 
[0m15:27:20.383431 [info ] [MainThread]: Finished running 12 table models, 3 view models in 0 hours 0 minutes and 0.32 seconds (0.32s).
[0m15:27:20.384370 [debug] [MainThread]: Command end result
[0m15:27:20.406455 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:27:20.407699 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:27:20.411628 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m15:27:20.411868 [info ] [MainThread]: 
[0m15:27:20.412075 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:27:20.412262 [info ] [MainThread]: 
[0m15:27:20.412490 [error] [MainThread]: [31mFailure in model alpha_base_data (models/alpha101/alpha_base_data.sql)[0m
[0m15:27:20.412707 [error] [MainThread]:   Runtime Error in model alpha_base_data (models/alpha101/alpha_base_data.sql)
  Binder Error: Could not choose a best candidate function for the function call "-(STRING_LITERAL, INTERVAL)". In order to select one, please add explicit type casts.
  	Candidate functions:
  	-(DATE, INTERVAL) -> TIMESTAMP
  	-(TIME, INTERVAL) -> TIME
  	-(TIMESTAMP, INTERVAL) -> TIMESTAMP
  	-(TIME WITH TIME ZONE, INTERVAL) -> TIME WITH TIME ZONE
  	-(TIMESTAMP WITH TIME ZONE, INTERVAL) -> TIMESTAMP WITH TIME ZONE
  	-(INTERVAL, INTERVAL) -> INTERVAL
  
  
  LINE 475:     WHERE timestamp >= '2020-01-01' - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数...
                                                ^
[0m15:27:20.412892 [info ] [MainThread]: 
[0m15:27:20.413082 [info ] [MainThread]:   compiled code at target/compiled/quant_features/models/alpha101/alpha_base_data.sql
[0m15:27:20.413249 [info ] [MainThread]: 
[0m15:27:20.413427 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=1 SKIP=7 NO-OP=0 TOTAL=15
[0m15:27:20.413977 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.0885947, "process_in_blocks": "0", "process_kernel_time": 0.156504, "process_mem_max_rss": "167864", "process_out_blocks": "5432", "process_user_time": 1.874127}
[0m15:27:20.414305 [debug] [MainThread]: Command `dbt run` failed at 15:27:20.414242 after 1.09 seconds
[0m15:27:20.414540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90ca4a3d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90cf6f1c70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f90c8fbe7b0>]}
[0m15:27:20.414757 [debug] [MainThread]: Flushing usage events
[0m15:27:20.471403 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:27:27.655178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c61697770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c62cf1a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c6050bd90>]}


============================== 15:27:27.658659 | 35d3798b-4af2-4e77-8cc6-1830e26e304e ==============================
[0m15:27:27.658659 [info ] [MainThread]: Running with dbt=1.10.9
[0m15:27:27.659033 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'printer_width': '80', 'static_parser': 'True', 'warn_error': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'fail_fast': 'False', 'debug': 'False', 'invocation_command': 'dbt run --select stg_stock_prices stg_market_data daily_stock_summary stock_features', 'use_colors': 'True', 'no_print': 'None', 'log_path': '/workspace/dbt_project/logs', 'empty': 'False', 'target_path': 'None', 'partial_parse': 'True', 'write_json': 'True', 'cache_selected_only': 'False', 'introspect': 'True', 'indirect_selection': 'eager', 'version_check': 'True', 'use_experimental_parser': 'False', 'log_format': 'default', 'log_cache_events': 'False', 'profiles_dir': '/workspace/dbt_project'}
[0m15:27:27.807454 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '35d3798b-4af2-4e77-8cc6-1830e26e304e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c61222650>]}
[0m15:27:27.849175 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '35d3798b-4af2-4e77-8cc6-1830e26e304e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c60606be0>]}
[0m15:27:27.850341 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m15:27:27.881040 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m15:27:27.971116 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:27:27.971371 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:27:28.008633 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '35d3798b-4af2-4e77-8cc6-1830e26e304e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c5ce1d450>]}
[0m15:27:28.081504 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:27:28.082808 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:27:28.093485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '35d3798b-4af2-4e77-8cc6-1830e26e304e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c5ce51220>]}
[0m15:27:28.093827 [info ] [MainThread]: Found 15 models, 2 seeds, 37 data tests, 1 source, 565 macros
[0m15:27:28.094036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35d3798b-4af2-4e77-8cc6-1830e26e304e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c5ce90130>]}
[0m15:27:28.095779 [info ] [MainThread]: 
[0m15:27:28.096053 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:27:28.096229 [info ] [MainThread]: 
[0m15:27:28.096612 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:27:28.099893 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m15:27:28.118373 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m15:27:28.118644 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m15:27:28.118838 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:27:28.131380 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m15:27:28.132287 [debug] [ThreadPool]: On list_quant_features: Close
[0m15:27:28.133213 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m15:27:28.133613 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m15:27:28.137921 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:27:28.138180 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m15:27:28.138372 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:27:28.139410 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m15:27:28.140246 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:27:28.140490 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m15:27:28.140805 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:27:28.140979 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:27:28.141133 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m15:27:28.141460 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:27:28.141991 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:27:28.142193 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m15:27:28.142365 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m15:27:28.142659 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:27:28.142829 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m15:27:28.144566 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m15:27:28.187382 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:27:28.187629 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m15:27:28.187791 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m15:27:28.188183 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m15:27:28.188392 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:27:28.188552 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m15:27:28.195138 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m15:27:28.196086 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m15:27:28.196762 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m15:27:28.196983 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m15:27:28.198925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '35d3798b-4af2-4e77-8cc6-1830e26e304e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c5b6069c0>]}
[0m15:27:28.199375 [debug] [MainThread]: Using duckdb connection "master"
[0m15:27:28.199575 [debug] [MainThread]: On master: BEGIN
[0m15:27:28.199728 [debug] [MainThread]: Opening a new connection, currently in state init
[0m15:27:28.200124 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:27:28.200323 [debug] [MainThread]: On master: COMMIT
[0m15:27:28.200494 [debug] [MainThread]: Using duckdb connection "master"
[0m15:27:28.200639 [debug] [MainThread]: On master: COMMIT
[0m15:27:28.200896 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:27:28.201076 [debug] [MainThread]: On master: Close
[0m15:27:28.203618 [debug] [Thread-1 (]: Began running node model.quant_features.stg_market_data
[0m15:27:28.204011 [debug] [Thread-2 (]: Began running node model.quant_features.stg_stock_prices
[0m15:27:28.204497 [info ] [Thread-1 (]: 1 of 4 START sql view model main.stg_market_data ............................... [RUN]
[0m15:27:28.205087 [info ] [Thread-2 (]: 2 of 4 START sql view model main.stg_stock_prices .............................. [RUN]
[0m15:27:28.205536 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.stg_market_data)
[0m15:27:28.206038 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.quant_features.stg_stock_prices'
[0m15:27:28.206439 [debug] [Thread-1 (]: Began compiling node model.quant_features.stg_market_data
[0m15:27:28.206803 [debug] [Thread-2 (]: Began compiling node model.quant_features.stg_stock_prices
[0m15:27:28.211653 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.stg_market_data"
[0m15:27:28.214027 [debug] [Thread-2 (]: Writing injected SQL for node "model.quant_features.stg_stock_prices"
[0m15:27:28.214682 [debug] [Thread-1 (]: Began executing node model.quant_features.stg_market_data
[0m15:27:28.221785 [debug] [Thread-2 (]: Began executing node model.quant_features.stg_stock_prices
[0m15:27:28.241421 [debug] [Thread-2 (]: Writing runtime sql for node "model.quant_features.stg_stock_prices"
[0m15:27:28.242505 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.stg_market_data"
[0m15:27:28.243321 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:28.243597 [debug] [Thread-2 (]: On model.quant_features.stg_stock_prices: BEGIN
[0m15:27:28.243788 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m15:27:28.244334 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:28.244630 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: BEGIN
[0m15:27:28.244820 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:27:28.245245 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m15:27:28.245480 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:28.245692 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_market_data"} */

  
  create view "quant_features"."main"."stg_market_data__dbt_tmp" as (
    

with source_data as (
    select
        date,
        symbol,
        market_cap,
        pe_ratio,
        dividend_yield,
        sector,
        -- 添加计算字段
        case 
            when pe_ratio > 0 then market_cap / pe_ratio 
            else null 
        end as estimated_earnings,
        case 
            when dividend_yield > 0 then market_cap * dividend_yield / 100 
            else 0 
        end as estimated_dividend_payout
    from "quant_features"."main"."market_data"
    where date is not null
      and symbol is not null
      and market_cap > 0
)

select * from source_data
  );

[0m15:27:28.246105 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m15:27:28.246421 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:28.246668 [debug] [Thread-2 (]: On model.quant_features.stg_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_stock_prices"} */

  
  create view "quant_features"."main"."stg_stock_prices__dbt_tmp" as (
    

with source_data as (
    select
        date,
        symbol,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础技术指标
        (high - low) as daily_range,
        (close - open) as daily_change,
        (close - open) / open as daily_return,
        -- 添加数据质量检查
        case 
            when high >= low and high >= open and high >= close 
                 and low <= open and low <= close 
            then true 
            else false 
        end as is_valid_ohlc
    from "quant_features"."main"."raw_stock_prices"
    where date is not null
      and symbol is not null
      and open > 0
      and high > 0
      and low > 0
      and close > 0
      and volume >= 0
)

select * from source_data
where is_valid_ohlc = true
  );

[0m15:27:28.246994 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m15:27:28.251156 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:28.251445 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_market_data"} */
alter view "quant_features"."main"."stg_market_data" rename to "stg_market_data__dbt_backup"
[0m15:27:28.251825 [debug] [Thread-2 (]: SQL status: OK in 0.004 seconds
[0m15:27:28.253739 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:28.254027 [debug] [Thread-2 (]: On model.quant_features.stg_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_stock_prices"} */
alter view "quant_features"."main"."stg_stock_prices" rename to "stg_stock_prices__dbt_backup"
[0m15:27:28.254451 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:27:28.256527 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:28.256794 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_market_data"} */
alter view "quant_features"."main"."stg_market_data__dbt_tmp" rename to "stg_market_data"
[0m15:27:28.257148 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m15:27:28.259034 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:28.259310 [debug] [Thread-2 (]: On model.quant_features.stg_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_stock_prices"} */
alter view "quant_features"."main"."stg_stock_prices__dbt_tmp" rename to "stg_stock_prices"
[0m15:27:28.259671 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m15:27:28.265179 [debug] [Thread-2 (]: SQL status: OK in 0.006 seconds
[0m15:27:28.269420 [debug] [Thread-2 (]: On model.quant_features.stg_stock_prices: COMMIT
[0m15:27:28.269725 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:28.270802 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: COMMIT
[0m15:27:28.271626 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:28.271271 [debug] [Thread-2 (]: On model.quant_features.stg_stock_prices: COMMIT
[0m15:27:28.271841 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: COMMIT
[0m15:27:28.274394 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m15:27:28.278002 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.stg_stock_prices"
[0m15:27:28.278283 [debug] [Thread-2 (]: On model.quant_features.stg_stock_prices: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_stock_prices"} */

      drop view if exists "quant_features"."main"."stg_stock_prices__dbt_backup" cascade
    
[0m15:27:28.278805 [debug] [Thread-1 (]: SQL status: OK in 0.006 seconds
[0m15:27:28.280855 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_market_data"
[0m15:27:28.281109 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_market_data"} */

      drop view if exists "quant_features"."main"."stg_market_data__dbt_backup" cascade
    
[0m15:27:28.281512 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m15:27:28.283145 [debug] [Thread-2 (]: On model.quant_features.stg_stock_prices: Close
[0m15:27:28.283611 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m15:27:28.284601 [debug] [Thread-1 (]: On model.quant_features.stg_market_data: Close
[0m15:27:28.285774 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d3798b-4af2-4e77-8cc6-1830e26e304e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c5b5dca10>]}
[0m15:27:28.286307 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d3798b-4af2-4e77-8cc6-1830e26e304e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c5c038f70>]}
[0m15:27:28.286857 [info ] [Thread-1 (]: 1 of 4 OK created sql view model main.stg_market_data .......................... [[32mOK[0m in 0.08s]
[0m15:27:28.287441 [info ] [Thread-2 (]: 2 of 4 OK created sql view model main.stg_stock_prices ......................... [[32mOK[0m in 0.08s]
[0m15:27:28.287864 [debug] [Thread-1 (]: Finished running node model.quant_features.stg_market_data
[0m15:27:28.288329 [debug] [Thread-2 (]: Finished running node model.quant_features.stg_stock_prices
[0m15:27:28.289934 [debug] [Thread-3 (]: Began running node model.quant_features.daily_stock_summary
[0m15:27:28.290335 [info ] [Thread-3 (]: 3 of 4 START sql table model main.daily_stock_summary .......................... [RUN]
[0m15:27:28.290693 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.quant_features.daily_stock_summary'
[0m15:27:28.290903 [debug] [Thread-3 (]: Began compiling node model.quant_features.daily_stock_summary
[0m15:27:28.293238 [debug] [Thread-3 (]: Writing injected SQL for node "model.quant_features.daily_stock_summary"
[0m15:27:28.293662 [debug] [Thread-3 (]: Began executing node model.quant_features.daily_stock_summary
[0m15:27:28.306130 [debug] [Thread-3 (]: Writing runtime sql for node "model.quant_features.daily_stock_summary"
[0m15:27:28.306594 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:28.306820 [debug] [Thread-3 (]: On model.quant_features.daily_stock_summary: BEGIN
[0m15:27:28.307008 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:27:28.307482 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m15:27:28.307708 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:28.307940 [debug] [Thread-3 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */

  
    
    

    create  table
      "quant_features"."main"."daily_stock_summary__dbt_tmp"
  
    as (
      

with price_data as (
    select * from "quant_features"."main"."stg_stock_prices"
),

market_data as (
    select * from "quant_features"."main"."stg_market_data"
),

combined_data as (
    select
        p.date,
        p.symbol,
        p.open,
        p.high,
        p.low,
        p.close,
        p.volume,
        p.daily_range,
        p.daily_change,
        p.daily_return,
        m.market_cap,
        m.pe_ratio,
        m.dividend_yield,
        m.sector,
        m.estimated_earnings,
        m.estimated_dividend_payout,
        -- 计算额外的技术指标
        (p.high + p.low + p.close) / 3 as typical_price,
        p.volume * p.close as dollar_volume,
        case 
            when p.daily_return > 0.05 then 'Strong Up'
            when p.daily_return > 0.02 then 'Up'
            when p.daily_return > -0.02 then 'Flat'
            when p.daily_return > -0.05 then 'Down'
            else 'Strong Down'
        end as price_movement_category
    from price_data p
    left join market_data m
        on p.date = m.date
        and p.symbol = m.symbol
)

select * from combined_data
    );
  
  
[0m15:27:28.311853 [debug] [Thread-3 (]: SQL status: OK in 0.004 seconds
[0m15:27:28.313678 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:28.313937 [debug] [Thread-3 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */
alter table "quant_features"."main"."daily_stock_summary" rename to "daily_stock_summary__dbt_backup"
[0m15:27:28.314421 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m15:27:28.316137 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:28.316406 [debug] [Thread-3 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */
alter table "quant_features"."main"."daily_stock_summary__dbt_tmp" rename to "daily_stock_summary"
[0m15:27:28.316855 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m15:27:28.319876 [debug] [Thread-3 (]: On model.quant_features.daily_stock_summary: COMMIT
[0m15:27:28.320152 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:28.320367 [debug] [Thread-3 (]: On model.quant_features.daily_stock_summary: COMMIT
[0m15:27:28.322823 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m15:27:28.329038 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:28.329418 [debug] [Thread-3 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */

      drop table if exists "quant_features"."main"."daily_stock_summary__dbt_backup" cascade
    
[0m15:27:28.331384 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m15:27:28.332473 [debug] [Thread-3 (]: On model.quant_features.daily_stock_summary: Close
[0m15:27:28.333078 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d3798b-4af2-4e77-8cc6-1830e26e304e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c5b5c8e10>]}
[0m15:27:28.333540 [info ] [Thread-3 (]: 3 of 4 OK created sql table model main.daily_stock_summary ..................... [[32mOK[0m in 0.04s]
[0m15:27:28.333869 [debug] [Thread-3 (]: Finished running node model.quant_features.daily_stock_summary
[0m15:27:28.334952 [debug] [Thread-4 (]: Began running node model.quant_features.stock_features
[0m15:27:28.335367 [info ] [Thread-4 (]: 4 of 4 START sql table model main.stock_features ............................... [RUN]
[0m15:27:28.335719 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.quant_features.stock_features'
[0m15:27:28.335932 [debug] [Thread-4 (]: Began compiling node model.quant_features.stock_features
[0m15:27:28.338160 [debug] [Thread-4 (]: Writing injected SQL for node "model.quant_features.stock_features"
[0m15:27:28.338600 [debug] [Thread-4 (]: Began executing node model.quant_features.stock_features
[0m15:27:28.340771 [debug] [Thread-4 (]: Writing runtime sql for node "model.quant_features.stock_features"
[0m15:27:28.341205 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:28.341427 [debug] [Thread-4 (]: On model.quant_features.stock_features: BEGIN
[0m15:27:28.341616 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m15:27:28.342074 [debug] [Thread-4 (]: SQL status: OK in 0.000 seconds
[0m15:27:28.342289 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:28.342542 [debug] [Thread-4 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */

  
    
    

    create  table
      "quant_features"."main"."stock_features__dbt_tmp"
  
    as (
      

with daily_data as (
    select * from "quant_features"."main"."daily_stock_summary"
),

windowed_features as (
    select
        *,
        -- 移动平均
        avg(close) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as ma_5d,
        
        avg(close) over (
            partition by symbol 
            order by date 
            rows between 9 preceding and current row
        ) as ma_10d,
        
        -- 波动率（标准差）
        stddev(daily_return) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as volatility_5d,
        
        -- 价格相对位置
        (close - min(low) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        )) / (max(high) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) - min(low) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        )) as price_position_5d,
        
        -- 成交量相对强度
        volume / avg(volume) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as volume_ratio_5d
        
    from daily_data
),

final_features as (
    select
        *,
        -- 技术信号
        case 
            when close > ma_5d and ma_5d > ma_10d then 'Bullish'
            when close < ma_5d and ma_5d < ma_10d then 'Bearish'
            else 'Neutral'
        end as trend_signal,
        
        case 
            when volatility_5d > 0.03 then 'High'
            when volatility_5d > 0.01 then 'Medium'
            else 'Low'
        end as volatility_category
        
    from windowed_features
)

select * from final_features
    );
  
  
[0m15:27:28.349216 [debug] [Thread-4 (]: SQL status: OK in 0.006 seconds
[0m15:27:28.350948 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:28.351211 [debug] [Thread-4 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */
alter table "quant_features"."main"."stock_features" rename to "stock_features__dbt_backup"
[0m15:27:28.351722 [debug] [Thread-4 (]: SQL status: OK in 0.000 seconds
[0m15:27:28.353725 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:28.353989 [debug] [Thread-4 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */
alter table "quant_features"."main"."stock_features__dbt_tmp" rename to "stock_features"
[0m15:27:28.354474 [debug] [Thread-4 (]: SQL status: OK in 0.000 seconds
[0m15:27:28.355429 [debug] [Thread-4 (]: On model.quant_features.stock_features: COMMIT
[0m15:27:28.355688 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:28.355884 [debug] [Thread-4 (]: On model.quant_features.stock_features: COMMIT
[0m15:27:28.357792 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m15:27:28.359163 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:28.359439 [debug] [Thread-4 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */

      drop table if exists "quant_features"."main"."stock_features__dbt_backup" cascade
    
[0m15:27:28.361377 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m15:27:28.362271 [debug] [Thread-4 (]: On model.quant_features.stock_features: Close
[0m15:27:28.363016 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '35d3798b-4af2-4e77-8cc6-1830e26e304e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c5b6f1950>]}
[0m15:27:28.363418 [info ] [Thread-4 (]: 4 of 4 OK created sql table model main.stock_features .......................... [[32mOK[0m in 0.03s]
[0m15:27:28.363731 [debug] [Thread-4 (]: Finished running node model.quant_features.stock_features
[0m15:27:28.365457 [debug] [MainThread]: Using duckdb connection "master"
[0m15:27:28.365710 [debug] [MainThread]: On master: BEGIN
[0m15:27:28.365876 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m15:27:28.366270 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:27:28.366469 [debug] [MainThread]: On master: COMMIT
[0m15:27:28.366627 [debug] [MainThread]: Using duckdb connection "master"
[0m15:27:28.366772 [debug] [MainThread]: On master: COMMIT
[0m15:27:28.367044 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m15:27:28.367234 [debug] [MainThread]: On master: Close
[0m15:27:28.367524 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:27:28.367689 [debug] [MainThread]: Connection 'model.quant_features.stg_market_data' was properly closed.
[0m15:27:28.367829 [debug] [MainThread]: Connection 'model.quant_features.stg_stock_prices' was properly closed.
[0m15:27:28.367965 [debug] [MainThread]: Connection 'model.quant_features.daily_stock_summary' was properly closed.
[0m15:27:28.368097 [debug] [MainThread]: Connection 'model.quant_features.stock_features' was properly closed.
[0m15:27:28.368330 [info ] [MainThread]: 
[0m15:27:28.368554 [info ] [MainThread]: Finished running 2 table models, 2 view models in 0 hours 0 minutes and 0.27 seconds (0.27s).
[0m15:27:28.369144 [debug] [MainThread]: Command end result
[0m15:27:28.392246 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:27:28.393666 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:27:28.397779 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m15:27:28.398020 [info ] [MainThread]: 
[0m15:27:28.398251 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:27:28.398440 [info ] [MainThread]: 
[0m15:27:28.398637 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m15:27:28.399287 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.7865642, "process_in_blocks": "0", "process_kernel_time": 0.139911, "process_mem_max_rss": "158996", "process_out_blocks": "3664", "process_user_time": 1.542903}
[0m15:27:28.399617 [debug] [MainThread]: Command `dbt run` succeeded at 15:27:28.399551 after 0.79 seconds
[0m15:27:28.399843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c60531da0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c6472d400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0c6070b650>]}
[0m15:27:28.400054 [debug] [MainThread]: Flushing usage events
[0m15:27:28.456351 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:27:34.598249 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa910623770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa911c75a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa90f493d90>]}


============================== 15:27:34.600755 | 739055df-1b17-40a3-9538-a0b06eaafc9b ==============================
[0m15:27:34.600755 [info ] [MainThread]: Running with dbt=1.10.9
[0m15:27:34.601093 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt show --select stock_features --limit 10', 'introspect': 'True', 'use_experimental_parser': 'False', 'write_json': 'True', 'log_format': 'default', 'log_path': '/workspace/dbt_project/logs', 'profiles_dir': '/workspace/dbt_project', 'no_print': 'None', 'log_cache_events': 'False', 'static_parser': 'True', 'indirect_selection': 'eager', 'use_colors': 'True', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'cache_selected_only': 'False', 'partial_parse': 'True', 'version_check': 'True', 'printer_width': '80', 'fail_fast': 'False', 'target_path': 'None', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'empty': 'None', 'quiet': 'False'}
[0m15:27:34.751053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '739055df-1b17-40a3-9538-a0b06eaafc9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa9101ae650>]}
[0m15:27:34.792715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '739055df-1b17-40a3-9538-a0b06eaafc9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa90f592be0>]}
[0m15:27:34.801424 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m15:27:34.832332 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m15:27:34.921788 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:27:34.922032 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:27:34.959036 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '739055df-1b17-40a3-9538-a0b06eaafc9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa90b3d5650>]}
[0m15:27:35.032448 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:27:35.033708 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:27:35.038511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '739055df-1b17-40a3-9538-a0b06eaafc9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa90b3c1310>]}
[0m15:27:35.038863 [info ] [MainThread]: Found 15 models, 2 seeds, 37 data tests, 1 source, 565 macros
[0m15:27:35.039074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '739055df-1b17-40a3-9538-a0b06eaafc9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa90b44c590>]}
[0m15:27:35.040381 [info ] [MainThread]: 
[0m15:27:35.040667 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:27:35.040842 [info ] [MainThread]: 
[0m15:27:35.041145 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:27:35.044800 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features_main'
[0m15:27:35.095974 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:27:35.096231 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m15:27:35.096423 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:27:35.109649 [debug] [ThreadPool]: SQL status: OK in 0.013 seconds
[0m15:27:35.109907 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:27:35.110092 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m15:27:35.118306 [debug] [ThreadPool]: SQL status: OK in 0.008 seconds
[0m15:27:35.119308 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m15:27:35.119961 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m15:27:35.120192 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m15:27:35.122090 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '739055df-1b17-40a3-9538-a0b06eaafc9b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa90aff0ae0>]}
[0m15:27:35.124428 [debug] [Thread-1 (]: Began running node model.quant_features.stock_features
[0m15:27:35.124773 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.stock_features)
[0m15:27:35.124987 [debug] [Thread-1 (]: Began compiling node model.quant_features.stock_features
[0m15:27:35.129774 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.stock_features"
[0m15:27:35.130231 [debug] [Thread-1 (]: Began executing node model.quant_features.stock_features
[0m15:27:35.134742 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stock_features"
[0m15:27:35.135090 [debug] [Thread-1 (]: On model.quant_features.stock_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stock_features"} */

  
  

with daily_data as (
    select * from "quant_features"."main"."daily_stock_summary"
),

windowed_features as (
    select
        *,
        -- 移动平均
        avg(close) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as ma_5d,
        
        avg(close) over (
            partition by symbol 
            order by date 
            rows between 9 preceding and current row
        ) as ma_10d,
        
        -- 波动率（标准差）
        stddev(daily_return) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as volatility_5d,
        
        -- 价格相对位置
        (close - min(low) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        )) / (max(high) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) - min(low) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        )) as price_position_5d,
        
        -- 成交量相对强度
        volume / avg(volume) over (
            partition by symbol 
            order by date 
            rows between 4 preceding and current row
        ) as volume_ratio_5d
        
    from daily_data
),

final_features as (
    select
        *,
        -- 技术信号
        case 
            when close > ma_5d and ma_5d > ma_10d then 'Bullish'
            when close < ma_5d and ma_5d < ma_10d then 'Bearish'
            else 'Neutral'
        end as trend_signal,
        
        case 
            when volatility_5d > 0.03 then 'High'
            when volatility_5d > 0.01 then 'Medium'
            else 'Low'
        end as volatility_category
        
    from windowed_features
)

select * from final_features
  
  limit 10

[0m15:27:35.135372 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:27:35.140681 [debug] [Thread-1 (]: SQL status: OK in 0.005 seconds
[0m15:27:35.143092 [debug] [Thread-1 (]: On model.quant_features.stock_features: Close
[0m15:27:35.143865 [debug] [Thread-1 (]: Finished running node model.quant_features.stock_features
[0m15:27:35.145382 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:27:35.145646 [debug] [MainThread]: Connection 'model.quant_features.stock_features' was properly closed.
[0m15:27:35.146063 [debug] [MainThread]: Command end result
[0m15:27:35.168502 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:27:35.169723 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:27:35.173962 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m15:27:35.175024 [info ] [MainThread]: Previewing node 'stock_features':
|       date | symbol |    open |    high |     low |   close | ... |
| ---------- | ------ | ------- | ------- | ------- | ------- | --- |
| 2024-01-01 | GOOGL  | 2,800.0 | 2,850.0 | 2,780.0 | 2,820.0 | ... |
| 2024-01-02 | GOOGL  | 2,820.0 | 2,870.0 | 2,810.0 | 2,845.0 | ... |
| 2024-01-01 | MSFT   |   380.0 |   385.0 |   378.0 |   382.5 | ... |
| 2024-01-02 | MSFT   |   382.5 |   387.0 |   380.5 |   384.2 | ... |
| 2024-01-03 | MSFT   |   384.2 |   389.0 |   382.8 |   386.7 | ... |
| 2024-01-04 | MSFT   |   386.7 |   391.5 |   385.2 |   388.9 | ... |
| 2024-01-05 | MSFT   |   388.9 |   393.0 |   387.4 |   390.8 | ... |
| 2024-01-08 | MSFT   |   390.8 |   395.2 |   389.5 |   392.6 | ... |
| 2024-01-09 | MSFT   |   392.6 |   397.0 |   391.2 |   394.4 | ... |
| 2024-01-10 | MSFT   |   394.4 |   399.0 |   393.1 |   396.2 | ... |

[0m15:27:35.175668 [debug] [MainThread]: Resource report: {"command_name": "show", "command_success": true, "command_wall_clock_time": 0.61442894, "process_in_blocks": "0", "process_kernel_time": 0.18255, "process_mem_max_rss": "153040", "process_out_blocks": "3456", "process_user_time": 1.34534}
[0m15:27:35.175973 [debug] [MainThread]: Command `dbt show` succeeded at 15:27:35.175911 after 0.61 seconds
[0m15:27:35.176174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa90f82f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa90b179390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa90b179440>]}
[0m15:27:35.176387 [debug] [MainThread]: Flushing usage events
[0m15:27:35.241632 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m15:27:40.918204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7eca53770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7ee085a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7eb8c7d90>]}


============================== 15:27:40.920538 | d014ec97-0aed-4f57-a9bc-2341530ab41c ==============================
[0m15:27:40.920538 [info ] [MainThread]: Running with dbt=1.10.9
[0m15:27:40.920875 [debug] [MainThread]: running dbt with arguments {'indirect_selection': 'eager', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'version_check': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'empty': 'None', 'target_path': 'None', 'log_cache_events': 'False', 'no_print': 'None', 'introspect': 'True', 'static_parser': 'True', 'debug': 'False', 'quiet': 'False', 'printer_width': '80', 'invocation_command': 'dbt show --select daily_stock_summary --limit 5', 'fail_fast': 'False', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'log_path': '/workspace/dbt_project/logs', 'log_format': 'default', 'warn_error': 'None', 'use_experimental_parser': 'False', 'profiles_dir': '/workspace/dbt_project'}
[0m15:27:41.059488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd014ec97-0aed-4f57-a9bc-2341530ab41c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7ec5de650>]}
[0m15:27:41.100541 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd014ec97-0aed-4f57-a9bc-2341530ab41c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7eb9c2be0>]}
[0m15:27:41.108482 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m15:27:41.137560 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m15:27:41.224187 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:27:41.224441 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:27:41.261069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd014ec97-0aed-4f57-a9bc-2341530ab41c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7e77e1650>]}
[0m15:27:41.330199 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:27:41.331399 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:27:41.335551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd014ec97-0aed-4f57-a9bc-2341530ab41c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7e77d1310>]}
[0m15:27:41.335911 [info ] [MainThread]: Found 15 models, 2 seeds, 37 data tests, 1 source, 565 macros
[0m15:27:41.336137 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd014ec97-0aed-4f57-a9bc-2341530ab41c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7e7858590>]}
[0m15:27:41.337339 [info ] [MainThread]: 
[0m15:27:41.337610 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m15:27:41.337781 [info ] [MainThread]: 
[0m15:27:41.338065 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m15:27:41.341747 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features_main'
[0m15:27:41.388026 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:27:41.388281 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m15:27:41.388505 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:27:41.398849 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m15:27:41.399103 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m15:27:41.399279 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m15:27:41.406214 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m15:27:41.407185 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m15:27:41.407800 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m15:27:41.408013 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m15:27:41.409612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd014ec97-0aed-4f57-a9bc-2341530ab41c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7e73fcae0>]}
[0m15:27:41.412005 [debug] [Thread-1 (]: Began running node model.quant_features.daily_stock_summary
[0m15:27:41.412392 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.daily_stock_summary)
[0m15:27:41.412626 [debug] [Thread-1 (]: Began compiling node model.quant_features.daily_stock_summary
[0m15:27:41.417513 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.daily_stock_summary"
[0m15:27:41.417971 [debug] [Thread-1 (]: Began executing node model.quant_features.daily_stock_summary
[0m15:27:41.422689 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.daily_stock_summary"
[0m15:27:41.423002 [debug] [Thread-1 (]: On model.quant_features.daily_stock_summary: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.daily_stock_summary"} */

  
  

with price_data as (
    select * from "quant_features"."main"."stg_stock_prices"
),

market_data as (
    select * from "quant_features"."main"."stg_market_data"
),

combined_data as (
    select
        p.date,
        p.symbol,
        p.open,
        p.high,
        p.low,
        p.close,
        p.volume,
        p.daily_range,
        p.daily_change,
        p.daily_return,
        m.market_cap,
        m.pe_ratio,
        m.dividend_yield,
        m.sector,
        m.estimated_earnings,
        m.estimated_dividend_payout,
        -- 计算额外的技术指标
        (p.high + p.low + p.close) / 3 as typical_price,
        p.volume * p.close as dollar_volume,
        case 
            when p.daily_return > 0.05 then 'Strong Up'
            when p.daily_return > 0.02 then 'Up'
            when p.daily_return > -0.02 then 'Flat'
            when p.daily_return > -0.05 then 'Down'
            else 'Strong Down'
        end as price_movement_category
    from price_data p
    left join market_data m
        on p.date = m.date
        and p.symbol = m.symbol
)

select * from combined_data
  
  limit 5

[0m15:27:41.423239 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m15:27:41.427320 [debug] [Thread-1 (]: SQL status: OK in 0.004 seconds
[0m15:27:41.429291 [debug] [Thread-1 (]: On model.quant_features.daily_stock_summary: Close
[0m15:27:41.429930 [debug] [Thread-1 (]: Finished running node model.quant_features.daily_stock_summary
[0m15:27:41.431177 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:27:41.431420 [debug] [MainThread]: Connection 'model.quant_features.daily_stock_summary' was properly closed.
[0m15:27:41.431849 [debug] [MainThread]: Command end result
[0m15:27:41.453245 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m15:27:41.454412 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m15:27:41.458584 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m15:27:41.459357 [info ] [MainThread]: Previewing node 'daily_stock_summary':
|       date | symbol |  open |  high |   low | close | ... |
| ---------- | ------ | ----- | ----- | ----- | ----- | --- |
| 2024-01-01 | AAPL   | 150.0 | 152.5 | 149.8 | 151.2 | ... |
| 2024-01-02 | AAPL   | 151.2 | 153.0 | 150.5 | 152.8 | ... |
| 2024-01-03 | AAPL   | 152.8 | 154.2 | 151.9 | 153.5 | ... |
| 2024-01-04 | AAPL   | 153.5 | 155.0 | 152.8 | 154.3 | ... |
| 2024-01-05 | AAPL   | 154.3 | 156.2 | 153.5 | 155.8 | ... |

[0m15:27:41.459957 [debug] [MainThread]: Resource report: {"command_name": "show", "command_success": true, "command_wall_clock_time": 0.5773786, "process_in_blocks": "0", "process_kernel_time": 0.124516, "process_mem_max_rss": "150792", "process_out_blocks": "3448", "process_user_time": 1.32949}
[0m15:27:41.460248 [debug] [MainThread]: Command `dbt show` succeeded at 15:27:41.460191 after 0.58 seconds
[0m15:27:41.460465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7eba63110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7e753d390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc7e753d440>]}
[0m15:27:41.460692 [debug] [MainThread]: Flushing usage events
[0m15:27:41.483239 [debug] [MainThread]: An error was encountered while trying to flush usage events
