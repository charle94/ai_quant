[0m17:54:37.878597 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f22605d3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2261bf1a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f225f44fd90>]}


============================== 17:54:37.881047 | bd20b1ab-121e-439a-aca3-20f8c14f4a3a ==============================
[0m17:54:37.881047 [info ] [MainThread]: Running with dbt=1.10.9
[0m17:54:37.881393 [debug] [MainThread]: running dbt with arguments {'write_json': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'printer_width': '80', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'target_path': 'None', 'version_check': 'True', 'log_path': '/workspace/dbt_project/logs', 'partial_parse': 'True', 'invocation_command': 'dbt debug', 'quiet': 'False', 'cache_selected_only': 'False', 'fail_fast': 'False', 'profiles_dir': '/workspace/dbt_project', 'empty': 'None', 'use_colors': 'True', 'warn_error': 'None', 'send_anonymous_usage_stats': 'True', 'debug': 'False', 'indirect_selection': 'eager', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'log_cache_events': 'False'}
[0m17:54:37.889836 [info ] [MainThread]: dbt version: 1.10.9
[0m17:54:37.890119 [info ] [MainThread]: python version: 3.13.3
[0m17:54:37.890306 [info ] [MainThread]: python path: /workspace/venv/bin/python3
[0m17:54:37.890461 [info ] [MainThread]: os info: Linux-6.1.147-x86_64-with-glibc2.41
[0m17:54:37.951331 [info ] [MainThread]: Using profiles dir at /workspace/dbt_project
[0m17:54:37.951606 [info ] [MainThread]: Using profiles.yml file at /workspace/dbt_project/profiles.yml
[0m17:54:37.951788 [info ] [MainThread]: Using dbt_project.yml file at /workspace/dbt_project/dbt_project.yml
[0m17:54:37.952544 [info ] [MainThread]: adapter type: duckdb
[0m17:54:37.952747 [info ] [MainThread]: adapter version: 1.9.4
[0m17:54:38.021976 [info ] [MainThread]: Configuration:
[0m17:54:38.022250 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m17:54:38.022426 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m17:54:38.022597 [info ] [MainThread]: Required dependencies:
[0m17:54:38.022776 [debug] [MainThread]: Executing "git --help"
[0m17:54:38.024917 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:54:38.025246 [debug] [MainThread]: STDERR: "b''"
[0m17:54:38.025432 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m17:54:38.025602 [info ] [MainThread]: Connection:
[0m17:54:38.025763 [info ] [MainThread]:   database: quant_features
[0m17:54:38.025926 [info ] [MainThread]:   schema: main
[0m17:54:38.026077 [info ] [MainThread]:   path: /workspace/data/quant_features.duckdb
[0m17:54:38.026237 [info ] [MainThread]:   config_options: None
[0m17:54:38.026384 [info ] [MainThread]:   extensions: None
[0m17:54:38.026526 [info ] [MainThread]:   settings: {}
[0m17:54:38.026666 [info ] [MainThread]:   external_root: .
[0m17:54:38.026809 [info ] [MainThread]:   use_credential_provider: None
[0m17:54:38.026947 [info ] [MainThread]:   attach: None
[0m17:54:38.027086 [info ] [MainThread]:   filesystems: None
[0m17:54:38.027230 [info ] [MainThread]:   remote: None
[0m17:54:38.027389 [info ] [MainThread]:   plugins: None
[0m17:54:38.027540 [info ] [MainThread]:   disable_transactions: False
[0m17:54:38.027793 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m17:54:38.053316 [debug] [MainThread]: Acquiring new duckdb connection 'debug'
[0m17:54:38.060974 [debug] [MainThread]: Using duckdb connection "debug"
[0m17:54:38.061217 [debug] [MainThread]: On debug: select 1 as id
[0m17:54:38.061406 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:54:38.065709 [debug] [MainThread]: DuckDB adapter: Error running SQL: select 1 as id
[0m17:54:38.065982 [debug] [MainThread]: DuckDB adapter: Rolling back transaction.
[0m17:54:38.066214 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m17:54:38.066422 [info ] [MainThread]: [31m1 check failed:[0m
[0m17:54:38.066589 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Runtime Error
  IO Error: Cannot open file "/workspace/data/quant_features.duckdb": No such file or directory

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m17:54:38.067134 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.2255174, "process_in_blocks": "0", "process_kernel_time": 0.115865, "process_mem_max_rss": "132388", "process_out_blocks": "24", "process_user_time": 0.998894}
[0m17:54:38.067415 [debug] [MainThread]: Command `dbt debug` failed at 17:54:38.067358 after 0.23 seconds
[0m17:54:38.067605 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m17:54:38.067788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f225b1b8fc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f225bd1fbf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f225f3da030>]}
[0m17:54:38.068002 [debug] [MainThread]: Flushing usage events
[0m17:54:46.676507 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:54:57.447852 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f066f917770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0670f61a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f066e78bd90>]}


============================== 17:54:57.450506 | 077804f8-9435-450a-8e39-2643e159430b ==============================
[0m17:54:57.450506 [info ] [MainThread]: Running with dbt=1.10.9
[0m17:54:57.450856 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'printer_width': '80', 'version_check': 'True', 'log_format': 'default', 'static_parser': 'True', 'warn_error': 'None', 'profiles_dir': '/workspace/dbt_project', 'invocation_command': 'dbt debug', 'partial_parse': 'True', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'empty': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'quiet': 'False', 'target_path': 'None', 'write_json': 'True', 'use_experimental_parser': 'False', 'log_path': '/workspace/dbt_project/logs', 'introspect': 'True', 'no_print': 'None', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'fail_fast': 'False', 'debug': 'False'}
[0m17:54:57.459488 [info ] [MainThread]: dbt version: 1.10.9
[0m17:54:57.459750 [info ] [MainThread]: python version: 3.13.3
[0m17:54:57.459917 [info ] [MainThread]: python path: /workspace/venv/bin/python3
[0m17:54:57.460074 [info ] [MainThread]: os info: Linux-6.1.147-x86_64-with-glibc2.41
[0m17:54:57.522277 [info ] [MainThread]: Using profiles dir at /workspace/dbt_project
[0m17:54:57.522550 [info ] [MainThread]: Using profiles.yml file at /workspace/dbt_project/profiles.yml
[0m17:54:57.522726 [info ] [MainThread]: Using dbt_project.yml file at /workspace/dbt_project/dbt_project.yml
[0m17:54:57.523519 [info ] [MainThread]: adapter type: duckdb
[0m17:54:57.523731 [info ] [MainThread]: adapter version: 1.9.4
[0m17:54:57.591415 [info ] [MainThread]: Configuration:
[0m17:54:57.591676 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m17:54:57.591844 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m17:54:57.592000 [info ] [MainThread]: Required dependencies:
[0m17:54:57.592174 [debug] [MainThread]: Executing "git --help"
[0m17:54:57.594129 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:54:57.594602 [debug] [MainThread]: STDERR: "b''"
[0m17:54:57.594804 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m17:54:57.595005 [info ] [MainThread]: Connection:
[0m17:54:57.595187 [info ] [MainThread]:   database: quant_features
[0m17:54:57.595382 [info ] [MainThread]:   schema: main
[0m17:54:57.595541 [info ] [MainThread]:   path: /workspace/data/quant_features.duckdb
[0m17:54:57.595690 [info ] [MainThread]:   config_options: None
[0m17:54:57.595835 [info ] [MainThread]:   extensions: None
[0m17:54:57.595983 [info ] [MainThread]:   settings: {}
[0m17:54:57.596124 [info ] [MainThread]:   external_root: .
[0m17:54:57.596275 [info ] [MainThread]:   use_credential_provider: None
[0m17:54:57.596414 [info ] [MainThread]:   attach: None
[0m17:54:57.596551 [info ] [MainThread]:   filesystems: None
[0m17:54:57.596691 [info ] [MainThread]:   remote: None
[0m17:54:57.596832 [info ] [MainThread]:   plugins: None
[0m17:54:57.596967 [info ] [MainThread]:   disable_transactions: False
[0m17:54:57.597296 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m17:54:57.625950 [debug] [MainThread]: Acquiring new duckdb connection 'debug'
[0m17:54:57.635387 [debug] [MainThread]: Using duckdb connection "debug"
[0m17:54:57.635676 [debug] [MainThread]: On debug: select 1 as id
[0m17:54:57.635857 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:54:57.641278 [debug] [MainThread]: DuckDB adapter: Error running SQL: select 1 as id
[0m17:54:57.641540 [debug] [MainThread]: DuckDB adapter: Rolling back transaction.
[0m17:54:57.641762 [info ] [MainThread]:   Connection test: [[31mERROR[0m]

[0m17:54:57.641976 [info ] [MainThread]: [31m1 check failed:[0m
[0m17:54:57.642137 [info ] [MainThread]: dbt was unable to connect to the specified database.
The database returned the following error:

  >Runtime Error
  IO Error: The file "/workspace/data/quant_features.duckdb" exists, but it is not a valid DuckDB database file!

Check your database credentials and try again. For more information, visit:
https://docs.getdbt.com/docs/configure-your-profile


[0m17:54:57.642806 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": false, "command_wall_clock_time": 0.23163821, "process_in_blocks": "0", "process_kernel_time": 0.103739, "process_mem_max_rss": "131340", "process_out_blocks": "16", "process_user_time": 1.025405}
[0m17:54:57.643158 [debug] [MainThread]: Command `dbt debug` failed at 17:54:57.643091 after 0.23 seconds
[0m17:54:57.643381 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m17:54:57.643598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f066a4a8fc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f066a7e7bf0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f066e716030>]}
[0m17:54:57.643874 [debug] [MainThread]: Flushing usage events
[0m17:54:58.126837 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:55:13.825158 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0662523770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0663b79a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0661393d90>]}


============================== 17:55:13.827806 | 2ef93252-a074-4fee-ad92-6536394c3f26 ==============================
[0m17:55:13.827806 [info ] [MainThread]: Running with dbt=1.10.9
[0m17:55:13.828180 [debug] [MainThread]: running dbt with arguments {'cache_selected_only': 'False', 'invocation_command': 'dbt debug', 'version_check': 'True', 'empty': 'None', 'send_anonymous_usage_stats': 'True', 'static_parser': 'True', 'log_path': '/workspace/dbt_project/logs', 'quiet': 'False', 'fail_fast': 'False', 'log_format': 'default', 'log_cache_events': 'False', 'target_path': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'no_print': 'None', 'warn_error': 'None', 'partial_parse': 'True', 'debug': 'False', 'indirect_selection': 'eager', 'profiles_dir': '/workspace/dbt_project', 'introspect': 'True', 'write_json': 'True', 'printer_width': '80'}
[0m17:55:13.837454 [info ] [MainThread]: dbt version: 1.10.9
[0m17:55:13.837730 [info ] [MainThread]: python version: 3.13.3
[0m17:55:13.837909 [info ] [MainThread]: python path: /workspace/venv/bin/python3
[0m17:55:13.838070 [info ] [MainThread]: os info: Linux-6.1.147-x86_64-with-glibc2.41
[0m17:55:13.905780 [info ] [MainThread]: Using profiles dir at /workspace/dbt_project
[0m17:55:13.906069 [info ] [MainThread]: Using profiles.yml file at /workspace/dbt_project/profiles.yml
[0m17:55:13.906245 [info ] [MainThread]: Using dbt_project.yml file at /workspace/dbt_project/dbt_project.yml
[0m17:55:13.907057 [info ] [MainThread]: adapter type: duckdb
[0m17:55:13.907300 [info ] [MainThread]: adapter version: 1.9.4
[0m17:55:13.974829 [info ] [MainThread]: Configuration:
[0m17:55:13.975091 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m17:55:13.975271 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m17:55:13.975426 [info ] [MainThread]: Required dependencies:
[0m17:55:13.975605 [debug] [MainThread]: Executing "git --help"
[0m17:55:13.977011 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone     Clone a repository into a new directory\n   init      Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add       Add file contents to the index\n   mv        Move or rename a file, a directory, or a symlink\n   restore   Restore working tree files\n   rm        Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect    Use binary search to find the commit that introduced a bug\n   diff      Show changes between commits, commit and working tree, etc\n   grep      Print lines matching a pattern\n   log       Show commit logs\n   show      Show various types of objects\n   status    Show the working tree status\n\ngrow, mark and tweak your common history\n   branch    List, create, or delete branches\n   commit    Record changes to the repository\n   merge     Join two or more development histories together\n   rebase    Reapply commits on top of another base tip\n   reset     Reset current HEAD to the specified state\n   switch    Switch branches\n   tag       Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch     Download objects and refs from another repository\n   pull      Fetch from and integrate with another repository or a local branch\n   push      Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m17:55:13.977328 [debug] [MainThread]: STDERR: "b''"
[0m17:55:13.977507 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m17:55:13.977677 [info ] [MainThread]: Connection:
[0m17:55:13.977847 [info ] [MainThread]:   database: quant_features
[0m17:55:13.978009 [info ] [MainThread]:   schema: main
[0m17:55:13.978151 [info ] [MainThread]:   path: /workspace/data/quant_features.duckdb
[0m17:55:13.978303 [info ] [MainThread]:   config_options: None
[0m17:55:13.978445 [info ] [MainThread]:   extensions: None
[0m17:55:13.978583 [info ] [MainThread]:   settings: {}
[0m17:55:13.978717 [info ] [MainThread]:   external_root: .
[0m17:55:13.978850 [info ] [MainThread]:   use_credential_provider: None
[0m17:55:13.978986 [info ] [MainThread]:   attach: None
[0m17:55:13.979124 [info ] [MainThread]:   filesystems: None
[0m17:55:13.979270 [info ] [MainThread]:   remote: None
[0m17:55:13.979408 [info ] [MainThread]:   plugins: None
[0m17:55:13.979545 [info ] [MainThread]:   disable_transactions: False
[0m17:55:13.979790 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m17:55:14.006332 [debug] [MainThread]: Acquiring new duckdb connection 'debug'
[0m17:55:14.014754 [debug] [MainThread]: Using duckdb connection "debug"
[0m17:55:14.015005 [debug] [MainThread]: On debug: select 1 as id
[0m17:55:14.015196 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:55:14.024568 [debug] [MainThread]: SQL status: OK in 0.009 seconds
[0m17:55:14.025219 [debug] [MainThread]: On debug: Close
[0m17:55:14.025497 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m17:55:14.025692 [info ] [MainThread]: [32mAll checks passed![0m
[0m17:55:14.026297 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.23796244, "process_in_blocks": "0", "process_kernel_time": 0.111708, "process_mem_max_rss": "137836", "process_out_blocks": "24", "process_user_time": 1.025312}
[0m17:55:14.026595 [debug] [MainThread]: Command `dbt debug` succeeded at 17:55:14.026534 after 0.24 seconds
[0m17:55:14.026784 [debug] [MainThread]: Connection 'debug' was properly closed.
[0m17:55:14.026980 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f065d094fc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f065d3e3d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0661314e20>]}
[0m17:55:14.027223 [debug] [MainThread]: Flushing usage events
[0m17:55:24.039600 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:55:32.619111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eef7e3770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ef0e1da90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eee657d90>]}


============================== 17:55:32.621626 | 7bf6625d-94fc-4472-b3fe-3cf1956ac193 ==============================
[0m17:55:32.621626 [info ] [MainThread]: Running with dbt=1.10.9
[0m17:55:32.621981 [debug] [MainThread]: running dbt with arguments {'log_cache_events': 'False', 'target_path': 'None', 'fail_fast': 'False', 'log_path': '/workspace/dbt_project/logs', 'no_print': 'None', 'partial_parse': 'True', 'log_format': 'default', 'indirect_selection': 'eager', 'use_colors': 'True', 'empty': 'False', 'printer_width': '80', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'cache_selected_only': 'False', 'invocation_command': 'dbt run --select staging', 'write_json': 'True', 'warn_error': 'None', 'static_parser': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'quiet': 'False', 'profiles_dir': '/workspace/dbt_project', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m17:55:32.761604 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '7bf6625d-94fc-4472-b3fe-3cf1956ac193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eef36e650>]}
[0m17:55:32.803171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '7bf6625d-94fc-4472-b3fe-3cf1956ac193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eee74abe0>]}
[0m17:55:32.804207 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m17:55:32.834606 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m17:55:32.835037 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m17:55:32.835282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '7bf6625d-94fc-4472-b3fe-3cf1956ac193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eea720e50>]}
[0m17:55:33.762784 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values`. Arguments to generic tests
should be nested under the `arguments` property.`
[0m17:55:33.763145 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '7bf6625d-94fc-4472-b3fe-3cf1956ac193', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eea3377a0>]}
[0m17:55:33.970970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7bf6625d-94fc-4472-b3fe-3cf1956ac193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee9788f30>]}
[0m17:55:34.029067 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:55:34.030394 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:55:34.041139 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7bf6625d-94fc-4472-b3fe-3cf1956ac193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee96d3d40>]}
[0m17:55:34.041465 [info ] [MainThread]: Found 11 models, 37 data tests, 1 source, 565 macros
[0m17:55:34.041680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7bf6625d-94fc-4472-b3fe-3cf1956ac193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee96d4dd0>]}
[0m17:55:34.042931 [info ] [MainThread]: 
[0m17:55:34.043252 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:55:34.043458 [info ] [MainThread]: 
[0m17:55:34.043774 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m17:55:34.045168 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m17:55:34.067517 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m17:55:34.067835 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m17:55:34.068050 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:55:34.086306 [debug] [ThreadPool]: SQL status: OK in 0.018 seconds
[0m17:55:34.087547 [debug] [ThreadPool]: On list_quant_features: Close
[0m17:55:34.088683 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m17:55:34.089136 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m17:55:34.093866 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:55:34.094178 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m17:55:34.094364 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:55:34.095266 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:55:34.096177 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:55:34.096407 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m17:55:34.096771 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:55:34.096958 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:55:34.097120 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m17:55:34.097557 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:55:34.098164 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:55:34.098376 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:55:34.098531 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:55:34.098830 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:55:34.099013 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m17:55:34.103704 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m17:55:34.107716 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:55:34.107962 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m17:55:34.108142 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:55:34.108533 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:55:34.108718 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:55:34.108876 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m17:55:34.116098 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m17:55:34.116949 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m17:55:34.118044 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m17:55:34.118282 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m17:55:34.119306 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7bf6625d-94fc-4472-b3fe-3cf1956ac193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee9669650>]}
[0m17:55:34.119807 [debug] [MainThread]: Using duckdb connection "master"
[0m17:55:34.120014 [debug] [MainThread]: On master: BEGIN
[0m17:55:34.120184 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:55:34.120841 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m17:55:34.121048 [debug] [MainThread]: On master: COMMIT
[0m17:55:34.121222 [debug] [MainThread]: Using duckdb connection "master"
[0m17:55:34.121364 [debug] [MainThread]: On master: COMMIT
[0m17:55:34.121649 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:55:34.121838 [debug] [MainThread]: On master: Close
[0m17:55:34.125174 [debug] [Thread-1 (]: Began running node model.quant_features.stg_ohlc_data
[0m17:55:34.125632 [info ] [Thread-1 (]: 1 of 1 START sql view model main.stg_ohlc_data ................................. [RUN]
[0m17:55:34.125978 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.stg_ohlc_data)
[0m17:55:34.126223 [debug] [Thread-1 (]: Began compiling node model.quant_features.stg_ohlc_data
[0m17:55:34.131912 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.stg_ohlc_data"
[0m17:55:34.132519 [debug] [Thread-1 (]: Began executing node model.quant_features.stg_ohlc_data
[0m17:55:34.154858 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.stg_ohlc_data"
[0m17:55:34.155493 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:55:34.155758 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: BEGIN
[0m17:55:34.155958 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:55:34.156587 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m17:55:34.156823 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:55:34.157042 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

  
  create view "quant_features"."main"."stg_ohlc_data__dbt_tmp" as (
    

with raw_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 数据清洗和验证
        case 
            when open <= 0 or high <= 0 or low <= 0 or close <= 0 then null
            when high < greatest(open, close, low) then null
            when low > least(open, close, high) then null
            else timestamp
        end as valid_timestamp
    from "quant_features"."raw"."ohlc_data"
),

cleaned_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础指标
        (high + low + close) / 3 as typical_price,
        (high - low) as daily_range,
        case when open != 0 then (close - open) / open else 0 end as daily_return,
        case when close != 0 then volume / close else 0 end as volume_price_ratio
    from raw_ohlc
    where valid_timestamp is not null
      and timestamp >= '2020-01-01'
      and timestamp <= '2024-12-31'
)

select * from cleaned_ohlc
  );

[0m17:55:34.158034 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

  
  create view "quant_features"."main"."stg_ohlc_data__dbt_tmp" as (
    

with raw_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 数据清洗和验证
        case 
            when open <= 0 or high <= 0 or low <= 0 or close <= 0 then null
            when high < greatest(open, close, low) then null
            when low > least(open, close, high) then null
            else timestamp
        end as valid_timestamp
    from "quant_features"."raw"."ohlc_data"
),

cleaned_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础指标
        (high + low + close) / 3 as typical_price,
        (high - low) as daily_range,
        case when open != 0 then (close - open) / open else 0 end as daily_return,
        case when close != 0 then volume / close else 0 end as volume_price_ratio
    from raw_ohlc
    where valid_timestamp is not null
      and timestamp >= '2020-01-01'
      and timestamp <= '2024-12-31'
)

select * from cleaned_ohlc
  );

[0m17:55:34.158347 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m17:55:34.158645 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: ROLLBACK
[0m17:55:34.162160 [debug] [Thread-1 (]: Failed to rollback 'model.quant_features.stg_ohlc_data'
[0m17:55:34.162430 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: Close
[0m17:55:34.164776 [debug] [Thread-1 (]: Runtime Error in model stg_ohlc_data (models/staging/stg_ohlc_data.sql)
  Catalog Error: Table with name ohlc_data does not exist!
  Did you mean "pg_catalog.pg_database"?
  
  LINE 23:     from "quant_features"."raw"."ohlc_data"
                    ^
[0m17:55:34.165878 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7bf6625d-94fc-4472-b3fe-3cf1956ac193', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eef31ed50>]}
[0m17:55:34.166353 [error] [Thread-1 (]: 1 of 1 ERROR creating sql view model main.stg_ohlc_data ........................ [[31mERROR[0m in 0.04s]
[0m17:55:34.166719 [debug] [Thread-1 (]: Finished running node model.quant_features.stg_ohlc_data
[0m17:55:34.167053 [debug] [Thread-7 (]: Marking all children of 'model.quant_features.stg_ohlc_data' to be skipped because of status 'error'.  Reason: Runtime Error in model stg_ohlc_data (models/staging/stg_ohlc_data.sql)
  Catalog Error: Table with name ohlc_data does not exist!
  Did you mean "pg_catalog.pg_database"?
  
  LINE 23:     from "quant_features"."raw"."ohlc_data"
                    ^.
[0m17:55:34.169100 [debug] [MainThread]: Using duckdb connection "master"
[0m17:55:34.169373 [debug] [MainThread]: On master: BEGIN
[0m17:55:34.169535 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:55:34.169927 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:55:34.170112 [debug] [MainThread]: On master: COMMIT
[0m17:55:34.170282 [debug] [MainThread]: Using duckdb connection "master"
[0m17:55:34.170425 [debug] [MainThread]: On master: COMMIT
[0m17:55:34.170679 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:55:34.170860 [debug] [MainThread]: On master: Close
[0m17:55:34.171147 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:55:34.171309 [debug] [MainThread]: Connection 'model.quant_features.stg_ohlc_data' was properly closed.
[0m17:55:34.171472 [info ] [MainThread]: 
[0m17:55:34.171666 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.13 seconds (0.13s).
[0m17:55:34.172042 [debug] [MainThread]: Command end result
[0m17:55:34.192376 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:55:34.193539 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:55:34.197068 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m17:55:34.197305 [info ] [MainThread]: 
[0m17:55:34.197550 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m17:55:34.197742 [info ] [MainThread]: 
[0m17:55:34.197981 [error] [MainThread]: [31mFailure in model stg_ohlc_data (models/staging/stg_ohlc_data.sql)[0m
[0m17:55:34.198219 [error] [MainThread]:   Runtime Error in model stg_ohlc_data (models/staging/stg_ohlc_data.sql)
  Catalog Error: Table with name ohlc_data does not exist!
  Did you mean "pg_catalog.pg_database"?
  
  LINE 23:     from "quant_features"."raw"."ohlc_data"
                    ^
[0m17:55:34.198390 [info ] [MainThread]: 
[0m17:55:34.198581 [info ] [MainThread]:   compiled code at target/compiled/quant_features/models/staging/stg_ohlc_data.sql
[0m17:55:34.198733 [info ] [MainThread]: 
[0m17:55:34.198903 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m17:55:34.199223 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 12 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m17:55:34.199908 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.6176295, "process_in_blocks": "0", "process_kernel_time": 0.224664, "process_mem_max_rss": "157780", "process_out_blocks": "4752", "process_user_time": 2.29875}
[0m17:55:34.200254 [debug] [MainThread]: Command `dbt run` failed at 17:55:34.200190 after 1.62 seconds
[0m17:55:34.200492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ee963bad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eee65d4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4eee69d0f0>]}
[0m17:55:34.200716 [debug] [MainThread]: Flushing usage events
[0m17:55:34.664675 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:55:53.772296 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a07963770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a08f81a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a0679bd90>]}


============================== 17:55:53.774755 | 54be8739-16ba-4d4a-bcf2-51ef8b698201 ==============================
[0m17:55:53.774755 [info ] [MainThread]: Running with dbt=1.10.9
[0m17:55:53.775077 [debug] [MainThread]: running dbt with arguments {'quiet': 'False', 'introspect': 'True', 'log_format': 'default', 'static_parser': 'True', 'invocation_command': 'dbt run --select staging', 'no_print': 'None', 'profiles_dir': '/workspace/dbt_project', 'use_experimental_parser': 'False', 'debug': 'False', 'target_path': 'None', 'cache_selected_only': 'False', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'fail_fast': 'False', 'log_cache_events': 'False', 'log_path': '/workspace/dbt_project/logs', 'printer_width': '80', 'indirect_selection': 'eager', 'partial_parse': 'True', 'write_json': 'True', 'empty': 'False', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'warn_error': 'None'}
[0m17:55:53.911246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '54be8739-16ba-4d4a-bcf2-51ef8b698201', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a074e6650>]}
[0m17:55:53.952682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '54be8739-16ba-4d4a-bcf2-51ef8b698201', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a06892be0>]}
[0m17:55:53.953773 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m17:55:53.983548 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m17:55:54.062757 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:55:54.062999 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:55:54.093290 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '54be8739-16ba-4d4a-bcf2-51ef8b698201', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a06861450>]}
[0m17:55:54.153699 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:55:54.154853 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:55:54.164501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '54be8739-16ba-4d4a-bcf2-51ef8b698201', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a030d8e60>]}
[0m17:55:54.164826 [info ] [MainThread]: Found 11 models, 37 data tests, 1 source, 565 macros
[0m17:55:54.165030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54be8739-16ba-4d4a-bcf2-51ef8b698201', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a03118050>]}
[0m17:55:54.166220 [info ] [MainThread]: 
[0m17:55:54.166483 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:55:54.166662 [info ] [MainThread]: 
[0m17:55:54.166962 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m17:55:54.167819 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m17:55:54.184759 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m17:55:54.185017 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m17:55:54.185207 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:55:54.195485 [debug] [ThreadPool]: SQL status: OK in 0.010 seconds
[0m17:55:54.196388 [debug] [ThreadPool]: On list_quant_features: Close
[0m17:55:54.197107 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m17:55:54.197424 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m17:55:54.201498 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:55:54.201747 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m17:55:54.201956 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:55:54.202650 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:55:54.203478 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:55:54.203691 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m17:55:54.204004 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:55:54.204196 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:55:54.204355 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m17:55:54.204655 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:55:54.205171 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:55:54.205371 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:55:54.205530 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:55:54.205845 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:55:54.206051 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m17:55:54.210857 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m17:55:54.216009 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:55:54.216469 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m17:55:54.216657 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:55:54.217511 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:55:54.217735 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:55:54.217927 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m17:55:54.225368 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m17:55:54.226386 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m17:55:54.227289 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m17:55:54.227527 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m17:55:54.228287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '54be8739-16ba-4d4a-bcf2-51ef8b698201', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a023fa4e0>]}
[0m17:55:54.228872 [debug] [MainThread]: Using duckdb connection "master"
[0m17:55:54.229082 [debug] [MainThread]: On master: BEGIN
[0m17:55:54.229250 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:55:54.229730 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:55:54.229944 [debug] [MainThread]: On master: COMMIT
[0m17:55:54.230118 [debug] [MainThread]: Using duckdb connection "master"
[0m17:55:54.230268 [debug] [MainThread]: On master: COMMIT
[0m17:55:54.230537 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:55:54.230716 [debug] [MainThread]: On master: Close
[0m17:55:54.233091 [debug] [Thread-1 (]: Began running node model.quant_features.stg_ohlc_data
[0m17:55:54.233517 [info ] [Thread-1 (]: 1 of 1 START sql view model main.stg_ohlc_data ................................. [RUN]
[0m17:55:54.233834 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.stg_ohlc_data)
[0m17:55:54.234059 [debug] [Thread-1 (]: Began compiling node model.quant_features.stg_ohlc_data
[0m17:55:54.240061 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.stg_ohlc_data"
[0m17:55:54.240509 [debug] [Thread-1 (]: Began executing node model.quant_features.stg_ohlc_data
[0m17:55:54.263350 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.stg_ohlc_data"
[0m17:55:54.263811 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:55:54.264038 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: BEGIN
[0m17:55:54.264241 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:55:54.264725 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:55:54.264954 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:55:54.265194 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

  
  create view "quant_features"."main"."stg_ohlc_data__dbt_tmp" as (
    

with raw_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 数据清洗和验证
        case 
            when open <= 0 or high <= 0 or low <= 0 or close <= 0 then null
            when high < greatest(open, close, low) then null
            when low > least(open, close, high) then null
            else timestamp
        end as valid_timestamp
    from "quant_features"."raw"."ohlc_data"
),

cleaned_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础指标
        (high + low + close) / 3 as typical_price,
        (high - low) as daily_range,
        case when open != 0 then (close - open) / open else 0 end as daily_return,
        case when close != 0 then volume / close else 0 end as volume_price_ratio
    from raw_ohlc
    where valid_timestamp is not null
      and timestamp >= '2020-01-01'
      and timestamp <= '2024-12-31'
)

select * from cleaned_ohlc
  );

[0m17:55:54.266223 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m17:55:54.300785 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:55:54.301061 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */
alter view "quant_features"."main"."stg_ohlc_data__dbt_tmp" rename to "stg_ohlc_data"
[0m17:55:54.301662 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:55:54.308136 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m17:55:54.308415 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:55:54.308613 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m17:55:54.311072 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m17:55:54.314617 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:55:54.314888 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

      drop view if exists "quant_features"."main"."stg_ohlc_data__dbt_backup" cascade
    
[0m17:55:54.315366 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:55:54.316949 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: Close
[0m17:55:54.318251 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '54be8739-16ba-4d4a-bcf2-51ef8b698201', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a023ef590>]}
[0m17:55:54.318716 [info ] [Thread-1 (]: 1 of 1 OK created sql view model main.stg_ohlc_data ............................ [[32mOK[0m in 0.08s]
[0m17:55:54.319071 [debug] [Thread-1 (]: Finished running node model.quant_features.stg_ohlc_data
[0m17:55:54.320591 [debug] [MainThread]: Using duckdb connection "master"
[0m17:55:54.320841 [debug] [MainThread]: On master: BEGIN
[0m17:55:54.321044 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:55:54.321493 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:55:54.321698 [debug] [MainThread]: On master: COMMIT
[0m17:55:54.321883 [debug] [MainThread]: Using duckdb connection "master"
[0m17:55:54.322084 [debug] [MainThread]: On master: COMMIT
[0m17:55:54.322378 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:55:54.322583 [debug] [MainThread]: On master: Close
[0m17:55:54.322869 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:55:54.323035 [debug] [MainThread]: Connection 'model.quant_features.stg_ohlc_data' was properly closed.
[0m17:55:54.323215 [info ] [MainThread]: 
[0m17:55:54.323398 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 0.16 seconds (0.16s).
[0m17:55:54.323775 [debug] [MainThread]: Command end result
[0m17:55:54.343258 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:55:54.344417 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:55:54.348055 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m17:55:54.348311 [info ] [MainThread]: 
[0m17:55:54.348539 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:55:54.348715 [info ] [MainThread]: 
[0m17:55:54.348906 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m17:55:54.349458 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.6138587, "process_in_blocks": "0", "process_kernel_time": 0.140037, "process_mem_max_rss": "147332", "process_out_blocks": "3376", "process_user_time": 1.368332}
[0m17:55:54.349736 [debug] [MainThread]: Command `dbt run` succeeded at 17:55:54.349679 after 0.61 seconds
[0m17:55:54.349957 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a0237bd80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a090974d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2a08e07430>]}
[0m17:55:54.350186 [debug] [MainThread]: Flushing usage events
[0m17:55:54.811686 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:56:01.498411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55799cf770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f557b001a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5578843d90>]}


============================== 17:56:01.500850 | ab599753-5ebe-419a-ae28-40f33bd323bc ==============================
[0m17:56:01.500850 [info ] [MainThread]: Running with dbt=1.10.9
[0m17:56:01.501194 [debug] [MainThread]: running dbt with arguments {'send_anonymous_usage_stats': 'True', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'cache_selected_only': 'False', 'partial_parse': 'True', 'version_check': 'True', 'write_json': 'True', 'debug': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_experimental_parser': 'False', 'printer_width': '80', 'invocation_command': 'dbt run', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/workspace/dbt_project', 'quiet': 'False', 'log_path': '/workspace/dbt_project/logs', 'empty': 'False', 'no_print': 'None'}
[0m17:56:01.637382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'ab599753-5ebe-419a-ae28-40f33bd323bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f557955a650>]}
[0m17:56:01.679025 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'ab599753-5ebe-419a-ae28-40f33bd323bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5578936be0>]}
[0m17:56:01.680022 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m17:56:01.709850 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m17:56:01.788827 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:56:01.789106 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:56:01.819166 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ab599753-5ebe-419a-ae28-40f33bd323bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5574921450>]}
[0m17:56:01.883206 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:56:01.884552 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:56:01.894636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ab599753-5ebe-419a-ae28-40f33bd323bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5574954e60>]}
[0m17:56:01.894982 [info ] [MainThread]: Found 11 models, 37 data tests, 1 source, 565 macros
[0m17:56:01.895229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ab599753-5ebe-419a-ae28-40f33bd323bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5574994050>]}
[0m17:56:01.896826 [info ] [MainThread]: 
[0m17:56:01.897119 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:56:01.897298 [info ] [MainThread]: 
[0m17:56:01.897615 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m17:56:01.901594 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m17:56:01.922000 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m17:56:01.922356 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m17:56:01.922551 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:56:01.934851 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m17:56:01.935982 [debug] [ThreadPool]: On list_quant_features: Close
[0m17:56:01.936858 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m17:56:01.937225 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m17:56:01.942193 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:01.942451 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m17:56:01.942633 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:56:01.943375 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:56:01.944294 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:01.944508 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m17:56:01.944820 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:01.944987 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:01.945152 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m17:56:01.945453 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:01.946075 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:56:01.946301 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:01.946465 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:56:01.946829 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:01.947012 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m17:56:01.949241 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m17:56:01.953560 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:56:01.953841 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m17:56:01.954040 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:56:01.954454 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:01.954655 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:56:01.954815 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m17:56:01.961413 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m17:56:01.962416 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m17:56:01.963321 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m17:56:01.963548 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m17:56:01.964786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ab599753-5ebe-419a-ae28-40f33bd323bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f557432e820>]}
[0m17:56:01.965238 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:01.965444 [debug] [MainThread]: On master: BEGIN
[0m17:56:01.965607 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:56:01.966252 [debug] [MainThread]: SQL status: OK in 0.001 seconds
[0m17:56:01.966467 [debug] [MainThread]: On master: COMMIT
[0m17:56:01.966627 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:01.966772 [debug] [MainThread]: On master: COMMIT
[0m17:56:01.967040 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:01.967231 [debug] [MainThread]: On master: Close
[0m17:56:01.969881 [debug] [Thread-1 (]: Began running node model.quant_features.stg_ohlc_data
[0m17:56:01.970315 [info ] [Thread-1 (]: 1 of 11 START sql view model main.stg_ohlc_data ................................ [RUN]
[0m17:56:01.970618 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.stg_ohlc_data)
[0m17:56:01.970826 [debug] [Thread-1 (]: Began compiling node model.quant_features.stg_ohlc_data
[0m17:56:01.976537 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.stg_ohlc_data"
[0m17:56:01.976999 [debug] [Thread-1 (]: Began executing node model.quant_features.stg_ohlc_data
[0m17:56:01.999692 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.stg_ohlc_data"
[0m17:56:02.000170 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:02.000399 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: BEGIN
[0m17:56:02.000582 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:56:02.001143 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m17:56:02.001373 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:02.001587 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

  
  create view "quant_features"."main"."stg_ohlc_data__dbt_tmp" as (
    

with raw_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 数据清洗和验证
        case 
            when open <= 0 or high <= 0 or low <= 0 or close <= 0 then null
            when high < greatest(open, close, low) then null
            when low > least(open, close, high) then null
            else timestamp
        end as valid_timestamp
    from "quant_features"."raw"."ohlc_data"
),

cleaned_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础指标
        (high + low + close) / 3 as typical_price,
        (high - low) as daily_range,
        case when open != 0 then (close - open) / open else 0 end as daily_return,
        case when close != 0 then volume / close else 0 end as volume_price_ratio
    from raw_ohlc
    where valid_timestamp is not null
      and timestamp >= '2020-01-01'
      and timestamp <= '2024-12-31'
)

select * from cleaned_ohlc
  );

[0m17:56:02.002704 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m17:56:02.043713 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:02.043991 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */
alter view "quant_features"."main"."stg_ohlc_data" rename to "stg_ohlc_data__dbt_backup"
[0m17:56:02.044524 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:56:02.046327 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:02.046602 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */
alter view "quant_features"."main"."stg_ohlc_data__dbt_tmp" rename to "stg_ohlc_data"
[0m17:56:02.047070 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:56:02.054682 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m17:56:02.054997 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:02.055238 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m17:56:02.058034 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m17:56:02.061806 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:02.062148 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

      drop view if exists "quant_features"."main"."stg_ohlc_data__dbt_backup" cascade
    
[0m17:56:02.064264 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m17:56:02.065865 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: Close
[0m17:56:02.067181 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab599753-5ebe-419a-ae28-40f33bd323bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5574323650>]}
[0m17:56:02.067626 [info ] [Thread-1 (]: 1 of 11 OK created sql view model main.stg_ohlc_data ........................... [[32mOK[0m in 0.10s]
[0m17:56:02.067969 [debug] [Thread-1 (]: Finished running node model.quant_features.stg_ohlc_data
[0m17:56:02.068810 [debug] [Thread-3 (]: Began running node model.quant_features.mart_technical_indicators
[0m17:56:02.069338 [info ] [Thread-3 (]: 3 of 11 START sql table model main.mart_technical_indicators ................... [RUN]
[0m17:56:02.069712 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.quant_features.mart_technical_indicators'
[0m17:56:02.069933 [debug] [Thread-3 (]: Began compiling node model.quant_features.mart_technical_indicators
[0m17:56:02.072119 [debug] [Thread-3 (]: Writing injected SQL for node "model.quant_features.mart_technical_indicators"
[0m17:56:02.072704 [debug] [Thread-2 (]: Began running node model.quant_features.alpha_base_data
[0m17:56:02.073253 [info ] [Thread-2 (]: 2 of 11 START sql table model main.alpha_base_data ............................. [RUN]
[0m17:56:02.073818 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.quant_features.alpha_base_data'
[0m17:56:02.074144 [debug] [Thread-2 (]: Began compiling node model.quant_features.alpha_base_data
[0m17:56:02.084660 [debug] [Thread-3 (]: Began executing node model.quant_features.mart_technical_indicators
[0m17:56:02.106653 [debug] [Thread-2 (]: Writing injected SQL for node "model.quant_features.alpha_base_data"
[0m17:56:02.109454 [debug] [Thread-3 (]: Writing runtime sql for node "model.quant_features.mart_technical_indicators"
[0m17:56:02.109991 [debug] [Thread-2 (]: Began executing node model.quant_features.alpha_base_data
[0m17:56:02.112460 [debug] [Thread-2 (]: Writing runtime sql for node "model.quant_features.alpha_base_data"
[0m17:56:02.113173 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:02.113458 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: BEGIN
[0m17:56:02.113806 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:02.114334 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m17:56:02.114701 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: BEGIN
[0m17:56:02.115406 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:56:02.115858 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m17:56:02.116165 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:02.116467 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */

  
    
    

    create  table
      "quant_features"."main"."mart_technical_indicators__dbt_tmp"
  
    as (
      

with base_data as (
    select * from "quant_features"."main"."stg_ohlc_data"
),

technical_indicators as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        typical_price,
        daily_range,
        daily_return,
        volume_price_ratio,
        
        -- 移动平均线
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 4 preceding and current row
        ) as ma_5,
        
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 9 preceding and current row
        ) as ma_10,
        
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as ma_20,
        
        -- 波动率 (标准差)
        stddev(daily_return) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as volatility_20d,
        
        -- RSI相关计算
        case when daily_return > 0 then daily_return else 0 end as gain,
        case when daily_return < 0 then abs(daily_return) else 0 end as loss,
        
        -- 价格位置指标
        (close - min(low) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        )) / nullif((max(high) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) - min(low) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        )), 0) as stoch_k_14,
        
        -- 成交量指标
        avg(volume) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as avg_volume_20d
        
    from base_data
),

rsi_calculation as (
    select *,
        -- RSI计算
        avg(gain) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) as avg_gain_14,
        
        avg(loss) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) as avg_loss_14
    from technical_indicators
),

final_indicators as (
    select *,
        case 
            when avg_loss_14 = 0 then 100
            when avg_gain_14 = 0 then 0
            else 100 - (100 / (1 + (avg_gain_14 / avg_loss_14)))
        end as rsi_14,
        
        -- 布林带
        ma_20 + (2 * stddev(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        )) as bollinger_upper,
        
        ma_20 - (2 * stddev(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        )) as bollinger_lower,
        
        -- 价格动量
        case when lag(close, 5) over (partition by symbol order by timestamp) != 0 
            then (close - lag(close, 5) over (partition by symbol order by timestamp)) / 
                 lag(close, 5) over (partition by symbol order by timestamp)
            else 0 
        end as momentum_5d,
        
        case when lag(close, 10) over (partition by symbol order by timestamp) != 0 
            then (close - lag(close, 10) over (partition by symbol order by timestamp)) / 
                 lag(close, 10) over (partition by symbol order by timestamp)
            else 0 
        end as momentum_10d
        
    from rsi_calculation
)

select * from final_indicators
    );
  
  
[0m17:56:02.117340 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m17:56:02.117678 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:02.118187 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_base_data__dbt_tmp"
  
    as (
      

-- Alpha 101 基础数据准备
-- 为Alpha因子计算准备所有必要的基础数据

WITH base_ohlc AS (
    SELECT 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算VWAP (简化版本，假设等权重)
        (high + low + close) / 3 AS vwap,
        -- 计算returns
        CASE 
            WHEN LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp) IS NOT NULL
            THEN (close - LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)) / 
                 LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)
            ELSE 0
        END AS returns
    FROM "quant_features"."main"."stg_ohlc_data"
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
),

enhanced_data AS (
    SELECT 
        *,
        -- 计算ADV (Average Daily Volume)
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 AS adv20,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

 AS adv10,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

 AS adv5,
        
        -- 预计算一些常用的时间序列指标
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_ma5,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ma10,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_ma20,
        
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_ma20,
        
        -- 预计算滚动标准差
        
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_std20,
        
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS returns_std20,
        
        -- 预计算一些延迟项
        
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag1,
        
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag2,
        
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag5,
        
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag10,
        
    LAG(close, 20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag20,
        
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS volume_lag1,
        
    LAG(high, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS high_lag1,
        
    LAG(low, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS low_lag1,
        
    LAG(vwap, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS vwap_lag5,
        
        -- 预计算一些差值项
        
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta1,
        
    close - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta2,
        
    close - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta3,
        
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta5,
        
    close - 
    LAG(close, 7) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta7,
        
    close - 
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta10,
        
    volume - 
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta1,
        
    volume - 
    LAG(volume, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta3,
        
    high - 
    LAG(high, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS high_delta2,
        
        -- 预计算一些排序项
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
 AS close_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
 AS volume_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
 AS high_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
 AS low_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
 AS vwap_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns
    )
 AS returns_rank,
        
        -- 预计算时间序列排序
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ts_rank10,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_ts_rank5,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY high
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_ts_rank5,
        
        -- 预计算一些最值项
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_min100,
        
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS close_max3,
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_min5,
        
    MAX(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_max5,
        
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS low_min5,
        
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS high_max3,
        
        -- 预计算一些求和项
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_sum5,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS close_sum8,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_sum20,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_sum100,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
    )
 AS close_sum200,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_sum5,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_sum20,
        
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 AS returns_sum250,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_sum5,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS high_sum20,
        
        -- 预计算一些相关性
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_close_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(open, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_open_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS corr_high_volume_5,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS corr_vwap_volume_6,
        
        -- 预计算一些协方差
        
    COVAR_SAMP(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_close_volume_5,
        
    COVAR_SAMP(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_high_volume_5
        
    FROM base_ohlc
    WHERE timestamp >= '2020-01-01' - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数据
),

-- 过滤回原始时间范围
final_data AS (
    SELECT *
    FROM enhanced_data
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
)

SELECT * FROM final_data
    );
  
  
[0m17:56:02.121164 [debug] [Thread-2 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_base_data__dbt_tmp"
  
    as (
      

-- Alpha 101 基础数据准备
-- 为Alpha因子计算准备所有必要的基础数据

WITH base_ohlc AS (
    SELECT 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算VWAP (简化版本，假设等权重)
        (high + low + close) / 3 AS vwap,
        -- 计算returns
        CASE 
            WHEN LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp) IS NOT NULL
            THEN (close - LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)) / 
                 LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)
            ELSE 0
        END AS returns
    FROM "quant_features"."main"."stg_ohlc_data"
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
),

enhanced_data AS (
    SELECT 
        *,
        -- 计算ADV (Average Daily Volume)
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 AS adv20,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

 AS adv10,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

 AS adv5,
        
        -- 预计算一些常用的时间序列指标
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_ma5,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ma10,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_ma20,
        
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_ma20,
        
        -- 预计算滚动标准差
        
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_std20,
        
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS returns_std20,
        
        -- 预计算一些延迟项
        
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag1,
        
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag2,
        
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag5,
        
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag10,
        
    LAG(close, 20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag20,
        
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS volume_lag1,
        
    LAG(high, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS high_lag1,
        
    LAG(low, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS low_lag1,
        
    LAG(vwap, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS vwap_lag5,
        
        -- 预计算一些差值项
        
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta1,
        
    close - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta2,
        
    close - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta3,
        
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta5,
        
    close - 
    LAG(close, 7) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta7,
        
    close - 
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta10,
        
    volume - 
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta1,
        
    volume - 
    LAG(volume, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta3,
        
    high - 
    LAG(high, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS high_delta2,
        
        -- 预计算一些排序项
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
 AS close_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
 AS volume_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
 AS high_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
 AS low_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
 AS vwap_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns
    )
 AS returns_rank,
        
        -- 预计算时间序列排序
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ts_rank10,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_ts_rank5,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY high
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_ts_rank5,
        
        -- 预计算一些最值项
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_min100,
        
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS close_max3,
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_min5,
        
    MAX(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_max5,
        
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS low_min5,
        
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS high_max3,
        
        -- 预计算一些求和项
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_sum5,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS close_sum8,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_sum20,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_sum100,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
    )
 AS close_sum200,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_sum5,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_sum20,
        
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 AS returns_sum250,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_sum5,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS high_sum20,
        
        -- 预计算一些相关性
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_close_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(open, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_open_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS corr_high_volume_5,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS corr_vwap_volume_6,
        
        -- 预计算一些协方差
        
    COVAR_SAMP(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_close_volume_5,
        
    COVAR_SAMP(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_high_volume_5
        
    FROM base_ohlc
    WHERE timestamp >= '2020-01-01' - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数据
),

-- 过滤回原始时间范围
final_data AS (
    SELECT *
    FROM enhanced_data
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
)

SELECT * FROM final_data
    );
  
  
[0m17:56:02.121811 [debug] [Thread-2 (]: DuckDB adapter: Rolling back transaction.
[0m17:56:02.122175 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: ROLLBACK
[0m17:56:02.125994 [debug] [Thread-2 (]: Failed to rollback 'model.quant_features.alpha_base_data'
[0m17:56:02.126279 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: Close
[0m17:56:02.126915 [debug] [Thread-3 (]: SQL status: OK in 0.010 seconds
[0m17:56:02.129020 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:02.129973 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */
alter table "quant_features"."main"."mart_technical_indicators__dbt_tmp" rename to "mart_technical_indicators"
[0m17:56:02.132172 [debug] [Thread-2 (]: Runtime Error in model alpha_base_data (models/alpha101/alpha_base_data.sql)
  Binder Error: Could not choose a best candidate function for the function call "-(STRING_LITERAL, INTERVAL)". In order to select one, please add explicit type casts.
  	Candidate functions:
  	-(DATE, INTERVAL) -> TIMESTAMP
  	-(TIME, INTERVAL) -> TIME
  	-(TIMESTAMP, INTERVAL) -> TIMESTAMP
  	-(TIME WITH TIME ZONE, INTERVAL) -> TIME WITH TIME ZONE
  	-(TIMESTAMP WITH TIME ZONE, INTERVAL) -> TIMESTAMP WITH TIME ZONE
  	-(INTERVAL, INTERVAL) -> INTERVAL
  
  
  LINE 475:     WHERE timestamp >= '2020-01-01' - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数...
                                                ^
[0m17:56:02.132562 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m17:56:02.132981 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab599753-5ebe-419a-ae28-40f33bd323bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55744cf280>]}
[0m17:56:02.136289 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: COMMIT
[0m17:56:02.137000 [error] [Thread-2 (]: 2 of 11 ERROR creating sql table model main.alpha_base_data .................... [[31mERROR[0m in 0.06s]
[0m17:56:02.137422 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:02.137839 [debug] [Thread-2 (]: Finished running node model.quant_features.alpha_base_data
[0m17:56:02.138430 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: COMMIT
[0m17:56:02.139058 [debug] [Thread-7 (]: Marking all children of 'model.quant_features.alpha_base_data' to be skipped because of status 'error'.  Reason: Runtime Error in model alpha_base_data (models/alpha101/alpha_base_data.sql)
  Binder Error: Could not choose a best candidate function for the function call "-(STRING_LITERAL, INTERVAL)". In order to select one, please add explicit type casts.
  	Candidate functions:
  	-(DATE, INTERVAL) -> TIMESTAMP
  	-(TIME, INTERVAL) -> TIME
  	-(TIMESTAMP, INTERVAL) -> TIMESTAMP
  	-(TIME WITH TIME ZONE, INTERVAL) -> TIME WITH TIME ZONE
  	-(TIMESTAMP WITH TIME ZONE, INTERVAL) -> TIMESTAMP WITH TIME ZONE
  	-(INTERVAL, INTERVAL) -> INTERVAL
  
  
  LINE 475:     WHERE timestamp >= '2020-01-01' - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数...
                                                ^.
[0m17:56:02.140430 [debug] [Thread-2 (]: Began running node model.quant_features.alpha_factors_051_075
[0m17:56:02.140892 [debug] [Thread-1 (]: Began running node model.quant_features.alpha_factors_021_050
[0m17:56:02.141369 [debug] [Thread-4 (]: Began running node model.quant_features.alpha_factors_001_020
[0m17:56:02.141754 [info ] [Thread-2 (]: 6 of 11 SKIP relation main.alpha_factors_051_075 ............................... [[33mSKIP[0m]
[0m17:56:02.142166 [debug] [Thread-3 (]: SQL status: OK in 0.003 seconds
[0m17:56:02.142736 [info ] [Thread-1 (]: 5 of 11 SKIP relation main.alpha_factors_021_050 ............................... [[33mSKIP[0m]
[0m17:56:02.143248 [info ] [Thread-4 (]: 4 of 11 SKIP relation main.alpha_factors_001_020 ............................... [[33mSKIP[0m]
[0m17:56:02.143710 [debug] [Thread-2 (]: Finished running node model.quant_features.alpha_factors_051_075
[0m17:56:02.145330 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:02.145653 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha_factors_021_050
[0m17:56:02.146013 [debug] [Thread-4 (]: Finished running node model.quant_features.alpha_factors_001_020
[0m17:56:02.146543 [debug] [Thread-2 (]: Began running node model.quant_features.alpha_factors_076_101
[0m17:56:02.146928 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */

      drop table if exists "quant_features"."main"."mart_technical_indicators__dbt_backup" cascade
    
[0m17:56:02.147331 [debug] [Thread-1 (]: Began running node model.quant_features.alpha_factors_advanced
[0m17:56:02.148530 [info ] [Thread-1 (]: 8 of 11 SKIP relation main.alpha_factors_advanced .............................. [[33mSKIP[0m]
[0m17:56:02.147983 [info ] [Thread-2 (]: 7 of 11 SKIP relation main.alpha_factors_076_101 ............................... [[33mSKIP[0m]
[0m17:56:02.148810 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha_factors_advanced
[0m17:56:02.149133 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m17:56:02.149540 [debug] [Thread-2 (]: Finished running node model.quant_features.alpha_factors_076_101
[0m17:56:02.150800 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: Close
[0m17:56:02.151151 [debug] [Thread-4 (]: Began running node model.quant_features.alpha_factors_final
[0m17:56:02.152067 [debug] [Thread-1 (]: Began running node model.quant_features.alpha101_complete
[0m17:56:02.152635 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab599753-5ebe-419a-ae28-40f33bd323bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55738abe30>]}
[0m17:56:02.153033 [info ] [Thread-4 (]: 9 of 11 SKIP relation main.alpha_factors_final ................................. [[33mSKIP[0m]
[0m17:56:02.153593 [info ] [Thread-1 (]: 10 of 11 SKIP relation main.alpha101_complete .................................. [[33mSKIP[0m]
[0m17:56:02.154193 [info ] [Thread-3 (]: 3 of 11 OK created sql table model main.mart_technical_indicators .............. [[32mOK[0m in 0.08s]
[0m17:56:02.154732 [debug] [Thread-4 (]: Finished running node model.quant_features.alpha_factors_final
[0m17:56:02.155134 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha101_complete
[0m17:56:02.155795 [debug] [Thread-3 (]: Finished running node model.quant_features.mart_technical_indicators
[0m17:56:02.156924 [debug] [Thread-2 (]: Began running node model.quant_features.features_ohlc_technical
[0m17:56:02.157362 [info ] [Thread-2 (]: 11 of 11 START sql table model main.features_ohlc_technical .................... [RUN]
[0m17:56:02.157690 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.quant_features.alpha_base_data, now model.quant_features.features_ohlc_technical)
[0m17:56:02.157933 [debug] [Thread-2 (]: Began compiling node model.quant_features.features_ohlc_technical
[0m17:56:02.160919 [debug] [Thread-2 (]: Writing injected SQL for node "model.quant_features.features_ohlc_technical"
[0m17:56:02.161539 [debug] [Thread-2 (]: Began executing node model.quant_features.features_ohlc_technical
[0m17:56:02.163679 [debug] [Thread-2 (]: Writing runtime sql for node "model.quant_features.features_ohlc_technical"
[0m17:56:02.164225 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:02.164459 [debug] [Thread-2 (]: On model.quant_features.features_ohlc_technical: BEGIN
[0m17:56:02.164655 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m17:56:02.165152 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m17:56:02.165405 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:02.165699 [debug] [Thread-2 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

  
    
    

    create  table
      "quant_features"."main"."features_ohlc_technical__dbt_tmp"
  
    as (
      

with technical_data as (
    select * from "quant_features"."main"."mart_technical_indicators"
),

feature_engineering as (
    select 
        symbol,
        timestamp,
        
        -- 基础价格特征
        close as price,
        daily_return,
        volatility_20d,
        
        -- 趋势特征
        ma_5,
        ma_10,
        ma_20,
        case when close > ma_5 then 1 else 0 end as price_above_ma5,
        case when close > ma_10 then 1 else 0 end as price_above_ma10,
        case when close > ma_20 then 1 else 0 end as price_above_ma20,
        case when ma_5 > ma_10 then 1 else 0 end as ma5_above_ma10,
        case when ma_10 > ma_20 then 1 else 0 end as ma10_above_ma20,
        
        -- 技术指标特征
        rsi_14,
        case when rsi_14 > 70 then 1 else 0 end as rsi_overbought,
        case when rsi_14 < 30 then 1 else 0 end as rsi_oversold,
        
        stoch_k_14,
        case when stoch_k_14 > 0.8 then 1 else 0 end as stoch_overbought,
        case when stoch_k_14 < 0.2 then 1 else 0 end as stoch_oversold,
        
        -- 布林带特征
        bollinger_upper,
        bollinger_lower,
        case when close > bollinger_upper then 1 else 0 end as price_above_bb_upper,
        case when close < bollinger_lower then 1 else 0 end as price_below_bb_lower,
        case 
            when bollinger_upper - bollinger_lower != 0 
            then (close - bollinger_lower) / (bollinger_upper - bollinger_lower)
            else 0.5
        end as bb_position,
        
        -- 动量特征
        momentum_5d,
        momentum_10d,
        case when momentum_5d > 0 then 1 else 0 end as momentum_5d_positive,
        case when momentum_10d > 0 then 1 else 0 end as momentum_10d_positive,
        
        -- 成交量特征
        volume,
        avg_volume_20d,
        case when avg_volume_20d != 0 then volume / avg_volume_20d else 0 end as volume_ratio,
        case when volume > avg_volume_20d * 1.5 then 1 else 0 end as high_volume,
        
        -- 价格范围特征
        daily_range,
        case when lag(close) over (partition by symbol order by timestamp) != 0 
            then daily_range / lag(close) over (partition by symbol order by timestamp)
            else 0
        end as range_ratio,
        
        -- 组合特征
        case when rsi_14 > 70 and stoch_k_14 > 0.8 then 1 else 0 end as double_overbought,
        case when rsi_14 < 30 and stoch_k_14 < 0.2 then 1 else 0 end as double_oversold,
        
        -- 时间特征
        extract(hour from timestamp) as hour,
        extract(dow from timestamp) as day_of_week,
        extract(month from timestamp) as month,
        
        -- 标识特征用于Feast
        concat(symbol, '_', date_trunc('day', timestamp)::string) as entity_id,
        timestamp as event_timestamp
        
    from technical_data
    where timestamp >= current_date - interval '20' days
)

select * from feature_engineering
    );
  
  
[0m17:56:02.168997 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m17:56:02.171262 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:02.171537 [debug] [Thread-2 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */
alter table "quant_features"."main"."features_ohlc_technical__dbt_tmp" rename to "features_ohlc_technical"
[0m17:56:02.172051 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m17:56:02.173286 [debug] [Thread-2 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m17:56:02.173529 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:02.173722 [debug] [Thread-2 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m17:56:02.175948 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m17:56:02.177362 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:02.177603 [debug] [Thread-2 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

      drop table if exists "quant_features"."main"."features_ohlc_technical__dbt_backup" cascade
    
[0m17:56:02.178027 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m17:56:02.178993 [debug] [Thread-2 (]: On model.quant_features.features_ohlc_technical: Close
[0m17:56:02.179793 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ab599753-5ebe-419a-ae28-40f33bd323bc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55738a3650>]}
[0m17:56:02.180257 [info ] [Thread-2 (]: 11 of 11 OK created sql table model main.features_ohlc_technical ............... [[32mOK[0m in 0.02s]
[0m17:56:02.180587 [debug] [Thread-2 (]: Finished running node model.quant_features.features_ohlc_technical
[0m17:56:02.181861 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:02.182120 [debug] [MainThread]: On master: BEGIN
[0m17:56:02.182288 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:56:02.182676 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:02.182869 [debug] [MainThread]: On master: COMMIT
[0m17:56:02.183036 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:02.183215 [debug] [MainThread]: On master: COMMIT
[0m17:56:02.183539 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:02.183727 [debug] [MainThread]: On master: Close
[0m17:56:02.184022 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:56:02.184195 [debug] [MainThread]: Connection 'model.quant_features.stg_ohlc_data' was properly closed.
[0m17:56:02.184344 [debug] [MainThread]: Connection 'model.quant_features.mart_technical_indicators' was properly closed.
[0m17:56:02.184480 [debug] [MainThread]: Connection 'model.quant_features.features_ohlc_technical' was properly closed.
[0m17:56:02.184718 [info ] [MainThread]: 
[0m17:56:02.184928 [info ] [MainThread]: Finished running 10 table models, 1 view model in 0 hours 0 minutes and 0.29 seconds (0.29s).
[0m17:56:02.185658 [debug] [MainThread]: Command end result
[0m17:56:02.206262 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:56:02.207667 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:56:02.211972 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m17:56:02.212276 [info ] [MainThread]: 
[0m17:56:02.212539 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m17:56:02.212737 [info ] [MainThread]: 
[0m17:56:02.212965 [error] [MainThread]: [31mFailure in model alpha_base_data (models/alpha101/alpha_base_data.sql)[0m
[0m17:56:02.213208 [error] [MainThread]:   Runtime Error in model alpha_base_data (models/alpha101/alpha_base_data.sql)
  Binder Error: Could not choose a best candidate function for the function call "-(STRING_LITERAL, INTERVAL)". In order to select one, please add explicit type casts.
  	Candidate functions:
  	-(DATE, INTERVAL) -> TIMESTAMP
  	-(TIME, INTERVAL) -> TIME
  	-(TIMESTAMP, INTERVAL) -> TIMESTAMP
  	-(TIME WITH TIME ZONE, INTERVAL) -> TIME WITH TIME ZONE
  	-(TIMESTAMP WITH TIME ZONE, INTERVAL) -> TIMESTAMP WITH TIME ZONE
  	-(INTERVAL, INTERVAL) -> INTERVAL
  
  
  LINE 475:     WHERE timestamp >= '2020-01-01' - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数...
                                                ^
[0m17:56:02.213409 [info ] [MainThread]: 
[0m17:56:02.213611 [info ] [MainThread]:   compiled code at target/compiled/quant_features/models/alpha101/alpha_base_data.sql
[0m17:56:02.213773 [info ] [MainThread]: 
[0m17:56:02.213976 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=1 SKIP=7 NO-OP=0 TOTAL=11
[0m17:56:02.214679 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.7529666, "process_in_blocks": "0", "process_kernel_time": 0.176024, "process_mem_max_rss": "156952", "process_out_blocks": "3656", "process_user_time": 1.488144}
[0m17:56:02.215050 [debug] [MainThread]: Command `dbt run` failed at 17:56:02.214981 after 0.75 seconds
[0m17:56:02.215324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55788890f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f557ca41400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f557a3f5670>]}
[0m17:56:02.215574 [debug] [MainThread]: Flushing usage events
[0m17:56:07.639731 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:56:25.081065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a664f770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a7ca5a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a54c3d90>]}


============================== 17:56:25.083863 | 43962f08-a125-4242-9f72-298de1a7fb48 ==============================
[0m17:56:25.083863 [info ] [MainThread]: Running with dbt=1.10.9
[0m17:56:25.084635 [debug] [MainThread]: running dbt with arguments {'log_format': 'default', 'warn_error': 'None', 'printer_width': '80', 'invocation_command': 'dbt run --select alpha_base_data', 'indirect_selection': 'eager', 'empty': 'False', 'use_experimental_parser': 'False', 'partial_parse': 'True', 'target_path': 'None', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'static_parser': 'True', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'use_colors': 'True', 'quiet': 'False', 'profiles_dir': '/workspace/dbt_project', 'fail_fast': 'False', 'write_json': 'True', 'cache_selected_only': 'False', 'log_path': '/workspace/dbt_project/logs', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False'}
[0m17:56:25.226685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '43962f08-a125-4242-9f72-298de1a7fb48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a61da650>]}
[0m17:56:25.269340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '43962f08-a125-4242-9f72-298de1a7fb48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a55b6be0>]}
[0m17:56:25.270425 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m17:56:25.304685 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m17:56:25.387124 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m17:56:25.387613 [debug] [MainThread]: Partial parsing: updated file: quant_features://models/alpha101/alpha_base_data.sql
[0m17:56:25.657850 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `dbt_utils.accepted_range`. Arguments to
generic tests should be nested under the `arguments` property.`
[0m17:56:25.658435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '43962f08-a125-4242-9f72-298de1a7fb48', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a1514a50>]}
[0m17:56:25.777288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '43962f08-a125-4242-9f72-298de1a7fb48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a0fb6030>]}
[0m17:56:25.837666 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:56:25.838969 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:56:25.850534 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '43962f08-a125-4242-9f72-298de1a7fb48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a0f33690>]}
[0m17:56:25.850915 [info ] [MainThread]: Found 11 models, 37 data tests, 1 source, 565 macros
[0m17:56:25.851161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43962f08-a125-4242-9f72-298de1a7fb48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a06b7ee0>]}
[0m17:56:25.852507 [info ] [MainThread]: 
[0m17:56:25.852803 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:56:25.853000 [info ] [MainThread]: 
[0m17:56:25.853349 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m17:56:25.854255 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m17:56:25.870900 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m17:56:25.871166 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m17:56:25.871355 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:56:25.884146 [debug] [ThreadPool]: SQL status: OK in 0.013 seconds
[0m17:56:25.885066 [debug] [ThreadPool]: On list_quant_features: Close
[0m17:56:25.885747 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m17:56:25.886114 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m17:56:25.890461 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:25.890715 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m17:56:25.890895 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:56:25.891628 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:56:25.892497 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:25.892708 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m17:56:25.893104 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:25.893271 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:25.893431 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m17:56:25.893762 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:25.894333 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:56:25.894546 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:25.894708 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:56:25.895045 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:25.895252 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m17:56:25.899779 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m17:56:25.903541 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:56:25.903785 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m17:56:25.903970 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:56:25.904840 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:56:25.905024 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:56:25.905191 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m17:56:25.911965 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m17:56:25.912841 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m17:56:25.913545 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m17:56:25.913770 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m17:56:25.915116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '43962f08-a125-4242-9f72-298de1a7fb48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a10b7c50>]}
[0m17:56:25.915480 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:25.915667 [debug] [MainThread]: On master: BEGIN
[0m17:56:25.915825 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:56:25.916277 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:25.916487 [debug] [MainThread]: On master: COMMIT
[0m17:56:25.916652 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:25.916812 [debug] [MainThread]: On master: COMMIT
[0m17:56:25.917171 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:25.917348 [debug] [MainThread]: On master: Close
[0m17:56:25.920766 [debug] [Thread-1 (]: Began running node model.quant_features.alpha_base_data
[0m17:56:25.921196 [info ] [Thread-1 (]: 1 of 1 START sql table model main.alpha_base_data .............................. [RUN]
[0m17:56:25.921516 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.alpha_base_data)
[0m17:56:25.921737 [debug] [Thread-1 (]: Began compiling node model.quant_features.alpha_base_data
[0m17:56:25.935524 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.alpha_base_data"
[0m17:56:25.935993 [debug] [Thread-1 (]: Began executing node model.quant_features.alpha_base_data
[0m17:56:25.956375 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.alpha_base_data"
[0m17:56:25.956882 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:25.957126 [debug] [Thread-1 (]: On model.quant_features.alpha_base_data: BEGIN
[0m17:56:25.957334 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:56:25.957851 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:56:25.958120 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:25.958572 [debug] [Thread-1 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_base_data__dbt_tmp"
  
    as (
      

-- Alpha 101 基础数据准备
-- 为Alpha因子计算准备所有必要的基础数据

WITH base_ohlc AS (
    SELECT 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算VWAP (简化版本，假设等权重)
        (high + low + close) / 3 AS vwap,
        -- 计算returns
        CASE 
            WHEN LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp) IS NOT NULL
            THEN (close - LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)) / 
                 LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)
            ELSE 0
        END AS returns
    FROM "quant_features"."main"."stg_ohlc_data"
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
),

enhanced_data AS (
    SELECT 
        *,
        -- 计算ADV (Average Daily Volume)
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 AS adv20,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

 AS adv10,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

 AS adv5,
        
        -- 预计算一些常用的时间序列指标
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_ma5,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ma10,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_ma20,
        
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_ma20,
        
        -- 预计算滚动标准差
        
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_std20,
        
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS returns_std20,
        
        -- 预计算一些延迟项
        
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag1,
        
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag2,
        
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag5,
        
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag10,
        
    LAG(close, 20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag20,
        
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS volume_lag1,
        
    LAG(high, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS high_lag1,
        
    LAG(low, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS low_lag1,
        
    LAG(vwap, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS vwap_lag5,
        
        -- 预计算一些差值项
        
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta1,
        
    close - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta2,
        
    close - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta3,
        
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta5,
        
    close - 
    LAG(close, 7) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta7,
        
    close - 
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta10,
        
    volume - 
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta1,
        
    volume - 
    LAG(volume, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta3,
        
    high - 
    LAG(high, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS high_delta2,
        
        -- 预计算一些排序项
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
 AS close_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
 AS volume_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
 AS high_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
 AS low_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
 AS vwap_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns
    )
 AS returns_rank,
        
        -- 预计算时间序列排序
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ts_rank10,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_ts_rank5,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY high
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_ts_rank5,
        
        -- 预计算一些最值项
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_min100,
        
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS close_max3,
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_min5,
        
    MAX(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_max5,
        
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS low_min5,
        
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS high_max3,
        
        -- 预计算一些求和项
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_sum5,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS close_sum8,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_sum20,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_sum100,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
    )
 AS close_sum200,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_sum5,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_sum20,
        
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 AS returns_sum250,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_sum5,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS high_sum20,
        
        -- 预计算一些相关性
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_close_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(open, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_open_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS corr_high_volume_5,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS corr_vwap_volume_6,
        
        -- 预计算一些协方差
        
    COVAR_SAMP(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_close_volume_5,
        
    COVAR_SAMP(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_high_volume_5
        
    FROM base_ohlc
    WHERE timestamp >= CAST('2020-01-01' AS DATE) - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数据
),

-- 过滤回原始时间范围
final_data AS (
    SELECT *
    FROM enhanced_data
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
)

SELECT * FROM final_data
    );
  
  
[0m17:56:25.990015 [debug] [Thread-1 (]: SQL status: OK in 0.031 seconds
[0m17:56:25.994202 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:25.994496 [debug] [Thread-1 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */
alter table "quant_features"."main"."alpha_base_data__dbt_tmp" rename to "alpha_base_data"
[0m17:56:25.995063 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:56:26.003949 [debug] [Thread-1 (]: On model.quant_features.alpha_base_data: COMMIT
[0m17:56:26.004236 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:26.004510 [debug] [Thread-1 (]: On model.quant_features.alpha_base_data: COMMIT
[0m17:56:26.007152 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m17:56:26.010911 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:26.011199 [debug] [Thread-1 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

      drop table if exists "quant_features"."main"."alpha_base_data__dbt_backup" cascade
    
[0m17:56:26.011616 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:56:26.013132 [debug] [Thread-1 (]: On model.quant_features.alpha_base_data: Close
[0m17:56:26.015472 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43962f08-a125-4242-9f72-298de1a7fb48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a12cfe30>]}
[0m17:56:26.015963 [info ] [Thread-1 (]: 1 of 1 OK created sql table model main.alpha_base_data ......................... [[32mOK[0m in 0.09s]
[0m17:56:26.016325 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha_base_data
[0m17:56:26.018494 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:26.018720 [debug] [MainThread]: On master: BEGIN
[0m17:56:26.018900 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:56:26.019281 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:26.019487 [debug] [MainThread]: On master: COMMIT
[0m17:56:26.019655 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:26.019800 [debug] [MainThread]: On master: COMMIT
[0m17:56:26.020075 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:26.020241 [debug] [MainThread]: On master: Close
[0m17:56:26.020517 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:56:26.020677 [debug] [MainThread]: Connection 'model.quant_features.alpha_base_data' was properly closed.
[0m17:56:26.020877 [info ] [MainThread]: 
[0m17:56:26.021117 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.17 seconds (0.17s).
[0m17:56:26.021524 [debug] [MainThread]: Command end result
[0m17:56:26.040285 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:56:26.041442 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:56:26.045329 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m17:56:26.045564 [info ] [MainThread]: 
[0m17:56:26.045797 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:56:26.046007 [info ] [MainThread]: 
[0m17:56:26.046197 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m17:56:26.046504 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 4 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m17:56:26.047156 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.0047523, "process_in_blocks": "0", "process_kernel_time": 0.203384, "process_mem_max_rss": "172392", "process_out_blocks": "4904", "process_user_time": 1.766625}
[0m17:56:26.047487 [debug] [MainThread]: Command `dbt run` succeeded at 17:56:26.047417 after 1.01 seconds
[0m17:56:26.047729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a03c71b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a04bfd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45a14c6ed0>]}
[0m17:56:26.047945 [debug] [MainThread]: Flushing usage events
[0m17:56:31.900863 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:56:39.636422 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff889773770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88adc5a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8885f3d90>]}


============================== 17:56:39.638840 | 842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38 ==============================
[0m17:56:39.638840 [info ] [MainThread]: Running with dbt=1.10.9
[0m17:56:39.639184 [debug] [MainThread]: running dbt with arguments {'use_colors': 'True', 'introspect': 'True', 'printer_width': '80', 'partial_parse': 'True', 'use_experimental_parser': 'False', 'version_check': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'invocation_command': 'dbt run', 'warn_error': 'None', 'target_path': 'None', 'cache_selected_only': 'False', 'indirect_selection': 'eager', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/workspace/dbt_project/logs', 'empty': 'False', 'quiet': 'False', 'static_parser': 'True', 'no_print': 'None', 'profiles_dir': '/workspace/dbt_project', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'log_format': 'default', 'log_cache_events': 'False'}
[0m17:56:39.774614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88930a650>]}
[0m17:56:39.815923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8886e6be0>]}
[0m17:56:39.816899 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m17:56:39.845663 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m17:56:39.924043 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:56:39.924288 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:56:39.954602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff884f01450>]}
[0m17:56:40.017106 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:56:40.018295 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:56:40.028169 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff884f34e60>]}
[0m17:56:40.028500 [info ] [MainThread]: Found 11 models, 37 data tests, 1 source, 565 macros
[0m17:56:40.028729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff884f74130>]}
[0m17:56:40.030287 [info ] [MainThread]: 
[0m17:56:40.030543 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:56:40.030714 [info ] [MainThread]: 
[0m17:56:40.031001 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m17:56:40.034798 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m17:56:40.054327 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m17:56:40.054672 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m17:56:40.054862 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:56:40.068191 [debug] [ThreadPool]: SQL status: OK in 0.013 seconds
[0m17:56:40.069195 [debug] [ThreadPool]: On list_quant_features: Close
[0m17:56:40.069871 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m17:56:40.070235 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m17:56:40.074725 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:40.074985 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m17:56:40.075180 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:56:40.076004 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:56:40.076904 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:40.077129 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m17:56:40.077454 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:40.077624 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:40.077778 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m17:56:40.078157 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:40.078711 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:56:40.078904 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:40.079074 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:56:40.079362 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:40.079551 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m17:56:40.081659 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m17:56:40.086336 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:56:40.086649 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m17:56:40.086831 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:56:40.087444 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:56:40.087645 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:56:40.087805 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m17:56:40.099970 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m17:56:40.101817 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m17:56:40.102811 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m17:56:40.103061 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m17:56:40.104759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff884042680>]}
[0m17:56:40.105299 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:40.105488 [debug] [MainThread]: On master: BEGIN
[0m17:56:40.105647 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:56:40.106160 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:40.106390 [debug] [MainThread]: On master: COMMIT
[0m17:56:40.106560 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:40.106712 [debug] [MainThread]: On master: COMMIT
[0m17:56:40.106988 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:40.107187 [debug] [MainThread]: On master: Close
[0m17:56:40.109802 [debug] [Thread-1 (]: Began running node model.quant_features.stg_ohlc_data
[0m17:56:40.110318 [info ] [Thread-1 (]: 1 of 11 START sql view model main.stg_ohlc_data ................................ [RUN]
[0m17:56:40.110631 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.stg_ohlc_data)
[0m17:56:40.110855 [debug] [Thread-1 (]: Began compiling node model.quant_features.stg_ohlc_data
[0m17:56:40.117075 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.stg_ohlc_data"
[0m17:56:40.117539 [debug] [Thread-1 (]: Began executing node model.quant_features.stg_ohlc_data
[0m17:56:40.140729 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.stg_ohlc_data"
[0m17:56:40.141216 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:40.141462 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: BEGIN
[0m17:56:40.141663 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:56:40.142167 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:56:40.142391 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:40.142608 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

  
  create view "quant_features"."main"."stg_ohlc_data__dbt_tmp" as (
    

with raw_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 数据清洗和验证
        case 
            when open <= 0 or high <= 0 or low <= 0 or close <= 0 then null
            when high < greatest(open, close, low) then null
            when low > least(open, close, high) then null
            else timestamp
        end as valid_timestamp
    from "quant_features"."raw"."ohlc_data"
),

cleaned_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础指标
        (high + low + close) / 3 as typical_price,
        (high - low) as daily_range,
        case when open != 0 then (close - open) / open else 0 end as daily_return,
        case when close != 0 then volume / close else 0 end as volume_price_ratio
    from raw_ohlc
    where valid_timestamp is not null
      and timestamp >= '2020-01-01'
      and timestamp <= '2024-12-31'
)

select * from cleaned_ohlc
  );

[0m17:56:40.143524 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m17:56:40.185198 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:40.185471 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */
alter view "quant_features"."main"."stg_ohlc_data" rename to "stg_ohlc_data__dbt_backup"
[0m17:56:40.185998 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:56:40.187677 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:40.187930 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */
alter view "quant_features"."main"."stg_ohlc_data__dbt_tmp" rename to "stg_ohlc_data"
[0m17:56:40.188379 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:56:40.195944 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m17:56:40.196234 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:40.196431 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m17:56:40.198535 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m17:56:40.202274 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:40.202542 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

      drop view if exists "quant_features"."main"."stg_ohlc_data__dbt_backup" cascade
    
[0m17:56:40.204643 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m17:56:40.206325 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: Close
[0m17:56:40.207600 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88402f890>]}
[0m17:56:40.208065 [info ] [Thread-1 (]: 1 of 11 OK created sql view model main.stg_ohlc_data ........................... [[32mOK[0m in 0.10s]
[0m17:56:40.208434 [debug] [Thread-1 (]: Finished running node model.quant_features.stg_ohlc_data
[0m17:56:40.209492 [debug] [Thread-3 (]: Began running node model.quant_features.mart_technical_indicators
[0m17:56:40.210025 [info ] [Thread-3 (]: 3 of 11 START sql table model main.mart_technical_indicators ................... [RUN]
[0m17:56:40.210436 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.quant_features.mart_technical_indicators'
[0m17:56:40.210648 [debug] [Thread-3 (]: Began compiling node model.quant_features.mart_technical_indicators
[0m17:56:40.213367 [debug] [Thread-3 (]: Writing injected SQL for node "model.quant_features.mart_technical_indicators"
[0m17:56:40.213993 [debug] [Thread-2 (]: Began running node model.quant_features.alpha_base_data
[0m17:56:40.214448 [debug] [Thread-3 (]: Began executing node model.quant_features.mart_technical_indicators
[0m17:56:40.214949 [info ] [Thread-2 (]: 2 of 11 START sql table model main.alpha_base_data ............................. [RUN]
[0m17:56:40.225803 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.quant_features.alpha_base_data'
[0m17:56:40.226167 [debug] [Thread-2 (]: Began compiling node model.quant_features.alpha_base_data
[0m17:56:40.234777 [debug] [Thread-3 (]: Writing runtime sql for node "model.quant_features.mart_technical_indicators"
[0m17:56:40.250293 [debug] [Thread-2 (]: Writing injected SQL for node "model.quant_features.alpha_base_data"
[0m17:56:40.250847 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:40.251237 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: BEGIN
[0m17:56:40.251464 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m17:56:40.252073 [debug] [Thread-2 (]: Began executing node model.quant_features.alpha_base_data
[0m17:56:40.254283 [debug] [Thread-2 (]: Writing runtime sql for node "model.quant_features.alpha_base_data"
[0m17:56:40.254720 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:40.254942 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: BEGIN
[0m17:56:40.255140 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:56:40.255599 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m17:56:40.255827 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:40.256302 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_base_data__dbt_tmp"
  
    as (
      

-- Alpha 101 基础数据准备
-- 为Alpha因子计算准备所有必要的基础数据

WITH base_ohlc AS (
    SELECT 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算VWAP (简化版本，假设等权重)
        (high + low + close) / 3 AS vwap,
        -- 计算returns
        CASE 
            WHEN LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp) IS NOT NULL
            THEN (close - LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)) / 
                 LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)
            ELSE 0
        END AS returns
    FROM "quant_features"."main"."stg_ohlc_data"
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
),

enhanced_data AS (
    SELECT 
        *,
        -- 计算ADV (Average Daily Volume)
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 AS adv20,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

 AS adv10,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

 AS adv5,
        
        -- 预计算一些常用的时间序列指标
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_ma5,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ma10,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_ma20,
        
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_ma20,
        
        -- 预计算滚动标准差
        
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_std20,
        
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS returns_std20,
        
        -- 预计算一些延迟项
        
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag1,
        
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag2,
        
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag5,
        
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag10,
        
    LAG(close, 20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag20,
        
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS volume_lag1,
        
    LAG(high, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS high_lag1,
        
    LAG(low, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS low_lag1,
        
    LAG(vwap, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS vwap_lag5,
        
        -- 预计算一些差值项
        
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta1,
        
    close - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta2,
        
    close - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta3,
        
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta5,
        
    close - 
    LAG(close, 7) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta7,
        
    close - 
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta10,
        
    volume - 
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta1,
        
    volume - 
    LAG(volume, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta3,
        
    high - 
    LAG(high, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS high_delta2,
        
        -- 预计算一些排序项
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
 AS close_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
 AS volume_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
 AS high_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
 AS low_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
 AS vwap_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns
    )
 AS returns_rank,
        
        -- 预计算时间序列排序
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ts_rank10,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_ts_rank5,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY high
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_ts_rank5,
        
        -- 预计算一些最值项
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_min100,
        
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS close_max3,
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_min5,
        
    MAX(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_max5,
        
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS low_min5,
        
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS high_max3,
        
        -- 预计算一些求和项
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_sum5,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS close_sum8,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_sum20,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_sum100,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
    )
 AS close_sum200,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_sum5,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_sum20,
        
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 AS returns_sum250,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_sum5,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS high_sum20,
        
        -- 预计算一些相关性
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_close_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(open, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_open_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS corr_high_volume_5,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS corr_vwap_volume_6,
        
        -- 预计算一些协方差
        
    COVAR_SAMP(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_close_volume_5,
        
    COVAR_SAMP(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_high_volume_5
        
    FROM base_ohlc
    WHERE timestamp >= CAST('2020-01-01' AS DATE) - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数据
),

-- 过滤回原始时间范围
final_data AS (
    SELECT *
    FROM enhanced_data
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
)

SELECT * FROM final_data
    );
  
  
[0m17:56:40.257353 [debug] [Thread-3 (]: SQL status: OK in 0.006 seconds
[0m17:56:40.257660 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:40.257986 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */

  
    
    

    create  table
      "quant_features"."main"."mart_technical_indicators__dbt_tmp"
  
    as (
      

with base_data as (
    select * from "quant_features"."main"."stg_ohlc_data"
),

technical_indicators as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        typical_price,
        daily_range,
        daily_return,
        volume_price_ratio,
        
        -- 移动平均线
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 4 preceding and current row
        ) as ma_5,
        
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 9 preceding and current row
        ) as ma_10,
        
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as ma_20,
        
        -- 波动率 (标准差)
        stddev(daily_return) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as volatility_20d,
        
        -- RSI相关计算
        case when daily_return > 0 then daily_return else 0 end as gain,
        case when daily_return < 0 then abs(daily_return) else 0 end as loss,
        
        -- 价格位置指标
        (close - min(low) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        )) / nullif((max(high) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) - min(low) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        )), 0) as stoch_k_14,
        
        -- 成交量指标
        avg(volume) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as avg_volume_20d
        
    from base_data
),

rsi_calculation as (
    select *,
        -- RSI计算
        avg(gain) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) as avg_gain_14,
        
        avg(loss) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) as avg_loss_14
    from technical_indicators
),

final_indicators as (
    select *,
        case 
            when avg_loss_14 = 0 then 100
            when avg_gain_14 = 0 then 0
            else 100 - (100 / (1 + (avg_gain_14 / avg_loss_14)))
        end as rsi_14,
        
        -- 布林带
        ma_20 + (2 * stddev(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        )) as bollinger_upper,
        
        ma_20 - (2 * stddev(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        )) as bollinger_lower,
        
        -- 价格动量
        case when lag(close, 5) over (partition by symbol order by timestamp) != 0 
            then (close - lag(close, 5) over (partition by symbol order by timestamp)) / 
                 lag(close, 5) over (partition by symbol order by timestamp)
            else 0 
        end as momentum_5d,
        
        case when lag(close, 10) over (partition by symbol order by timestamp) != 0 
            then (close - lag(close, 10) over (partition by symbol order by timestamp)) / 
                 lag(close, 10) over (partition by symbol order by timestamp)
            else 0 
        end as momentum_10d
        
    from rsi_calculation
)

select * from final_indicators
    );
  
  
[0m17:56:40.269728 [debug] [Thread-3 (]: SQL status: OK in 0.011 seconds
[0m17:56:40.272226 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:40.272567 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */
alter table "quant_features"."main"."mart_technical_indicators" rename to "mart_technical_indicators__dbt_backup"
[0m17:56:40.273499 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m17:56:40.275514 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:40.275958 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */
alter table "quant_features"."main"."mart_technical_indicators__dbt_tmp" rename to "mart_technical_indicators"
[0m17:56:40.276592 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m17:56:40.280127 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: COMMIT
[0m17:56:40.280413 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:40.280614 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: COMMIT
[0m17:56:40.282394 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m17:56:40.284091 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:40.284410 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */

      drop table if exists "quant_features"."main"."mart_technical_indicators__dbt_backup" cascade
    
[0m17:56:40.286463 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m17:56:40.287536 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: Close
[0m17:56:40.288855 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8841c6150>]}
[0m17:56:40.289327 [info ] [Thread-3 (]: 3 of 11 OK created sql table model main.mart_technical_indicators .............. [[32mOK[0m in 0.08s]
[0m17:56:40.289726 [debug] [Thread-3 (]: Finished running node model.quant_features.mart_technical_indicators
[0m17:56:40.290296 [debug] [Thread-4 (]: Began running node model.quant_features.features_ohlc_technical
[0m17:56:40.290734 [info ] [Thread-4 (]: 4 of 11 START sql table model main.features_ohlc_technical ..................... [RUN]
[0m17:56:40.291106 [debug] [Thread-2 (]: SQL status: OK in 0.034 seconds
[0m17:56:40.291626 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.quant_features.features_ohlc_technical'
[0m17:56:40.293643 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:40.294019 [debug] [Thread-4 (]: Began compiling node model.quant_features.features_ohlc_technical
[0m17:56:40.294510 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */
alter table "quant_features"."main"."alpha_base_data" rename to "alpha_base_data__dbt_backup"
[0m17:56:40.297641 [debug] [Thread-4 (]: Writing injected SQL for node "model.quant_features.features_ohlc_technical"
[0m17:56:40.298342 [debug] [Thread-4 (]: Began executing node model.quant_features.features_ohlc_technical
[0m17:56:40.298775 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m17:56:40.300926 [debug] [Thread-4 (]: Writing runtime sql for node "model.quant_features.features_ohlc_technical"
[0m17:56:40.303593 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:40.304351 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:40.304738 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */
alter table "quant_features"."main"."alpha_base_data__dbt_tmp" rename to "alpha_base_data"
[0m17:56:40.305079 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: BEGIN
[0m17:56:40.305434 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m17:56:40.305961 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m17:56:40.306962 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: COMMIT
[0m17:56:40.307223 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:40.307432 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: COMMIT
[0m17:56:40.307698 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m17:56:40.308265 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:40.308583 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

  
    
    

    create  table
      "quant_features"."main"."features_ohlc_technical__dbt_tmp"
  
    as (
      

with technical_data as (
    select * from "quant_features"."main"."mart_technical_indicators"
),

feature_engineering as (
    select 
        symbol,
        timestamp,
        
        -- 基础价格特征
        close as price,
        daily_return,
        volatility_20d,
        
        -- 趋势特征
        ma_5,
        ma_10,
        ma_20,
        case when close > ma_5 then 1 else 0 end as price_above_ma5,
        case when close > ma_10 then 1 else 0 end as price_above_ma10,
        case when close > ma_20 then 1 else 0 end as price_above_ma20,
        case when ma_5 > ma_10 then 1 else 0 end as ma5_above_ma10,
        case when ma_10 > ma_20 then 1 else 0 end as ma10_above_ma20,
        
        -- 技术指标特征
        rsi_14,
        case when rsi_14 > 70 then 1 else 0 end as rsi_overbought,
        case when rsi_14 < 30 then 1 else 0 end as rsi_oversold,
        
        stoch_k_14,
        case when stoch_k_14 > 0.8 then 1 else 0 end as stoch_overbought,
        case when stoch_k_14 < 0.2 then 1 else 0 end as stoch_oversold,
        
        -- 布林带特征
        bollinger_upper,
        bollinger_lower,
        case when close > bollinger_upper then 1 else 0 end as price_above_bb_upper,
        case when close < bollinger_lower then 1 else 0 end as price_below_bb_lower,
        case 
            when bollinger_upper - bollinger_lower != 0 
            then (close - bollinger_lower) / (bollinger_upper - bollinger_lower)
            else 0.5
        end as bb_position,
        
        -- 动量特征
        momentum_5d,
        momentum_10d,
        case when momentum_5d > 0 then 1 else 0 end as momentum_5d_positive,
        case when momentum_10d > 0 then 1 else 0 end as momentum_10d_positive,
        
        -- 成交量特征
        volume,
        avg_volume_20d,
        case when avg_volume_20d != 0 then volume / avg_volume_20d else 0 end as volume_ratio,
        case when volume > avg_volume_20d * 1.5 then 1 else 0 end as high_volume,
        
        -- 价格范围特征
        daily_range,
        case when lag(close) over (partition by symbol order by timestamp) != 0 
            then daily_range / lag(close) over (partition by symbol order by timestamp)
            else 0
        end as range_ratio,
        
        -- 组合特征
        case when rsi_14 > 70 and stoch_k_14 > 0.8 then 1 else 0 end as double_overbought,
        case when rsi_14 < 30 and stoch_k_14 < 0.2 then 1 else 0 end as double_oversold,
        
        -- 时间特征
        extract(hour from timestamp) as hour,
        extract(dow from timestamp) as day_of_week,
        extract(month from timestamp) as month,
        
        -- 标识特征用于Feast
        concat(symbol, '_', date_trunc('day', timestamp)::string) as entity_id,
        timestamp as event_timestamp
        
    from technical_data
    where timestamp >= current_date - interval '20' days
)

select * from feature_engineering
    );
  
  
[0m17:56:40.310091 [debug] [Thread-2 (]: SQL status: OK in 0.002 seconds
[0m17:56:40.311623 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:40.311900 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

      drop table if exists "quant_features"."main"."alpha_base_data__dbt_backup" cascade
    
[0m17:56:40.312523 [debug] [Thread-4 (]: SQL status: OK in 0.004 seconds
[0m17:56:40.314306 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:40.314757 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */
alter table "quant_features"."main"."features_ohlc_technical" rename to "features_ohlc_technical__dbt_backup"
[0m17:56:40.315086 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m17:56:40.316289 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: Close
[0m17:56:40.316713 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m17:56:40.319286 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:40.319764 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8805bf890>]}
[0m17:56:40.320106 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */
alter table "quant_features"."main"."features_ohlc_technical__dbt_tmp" rename to "features_ohlc_technical"
[0m17:56:40.320597 [info ] [Thread-2 (]: 2 of 11 OK created sql table model main.alpha_base_data ........................ [[32mOK[0m in 0.09s]
[0m17:56:40.321359 [debug] [Thread-2 (]: Finished running node model.quant_features.alpha_base_data
[0m17:56:40.321680 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m17:56:40.322704 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m17:56:40.322955 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:40.323165 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m17:56:40.323644 [debug] [Thread-3 (]: Began running node model.quant_features.alpha_factors_021_050
[0m17:56:40.323966 [debug] [Thread-1 (]: Began running node model.quant_features.alpha_factors_001_020
[0m17:56:40.324296 [debug] [Thread-2 (]: Began running node model.quant_features.alpha_factors_051_075
[0m17:56:40.324836 [info ] [Thread-3 (]: 6 of 11 START sql table model main.alpha_factors_021_050 ....................... [RUN]
[0m17:56:40.325382 [info ] [Thread-1 (]: 5 of 11 START sql table model main.alpha_factors_001_020 ....................... [RUN]
[0m17:56:40.325787 [info ] [Thread-2 (]: 7 of 11 START sql table model main.alpha_factors_051_075 ....................... [RUN]
[0m17:56:40.326171 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.quant_features.mart_technical_indicators, now model.quant_features.alpha_factors_021_050)
[0m17:56:40.326563 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.quant_features.stg_ohlc_data, now model.quant_features.alpha_factors_001_020)
[0m17:56:40.326930 [debug] [Thread-4 (]: SQL status: OK in 0.003 seconds
[0m17:56:40.327560 [debug] [Thread-2 (]: Re-using an available connection from the pool (formerly model.quant_features.alpha_base_data, now model.quant_features.alpha_factors_051_075)
[0m17:56:40.327985 [debug] [Thread-3 (]: Began compiling node model.quant_features.alpha_factors_021_050
[0m17:56:40.328331 [debug] [Thread-1 (]: Began compiling node model.quant_features.alpha_factors_001_020
[0m17:56:40.330119 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:40.330492 [debug] [Thread-2 (]: Began compiling node model.quant_features.alpha_factors_051_075
[0m17:56:40.347665 [debug] [Thread-3 (]: Writing injected SQL for node "model.quant_features.alpha_factors_021_050"
[0m17:56:40.353301 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

      drop table if exists "quant_features"."main"."features_ohlc_technical__dbt_backup" cascade
    
[0m17:56:40.357885 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.alpha_factors_001_020"
[0m17:56:40.377604 [debug] [Thread-3 (]: Began executing node model.quant_features.alpha_factors_021_050
[0m17:56:40.379785 [debug] [Thread-3 (]: Writing runtime sql for node "model.quant_features.alpha_factors_021_050"
[0m17:56:40.380316 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.alpha_factors_021_050"
[0m17:56:40.380576 [debug] [Thread-3 (]: On model.quant_features.alpha_factors_021_050: BEGIN
[0m17:56:40.380770 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:56:40.383132 [debug] [Thread-2 (]: Writing injected SQL for node "model.quant_features.alpha_factors_051_075"
[0m17:56:40.383685 [debug] [Thread-2 (]: Began executing node model.quant_features.alpha_factors_051_075
[0m17:56:40.389484 [debug] [Thread-2 (]: Writing runtime sql for node "model.quant_features.alpha_factors_051_075"
[0m17:56:40.389919 [debug] [Thread-1 (]: Began executing node model.quant_features.alpha_factors_001_020
[0m17:56:40.390512 [debug] [Thread-3 (]: SQL status: OK in 0.010 seconds
[0m17:56:40.393068 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.alpha_factors_001_020"
[0m17:56:40.393643 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_factors_051_075"
[0m17:56:40.394048 [debug] [Thread-4 (]: SQL status: OK in 0.017 seconds
[0m17:56:40.394501 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.alpha_factors_021_050"
[0m17:56:40.395100 [debug] [Thread-2 (]: On model.quant_features.alpha_factors_051_075: BEGIN
[0m17:56:40.395715 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.alpha_factors_001_020"
[0m17:56:40.396977 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: Close
[0m17:56:40.397931 [debug] [Thread-3 (]: On model.quant_features.alpha_factors_021_050: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_factors_021_050"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_factors_021_050__dbt_tmp"
  
    as (
      

-- Alpha 101 因子计算 (021-050)

WITH base_data AS (
    SELECT * FROM "quant_features"."main"."alpha_base_data"
),

-- 预计算复杂的中间变量
intermediate_calcs AS (
    SELECT 
        *,
        -- Alpha021 相关计算
        close_ma8 + close_std20 AS alpha021_ma8_plus_std,
        close_ma2 AS alpha021_ma2,
        close_ma8 - close_std20 AS alpha021_ma8_minus_std,
        
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END
 AS alpha021_vol_adv_ratio,
        
        -- Alpha022 相关计算
        
    
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 - 
    LAG(
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS alpha022_delta_corr,
        
        -- Alpha024 相关计算
        
    close_ma100 - 
    LAG(close_ma100, 100) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS alpha024_delta_ma100,
        
    CASE 
        WHEN 
    LAG(close, 100) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 = 0 OR 
    LAG(close, 100) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 IS NULL THEN NULL
        WHEN ABS(
    LAG(close, 100) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) < 1e-10 THEN NULL
        ELSE alpha024_delta_ma100 / 
    LAG(close, 100) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

    END
 AS alpha024_ratio,
        
        -- Alpha025 相关计算
        (-1 * returns) * adv20 * vwap * (high - close) AS alpha025_product,
        
        -- Alpha026 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY high
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha026_corr_ts_ranks,
        
        -- Alpha027 相关计算
        
    AVG(
    -- 使用DuckDB的CORR窗口函数
    CORR(volume_rank, vwap_rank) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
 AS alpha027_mean_corr,
        
        -- Alpha028 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(adv20, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 + (high + low) / 2 - close AS alpha028_expression,
        
        -- Alpha030 相关计算
        
    CASE 
        WHEN close_delta1 > 0 THEN 1
        WHEN close_delta1 < 0 THEN -1
        ELSE 0
    END
 + 
    CASE 
        WHEN 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 > 0 THEN 1
        WHEN 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 < 0 THEN -1
        ELSE 0
    END
 + 
        
    CASE 
        WHEN 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 > 0 THEN 1
        WHEN 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 < 0 THEN -1
        ELSE 0
    END
 AS alpha030_sign_sum,
        
        -- Alpha032 相关计算
        close_ma7 - close AS alpha032_ma_diff,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 229 PRECEDING AND CURRENT ROW
    )
 AS alpha032_corr_vwap_delay,
        
        -- Alpha033 相关计算
        1 - 
    CASE 
        WHEN close = 0 OR close IS NULL THEN NULL
        WHEN ABS(close) < 1e-10 THEN NULL
        ELSE open / close
    END
 AS alpha033_open_close_ratio,
        
        -- Alpha034 相关计算
        
    CASE 
        WHEN 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
 / 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

    END
 AS alpha034_std_ratio,
        
        -- Alpha035 相关计算
        close + high - low AS alpha035_price_sum,
        
        -- Alpha036 相关计算 (简化版)
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close - open, 
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )
 AS alpha036_corr1,
        open - close AS alpha036_open_close,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    LAG(-1 * returns, 6) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha036_ts_rank,
        
    ABS(
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, adv20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
)
 AS alpha036_abs_corr,
        (close_sum200 / 200 - open) * (close - open) AS alpha036_price_product,
        
        -- Alpha037 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    LAG(open - close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
, close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
    )
 AS alpha037_corr_delay,
        
        -- Alpha038 相关计算
        
    CASE 
        WHEN open = 0 OR open IS NULL THEN NULL
        WHEN ABS(open) < 1e-10 THEN NULL
        ELSE close / open
    END
 AS alpha038_close_open_ratio,
        
        -- Alpha039 相关计算
        close_delta7 * (1 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END
 * 
        (9 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (9 * (9 + 1) / 2)

    )
) AS alpha039_weighted_delta,
        
        -- Alpha043 相关计算
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END

        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS alpha043_ts_rank_vol,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY -1 * close_delta7
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS alpha043_ts_rank_delta,
        
        -- Alpha045 相关计算
        
    AVG(
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS alpha045_mean_delay_close,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
 AS alpha045_corr_close_vol,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close_sum5, close_sum20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
 AS alpha045_corr_sums,
        
        -- Alpha046-049 相关计算
        (close_lag20 - close_lag10) / 10 - (close_lag10 - close) / 10 AS alpha046_slope_diff,
        
        -- Alpha047 相关计算
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN close = 0 OR close IS NULL THEN NULL
        WHEN ABS(close) < 1e-10 THEN NULL
        ELSE 1 / close
    END

    )
 * volume / adv20 * high * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high - close
    )
 / (high_sum5 / 5) AS alpha047_complex1,
        vwap - vwap_lag5 AS alpha047_vwap_diff
        
    FROM base_data
),

-- 添加更多预计算的中间变量
more_intermediate AS (
    SELECT 
        *,
        -- 为Alpha036添加更多计算
        2.21 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_corr1
    )
 + 
        0.7 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_open_close
    )
 + 
        0.73 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_ts_rank
    )
 + 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_abs_corr
    )
 + 
        0.6 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_price_product
    )
 AS alpha036_combination
        
    FROM intermediate_calcs
),

-- 计算Alpha因子
alpha_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- Alpha 021
        CASE 
            WHEN alpha021_ma8_plus_std < alpha021_ma2 THEN -1
            WHEN alpha021_ma2 < alpha021_ma8_minus_std THEN 1
            WHEN alpha021_vol_adv_ratio >= 1 THEN 1
            ELSE -1
        END AS alpha021,
        
        -- Alpha 022: (-1 * (delta(correlation(high, volume, 5), 5) * rank(stddev(close, 20))))
        -1 * alpha022_delta_corr * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close_std20
    )
 AS alpha022,
        
        -- Alpha 023: (((sum(high, 20) / 20) < high) ? (-1 * delta(high, 2)) : 0)
        CASE 
            WHEN (high_sum20 / 20) < high THEN -1 * high_delta2
            ELSE 0
        END AS alpha023,
        
        -- Alpha 024
        CASE 
            WHEN alpha024_ratio <= 0.05 THEN -1 * (close - close_min100)
            ELSE -1 * close_delta3
        END AS alpha024,
        
        -- Alpha 025: rank(((((-1 * returns) * adv20) * vwap) * (high - close)))
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha025_product
    )
 AS alpha025,
        
        -- Alpha 026: (-1 * ts_max(correlation(ts_rank(volume, 5), ts_rank(high, 5), 5), 3))
        -1 * 
    MAX(alpha026_corr_ts_ranks) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha026,
        
        -- Alpha 027
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha027_mean_corr
    )
 > 0.5 THEN -1
            ELSE 1
        END AS alpha027,
        
        -- Alpha 028: scale(((correlation(adv20, low, 5) + ((high + low) / 2)) - close))
        
    alpha028_expression / NULLIF(
        SUM(ABS(alpha028_expression)) OVER (PARTITION BY timestamp), 0
    )
 AS alpha028,
        
        -- Alpha 029: 简化版本
        
    MIN(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    LAG(-1 * returns, 6) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha029,
        
        -- Alpha 030
        (1.0 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha030_sign_sum
    )
) * 
    CASE 
        WHEN volume_sum20 = 0 OR volume_sum20 IS NULL THEN NULL
        WHEN ABS(volume_sum20) < 1e-10 THEN NULL
        ELSE volume_sum5 / volume_sum20
    END
 AS alpha030,
        
        -- Alpha 031: 简化版本
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close_delta10
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY -1 * close_delta3
    )
 + 
        
    CASE 
        WHEN 
    
    -- 使用DuckDB的CORR窗口函数
    CORR(adv20, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 / NULLIF(
        SUM(ABS(
    -- 使用DuckDB的CORR窗口函数
    CORR(adv20, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
)) OVER (PARTITION BY timestamp), 0
    )
 > 0 THEN 1
        WHEN 
    
    -- 使用DuckDB的CORR窗口函数
    CORR(adv20, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 / NULLIF(
        SUM(ABS(
    -- 使用DuckDB的CORR窗口函数
    CORR(adv20, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
)) OVER (PARTITION BY timestamp), 0
    )
 < 0 THEN -1
        ELSE 0
    END
 AS alpha031,
        
        -- Alpha 032
        
    alpha032_ma_diff / NULLIF(
        SUM(ABS(alpha032_ma_diff)) OVER (PARTITION BY timestamp), 0
    )
 + 20 * 
    alpha032_corr_vwap_delay / NULLIF(
        SUM(ABS(alpha032_corr_vwap_delay)) OVER (PARTITION BY timestamp), 0
    )
 AS alpha032,
        
        -- Alpha 033: rank((-1 * ((1 - (open / close))^1)))
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY -1 * alpha033_open_close_ratio
    )
 AS alpha033,
        
        -- Alpha 034
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY (1 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha034_std_ratio
    )
) + (1 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close_delta1
    )
)
    )
 AS alpha034,
        
        -- Alpha 035
        volume_ts_rank5 * (1 - 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha035_price_sum
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    )
) * 
        (1 - 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY returns
        ROWS BETWEEN 31 PRECEDING AND CURRENT ROW
    )
) AS alpha035,
        
        -- Alpha 036: 复杂组合因子
        alpha036_combination AS alpha036,
        
        -- Alpha 037
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha037_corr_delay
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_open_close
    )
 AS alpha037,
        
        -- Alpha 038
        (-1 * close_ts_rank10) * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha038_close_open_ratio
    )
 AS alpha038,
        
        -- Alpha 039
        (-1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha039_weighted_delta
    )
) * (1 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns_sum250
    )
) AS alpha039,
        
        -- Alpha 040: ((-1 * rank(stddev(high, 10))) * correlation(high, volume, 10))
        (-1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    STDDEV(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

    )
) * corr_high_volume_5 AS alpha040,
        
        -- Alpha 041: (((high * low)^0.5) - vwap)
        SQRT(high * low) - vwap AS alpha041,
        
        -- Alpha 042: (rank((vwap - close)) / rank((vwap + close)))
        
    CASE 
        WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap + close
    )
 = 0 OR 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap + close
    )
 IS NULL THEN NULL
        WHEN ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap + close
    )
) < 1e-10 THEN NULL
        ELSE 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap - close
    )
 / 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap + close
    )

    END
 AS alpha042,
        
        -- Alpha 043
        alpha043_ts_rank_vol * alpha043_ts_rank_delta AS alpha043,
        
        -- Alpha 044: (-1 * correlation(high, rank(volume), 5))
        -1 * 
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume_rank) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha044,
        
        -- Alpha 045
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha045_mean_delay_close
    )
 * alpha045_corr_close_vol * 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha045_corr_sums
    )
 AS alpha045,
        
        -- Alpha 046
        CASE 
            WHEN alpha046_slope_diff > 0.25 THEN -1
            WHEN alpha046_slope_diff < 0 THEN 1
            ELSE -1 * (close - close_lag1)
        END AS alpha046,
        
        -- Alpha 047
        alpha047_complex1 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha047_vwap_diff
    )
 AS alpha047,
        
        -- Alpha 048: 简化版本
        
    CASE 
        WHEN 
    SUM(POWER(
    CASE 
        WHEN close_lag1 = 0 OR close_lag1 IS NULL THEN NULL
        WHEN ABS(close_lag1) < 1e-10 THEN NULL
        ELSE close_delta1 / close_lag1
    END
, 2)) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    SUM(POWER(
    CASE 
        WHEN close_lag1 = 0 OR close_lag1 IS NULL THEN NULL
        WHEN ABS(close_lag1) < 1e-10 THEN NULL
        ELSE close_delta1 / close_lag1
    END
, 2)) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    SUM(POWER(
    CASE 
        WHEN close_lag1 = 0 OR close_lag1 IS NULL THEN NULL
        WHEN ABS(close_lag1) < 1e-10 THEN NULL
        ELSE close_delta1 / close_lag1
    END
, 2)) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE 
    -- 使用DuckDB的CORR窗口函数
    CORR(close_delta1, 
    close_lag1 - 
    LAG(close_lag1, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 * close_delta1 / close / 
    SUM(POWER(
    CASE 
        WHEN close_lag1 = 0 OR close_lag1 IS NULL THEN NULL
        WHEN ABS(close_lag1) < 1e-10 THEN NULL
        ELSE close_delta1 / close_lag1
    END
, 2)) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )

    END
 AS alpha048,
        
        -- Alpha 049
        CASE 
            WHEN alpha046_slope_diff < -0.1 THEN 1
            ELSE -1 * (close - close_lag1)
        END AS alpha049,
        
        -- Alpha 050: (-1 * ts_max(rank(correlation(rank(volume), rank(vwap), 5)), 5))
        -1 * 
    MAX(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(volume_rank, vwap_rank) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha050
        
    FROM more_intermediate
)

SELECT * FROM alpha_factors
    );
  
  
[0m17:56:40.398975 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m17:56:40.399518 [debug] [Thread-1 (]: On model.quant_features.alpha_factors_001_020: BEGIN
[0m17:56:40.401711 [debug] [Thread-3 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_factors_021_050"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_factors_021_050__dbt_tmp"
  
    as (
      

-- Alpha 101 因子计算 (021-050)

WITH base_data AS (
    SELECT * FROM "quant_features"."main"."alpha_base_data"
),

-- 预计算复杂的中间变量
intermediate_calcs AS (
    SELECT 
        *,
        -- Alpha021 相关计算
        close_ma8 + close_std20 AS alpha021_ma8_plus_std,
        close_ma2 AS alpha021_ma2,
        close_ma8 - close_std20 AS alpha021_ma8_minus_std,
        
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END
 AS alpha021_vol_adv_ratio,
        
        -- Alpha022 相关计算
        
    
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 - 
    LAG(
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS alpha022_delta_corr,
        
        -- Alpha024 相关计算
        
    close_ma100 - 
    LAG(close_ma100, 100) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS alpha024_delta_ma100,
        
    CASE 
        WHEN 
    LAG(close, 100) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 = 0 OR 
    LAG(close, 100) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 IS NULL THEN NULL
        WHEN ABS(
    LAG(close, 100) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) < 1e-10 THEN NULL
        ELSE alpha024_delta_ma100 / 
    LAG(close, 100) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

    END
 AS alpha024_ratio,
        
        -- Alpha025 相关计算
        (-1 * returns) * adv20 * vwap * (high - close) AS alpha025_product,
        
        -- Alpha026 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY high
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha026_corr_ts_ranks,
        
        -- Alpha027 相关计算
        
    AVG(
    -- 使用DuckDB的CORR窗口函数
    CORR(volume_rank, vwap_rank) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
 AS alpha027_mean_corr,
        
        -- Alpha028 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(adv20, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 + (high + low) / 2 - close AS alpha028_expression,
        
        -- Alpha030 相关计算
        
    CASE 
        WHEN close_delta1 > 0 THEN 1
        WHEN close_delta1 < 0 THEN -1
        ELSE 0
    END
 + 
    CASE 
        WHEN 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 > 0 THEN 1
        WHEN 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 < 0 THEN -1
        ELSE 0
    END
 + 
        
    CASE 
        WHEN 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 > 0 THEN 1
        WHEN 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 < 0 THEN -1
        ELSE 0
    END
 AS alpha030_sign_sum,
        
        -- Alpha032 相关计算
        close_ma7 - close AS alpha032_ma_diff,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 229 PRECEDING AND CURRENT ROW
    )
 AS alpha032_corr_vwap_delay,
        
        -- Alpha033 相关计算
        1 - 
    CASE 
        WHEN close = 0 OR close IS NULL THEN NULL
        WHEN ABS(close) < 1e-10 THEN NULL
        ELSE open / close
    END
 AS alpha033_open_close_ratio,
        
        -- Alpha034 相关计算
        
    CASE 
        WHEN 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
 / 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

    END
 AS alpha034_std_ratio,
        
        -- Alpha035 相关计算
        close + high - low AS alpha035_price_sum,
        
        -- Alpha036 相关计算 (简化版)
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close - open, 
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )
 AS alpha036_corr1,
        open - close AS alpha036_open_close,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    LAG(-1 * returns, 6) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha036_ts_rank,
        
    ABS(
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, adv20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
)
 AS alpha036_abs_corr,
        (close_sum200 / 200 - open) * (close - open) AS alpha036_price_product,
        
        -- Alpha037 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    LAG(open - close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
, close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
    )
 AS alpha037_corr_delay,
        
        -- Alpha038 相关计算
        
    CASE 
        WHEN open = 0 OR open IS NULL THEN NULL
        WHEN ABS(open) < 1e-10 THEN NULL
        ELSE close / open
    END
 AS alpha038_close_open_ratio,
        
        -- Alpha039 相关计算
        close_delta7 * (1 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END
 * 
        (9 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (9 * (9 + 1) / 2)

    )
) AS alpha039_weighted_delta,
        
        -- Alpha043 相关计算
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END

        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS alpha043_ts_rank_vol,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY -1 * close_delta7
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS alpha043_ts_rank_delta,
        
        -- Alpha045 相关计算
        
    AVG(
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS alpha045_mean_delay_close,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
 AS alpha045_corr_close_vol,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close_sum5, close_sum20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
 AS alpha045_corr_sums,
        
        -- Alpha046-049 相关计算
        (close_lag20 - close_lag10) / 10 - (close_lag10 - close) / 10 AS alpha046_slope_diff,
        
        -- Alpha047 相关计算
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN close = 0 OR close IS NULL THEN NULL
        WHEN ABS(close) < 1e-10 THEN NULL
        ELSE 1 / close
    END

    )
 * volume / adv20 * high * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high - close
    )
 / (high_sum5 / 5) AS alpha047_complex1,
        vwap - vwap_lag5 AS alpha047_vwap_diff
        
    FROM base_data
),

-- 添加更多预计算的中间变量
more_intermediate AS (
    SELECT 
        *,
        -- 为Alpha036添加更多计算
        2.21 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_corr1
    )
 + 
        0.7 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_open_close
    )
 + 
        0.73 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_ts_rank
    )
 + 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_abs_corr
    )
 + 
        0.6 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_price_product
    )
 AS alpha036_combination
        
    FROM intermediate_calcs
),

-- 计算Alpha因子
alpha_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- Alpha 021
        CASE 
            WHEN alpha021_ma8_plus_std < alpha021_ma2 THEN -1
            WHEN alpha021_ma2 < alpha021_ma8_minus_std THEN 1
            WHEN alpha021_vol_adv_ratio >= 1 THEN 1
            ELSE -1
        END AS alpha021,
        
        -- Alpha 022: (-1 * (delta(correlation(high, volume, 5), 5) * rank(stddev(close, 20))))
        -1 * alpha022_delta_corr * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close_std20
    )
 AS alpha022,
        
        -- Alpha 023: (((sum(high, 20) / 20) < high) ? (-1 * delta(high, 2)) : 0)
        CASE 
            WHEN (high_sum20 / 20) < high THEN -1 * high_delta2
            ELSE 0
        END AS alpha023,
        
        -- Alpha 024
        CASE 
            WHEN alpha024_ratio <= 0.05 THEN -1 * (close - close_min100)
            ELSE -1 * close_delta3
        END AS alpha024,
        
        -- Alpha 025: rank(((((-1 * returns) * adv20) * vwap) * (high - close)))
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha025_product
    )
 AS alpha025,
        
        -- Alpha 026: (-1 * ts_max(correlation(ts_rank(volume, 5), ts_rank(high, 5), 5), 3))
        -1 * 
    MAX(alpha026_corr_ts_ranks) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha026,
        
        -- Alpha 027
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha027_mean_corr
    )
 > 0.5 THEN -1
            ELSE 1
        END AS alpha027,
        
        -- Alpha 028: scale(((correlation(adv20, low, 5) + ((high + low) / 2)) - close))
        
    alpha028_expression / NULLIF(
        SUM(ABS(alpha028_expression)) OVER (PARTITION BY timestamp), 0
    )
 AS alpha028,
        
        -- Alpha 029: 简化版本
        
    MIN(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    LAG(-1 * returns, 6) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha029,
        
        -- Alpha 030
        (1.0 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha030_sign_sum
    )
) * 
    CASE 
        WHEN volume_sum20 = 0 OR volume_sum20 IS NULL THEN NULL
        WHEN ABS(volume_sum20) < 1e-10 THEN NULL
        ELSE volume_sum5 / volume_sum20
    END
 AS alpha030,
        
        -- Alpha 031: 简化版本
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close_delta10
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY -1 * close_delta3
    )
 + 
        
    CASE 
        WHEN 
    
    -- 使用DuckDB的CORR窗口函数
    CORR(adv20, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 / NULLIF(
        SUM(ABS(
    -- 使用DuckDB的CORR窗口函数
    CORR(adv20, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
)) OVER (PARTITION BY timestamp), 0
    )
 > 0 THEN 1
        WHEN 
    
    -- 使用DuckDB的CORR窗口函数
    CORR(adv20, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 / NULLIF(
        SUM(ABS(
    -- 使用DuckDB的CORR窗口函数
    CORR(adv20, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
)) OVER (PARTITION BY timestamp), 0
    )
 < 0 THEN -1
        ELSE 0
    END
 AS alpha031,
        
        -- Alpha 032
        
    alpha032_ma_diff / NULLIF(
        SUM(ABS(alpha032_ma_diff)) OVER (PARTITION BY timestamp), 0
    )
 + 20 * 
    alpha032_corr_vwap_delay / NULLIF(
        SUM(ABS(alpha032_corr_vwap_delay)) OVER (PARTITION BY timestamp), 0
    )
 AS alpha032,
        
        -- Alpha 033: rank((-1 * ((1 - (open / close))^1)))
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY -1 * alpha033_open_close_ratio
    )
 AS alpha033,
        
        -- Alpha 034
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY (1 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha034_std_ratio
    )
) + (1 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close_delta1
    )
)
    )
 AS alpha034,
        
        -- Alpha 035
        volume_ts_rank5 * (1 - 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha035_price_sum
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    )
) * 
        (1 - 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY returns
        ROWS BETWEEN 31 PRECEDING AND CURRENT ROW
    )
) AS alpha035,
        
        -- Alpha 036: 复杂组合因子
        alpha036_combination AS alpha036,
        
        -- Alpha 037
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha037_corr_delay
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha036_open_close
    )
 AS alpha037,
        
        -- Alpha 038
        (-1 * close_ts_rank10) * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha038_close_open_ratio
    )
 AS alpha038,
        
        -- Alpha 039
        (-1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha039_weighted_delta
    )
) * (1 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns_sum250
    )
) AS alpha039,
        
        -- Alpha 040: ((-1 * rank(stddev(high, 10))) * correlation(high, volume, 10))
        (-1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    STDDEV(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

    )
) * corr_high_volume_5 AS alpha040,
        
        -- Alpha 041: (((high * low)^0.5) - vwap)
        SQRT(high * low) - vwap AS alpha041,
        
        -- Alpha 042: (rank((vwap - close)) / rank((vwap + close)))
        
    CASE 
        WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap + close
    )
 = 0 OR 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap + close
    )
 IS NULL THEN NULL
        WHEN ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap + close
    )
) < 1e-10 THEN NULL
        ELSE 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap - close
    )
 / 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap + close
    )

    END
 AS alpha042,
        
        -- Alpha 043
        alpha043_ts_rank_vol * alpha043_ts_rank_delta AS alpha043,
        
        -- Alpha 044: (-1 * correlation(high, rank(volume), 5))
        -1 * 
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume_rank) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha044,
        
        -- Alpha 045
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha045_mean_delay_close
    )
 * alpha045_corr_close_vol * 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha045_corr_sums
    )
 AS alpha045,
        
        -- Alpha 046
        CASE 
            WHEN alpha046_slope_diff > 0.25 THEN -1
            WHEN alpha046_slope_diff < 0 THEN 1
            ELSE -1 * (close - close_lag1)
        END AS alpha046,
        
        -- Alpha 047
        alpha047_complex1 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha047_vwap_diff
    )
 AS alpha047,
        
        -- Alpha 048: 简化版本
        
    CASE 
        WHEN 
    SUM(POWER(
    CASE 
        WHEN close_lag1 = 0 OR close_lag1 IS NULL THEN NULL
        WHEN ABS(close_lag1) < 1e-10 THEN NULL
        ELSE close_delta1 / close_lag1
    END
, 2)) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    SUM(POWER(
    CASE 
        WHEN close_lag1 = 0 OR close_lag1 IS NULL THEN NULL
        WHEN ABS(close_lag1) < 1e-10 THEN NULL
        ELSE close_delta1 / close_lag1
    END
, 2)) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    SUM(POWER(
    CASE 
        WHEN close_lag1 = 0 OR close_lag1 IS NULL THEN NULL
        WHEN ABS(close_lag1) < 1e-10 THEN NULL
        ELSE close_delta1 / close_lag1
    END
, 2)) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE 
    -- 使用DuckDB的CORR窗口函数
    CORR(close_delta1, 
    close_lag1 - 
    LAG(close_lag1, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 * close_delta1 / close / 
    SUM(POWER(
    CASE 
        WHEN close_lag1 = 0 OR close_lag1 IS NULL THEN NULL
        WHEN ABS(close_lag1) < 1e-10 THEN NULL
        ELSE close_delta1 / close_lag1
    END
, 2)) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )

    END
 AS alpha048,
        
        -- Alpha 049
        CASE 
            WHEN alpha046_slope_diff < -0.1 THEN 1
            ELSE -1 * (close - close_lag1)
        END AS alpha049,
        
        -- Alpha 050: (-1 * ts_max(rank(correlation(rank(volume), rank(vwap), 5)), 5))
        -1 * 
    MAX(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(volume_rank, vwap_rank) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha050
        
    FROM more_intermediate
)

SELECT * FROM alpha_factors
    );
  
  
[0m17:56:40.402905 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8836a9ad0>]}
[0m17:56:40.403576 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:56:40.403973 [debug] [Thread-2 (]: SQL status: OK in 0.005 seconds
[0m17:56:40.404494 [debug] [Thread-3 (]: DuckDB adapter: Rolling back transaction.
[0m17:56:40.405142 [info ] [Thread-4 (]: 4 of 11 OK created sql table model main.features_ohlc_technical ................ [[32mOK[0m in 0.11s]
[0m17:56:40.405748 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_factors_051_075"
[0m17:56:40.406331 [debug] [Thread-3 (]: On model.quant_features.alpha_factors_021_050: ROLLBACK
[0m17:56:40.406748 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m17:56:40.407187 [debug] [Thread-4 (]: Finished running node model.quant_features.features_ohlc_technical
[0m17:56:40.408602 [debug] [Thread-2 (]: On model.quant_features.alpha_factors_051_075: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_factors_051_075"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_factors_051_075__dbt_tmp"
  
    as (
      

-- Alpha 101 因子计算 (051-075)

WITH base_data AS (
    SELECT * FROM "quant_features"."main"."alpha_base_data"
),

-- 预计算复杂的中间变量
intermediate_calcs AS (
    SELECT 
        *,
        -- Alpha051 相关计算
        (close_lag20 - close_lag10) / 10 - (close_lag10 - close) / 10 AS alpha051_slope_diff,
        
        -- Alpha052 相关计算
        
    LAG(
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS alpha052_delay_min_low,
        (returns_sum250 - close_sum20) / 220 AS alpha052_returns_diff,
        
        -- Alpha053 相关计算
        
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE close - low / high - low
    END
 AS alpha053_hl_position,
        
        -- Alpha054 相关计算
        POWER(open, 5) AS alpha054_open_power5,
        POWER(close, 5) AS alpha054_close_power5,
        
        -- Alpha055 相关计算
        
    CASE 
        WHEN 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE close - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 / 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )

    END
 AS alpha055_stoch_like,
        
        -- Alpha056 相关计算
        
    CASE 
        WHEN 
    SUM(
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    SUM(
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    SUM(
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE 
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 / 
    SUM(
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )

    END
 AS alpha056_returns_ratio,
        returns * volume * close AS alpha056_weighted_returns,
        
        -- Alpha057 相关计算
        
    -- 使用ROW_NUMBER()来找到最大值的位置
    (30 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (close = 
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )
 AS alpha057_argmax_close,
        
        -- Alpha060 相关计算
        
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE (close - low) - (high - close) / high - low
    END
 * volume AS alpha060_price_vol_product,
        
        -- Alpha061 相关计算
        vwap - 
    MIN(vwap) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    )
 AS alpha061_vwap_min_diff,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 179 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 17 PRECEDING AND CURRENT ROW
    )
 AS alpha061_vwap_adv_corr,
        
        -- Alpha062 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 21 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS alpha062_corr1,
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
) < (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY (high + low) / 2
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
) AS alpha062_condition,
        
        -- Alpha063 相关计算
        close * 0.607 + open * 0.393 AS alpha063_weighted_price,
        vwap * 0.318 + open * 0.682 AS alpha063_weighted_vwap_open,
        
        -- Alpha064 相关计算
        open * 0.178 + low * 0.822 AS alpha064_weighted_open_low,
        (high + low) / 2 * 0.178 + vwap * 0.822 AS alpha064_weighted_hl_vwap,
        
        -- Alpha065 相关计算
        open * 0.008 + vwap * 0.992 AS alpha065_weighted_open_vwap,
        open - 
    MIN(open) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 AS alpha065_open_min_diff,
        
        -- Alpha066 相关计算
        low - vwap AS alpha066_low_vwap_diff,
        open - (high + low) / 2 AS alpha066_open_hl_mid_diff,
        
        -- Alpha067 相关计算
        high - 
    MIN(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
 AS alpha067_high_min_diff,
        
        -- Alpha068 相关计算
        close * 0.518 + low * 0.482 AS alpha068_weighted_close_low,
        
        -- Alpha069 相关计算
        close * 0.491 + vwap * 0.509 AS alpha069_weighted_close_vwap,
        
        -- Alpha070-075 相关计算
        low + open - 2 * vwap AS alpha071_price_diff,
        (high + low) / 2 AS alpha072_hl_mid,
        open * 0.147 + low * 0.853 AS alpha073_weighted_open_low,
        high * 0.026 + vwap * 0.974 AS alpha074_weighted_high_vwap,
        
        -- 预计算一些复杂的衰减线性加权值
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    vwap - 
    LAG(vwap, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)
 AS alpha073_decay_vwap_delta,
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
 * 
        (8 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (8 * (8 + 1) / 2)
 AS alpha058_decay_corr,
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR((high + low) / 2, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 * 
        (6 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (6 * (6 + 1) / 2)
 AS alpha077_decay_corr
        
    FROM base_data
),

-- 计算Alpha因子 (051-075)
alpha_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- Alpha 051: 价格趋势变化因子
        CASE 
            WHEN alpha051_slope_diff < -0.05 THEN 1
            ELSE -1 * (close - close_lag1)
        END AS alpha051,
        
        -- Alpha 052: 低价位与收益率关系因子
        ((-1 * 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
) + alpha052_delay_min_low) * 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha052_returns_diff
    )
 * 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha052,
        
        -- Alpha 053: 价格位置变化因子
        -1 * 
    alpha053_hl_position - 
    LAG(alpha053_hl_position, 9) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS alpha053,
        
        -- Alpha 054: 开盘收盘价格关系因子
        
    CASE 
        WHEN (low - high) * alpha054_close_power5 = 0 OR (low - high) * alpha054_close_power5 IS NULL THEN NULL
        WHEN ABS((low - high) * alpha054_close_power5) < 1e-10 THEN NULL
        ELSE -1 * (low - close) * alpha054_open_power5 / (low - high) * alpha054_close_power5
    END
 AS alpha054,
        
        -- Alpha 055: 随机指标与成交量相关性
        -1 * 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha055_stoch_like
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS alpha055,
        
        -- Alpha 056: 收益率比率与加权收益因子
        0 - (1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha056_returns_ratio
    )
 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha056_weighted_returns
    )
) AS alpha056,
        
        -- Alpha 057: VWAP偏离与价格位置因子
        0 - (1 * 
    CASE 
        WHEN 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha057_argmax_close
    )
 * 
        (2 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (2 * (2 + 1) / 2)
 = 0 OR 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha057_argmax_close
    )
 * 
        (2 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (2 * (2 + 1) / 2)
 IS NULL THEN NULL
        WHEN ABS(
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha057_argmax_close
    )
 * 
        (2 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (2 * (2 + 1) / 2)
) < 1e-10 THEN NULL
        ELSE close - vwap / 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha057_argmax_close
    )
 * 
        (2 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (2 * (2 + 1) / 2)

    END
) AS alpha057,
        
        -- Alpha 058: 简化的衰减相关性因子
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha058_decay_corr
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS alpha058,
        
        -- Alpha 059: 简化版本
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha058_decay_corr
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS alpha059,
        
        -- Alpha 060: 价格位置与成交量综合因子
        0 - (1 * (2 * 
    
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha060_price_vol_product
    )
 / NULLIF(
        SUM(ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha060_price_vol_product
    )
)) OVER (PARTITION BY timestamp), 0
    )
 - 
        
    
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用ROW_NUMBER()来找到最大值的位置
    (10 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (close = 
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )

    )
 / NULLIF(
        SUM(ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用ROW_NUMBER()来找到最大值的位置
    (10 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (close = 
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )

    )
)) OVER (PARTITION BY timestamp), 0
    )
)) AS alpha060,
        
        -- Alpha 061: VWAP最小值比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha061_vwap_min_diff
    )
 < 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha061_vwap_adv_corr
    )

            THEN 1 
            ELSE 0 
        END AS alpha061,
        
        -- Alpha 062: 复合条件因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha062_corr1
    )
 < 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha062_condition
    )

            THEN -1 
            ELSE 1 
        END AS alpha062,
        
        -- Alpha 063: 加权价格衰减因子
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha063_weighted_price - 
    LAG(alpha063_weighted_price, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (8 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (8 * (8 + 1) / 2)

    )
 - 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha063_weighted_vwap_open, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 179 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 36 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 * 
        (12 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (12 * (12 + 1) / 2)

    )
) * -1 AS alpha063,
        
        -- Alpha 064: 复合加权因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    SUM(alpha064_weighted_open_low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )
, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 119 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    )

    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    alpha064_weighted_hl_vwap - 
    LAG(alpha064_weighted_hl_vwap, 4) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )

            THEN -1 
            ELSE 1 
        END AS alpha064,
        
        -- Alpha 065: 开盘价最小值比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha065_weighted_open_vwap, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha065_open_min_diff
    )

            THEN -1 
            ELSE 1 
        END AS alpha065,
        
        -- Alpha 066: VWAP衰减与低价关系因子
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    vwap - 
    LAG(vwap, 4) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (7 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (7 * (7 + 1) / 2)

    )
 + 
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    CASE 
        WHEN alpha066_open_hl_mid_diff = 0 OR alpha066_open_hl_mid_diff IS NULL THEN NULL
        WHEN ABS(alpha066_open_hl_mid_diff) < 1e-10 THEN NULL
        ELSE alpha066_low_vwap_diff / alpha066_open_hl_mid_diff
    END
 * 
        (11 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 10 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 10 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (11 * (11 + 1) / 2)

        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
) * -1 AS alpha066,
        
        -- Alpha 067: 高价最小值幂函数因子
        POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha067_high_min_diff
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

    )
) * -1 AS alpha067,
        
        -- Alpha 068: 高价与平均日成交量关系因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    alpha068_weighted_close_low - 
    LAG(alpha068_weighted_close_low, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )

            THEN -1 
            ELSE 1 
        END AS alpha068,
        
        -- Alpha 069: VWAP最大值幂函数因子
        POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    MAX(
    vwap - 
    LAG(vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

    )
, 
              
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha069_weighted_close_vwap, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
) * -1 AS alpha069,
        
        -- Alpha 070: VWAP变化幂函数因子
        POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    vwap - 
    LAG(vwap, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(close, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 49 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 17 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 17 PRECEDING AND CURRENT ROW
    )
) * -1 AS alpha070,
        
        -- Alpha 071: 复合最大值因子
        GREATEST(
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 179 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 17 PRECEDING AND CURRENT ROW
    )
 * 
        (4 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (4 * (4 + 1) / 2)

        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha071_price_diff
    )
, 2) * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )

        ) AS alpha071,
        
        -- Alpha 072: 中价与VWAP关系比率因子
        
    CASE 
        WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

    )
 = 0 OR 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

    )
 IS NULL THEN NULL
        WHEN ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

    )
) < 1e-10 THEN NULL
        ELSE 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha072_hl_mid, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
 * 
        (10 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (10 * (10 + 1) / 2)

    )
 / 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

    )

    END
 AS alpha072,
        
        -- Alpha 073: 复合最大值衰减因子
        GREATEST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha073_decay_vwap_delta
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    CASE 
        WHEN alpha073_weighted_open_low = 0 OR alpha073_weighted_open_low IS NULL THEN NULL
        WHEN ABS(alpha073_weighted_open_low) < 1e-10 THEN NULL
        ELSE 
    alpha073_weighted_open_low - 
    LAG(alpha073_weighted_open_low, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 / alpha073_weighted_open_low
    END
 * -1 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha073,
        
        -- Alpha 074: 收盘价与高价VWAP关系比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(close, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 36 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )

    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha074_weighted_high_vwap
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 10 PRECEDING AND CURRENT ROW
    )

    )

            THEN -1 
            ELSE 1 
        END AS alpha074,
        
        -- Alpha 075: VWAP成交量与低价平均日成交量关系因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )

    )
 < 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 49 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )

    )

            THEN 1 
            ELSE 0 
        END AS alpha075
        
    FROM intermediate_calcs
)

SELECT * FROM alpha_factors
    );
  
  
[0m17:56:40.411071 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.alpha_factors_001_020"
[0m17:56:40.411916 [debug] [Thread-4 (]: Began running node model.quant_features.alpha_factors_076_101
[0m17:56:40.412717 [debug] [Thread-1 (]: On model.quant_features.alpha_factors_001_020: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_factors_001_020"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_factors_001_020__dbt_tmp"
  
    as (
      

-- Alpha 101 因子计算 (001-020)
-- 基于预处理的基础数据计算前20个Alpha因子

WITH base_data AS (
    SELECT * FROM "quant_features"."main"."alpha_base_data"
),

-- 预计算一些复杂的中间变量
intermediate_calcs AS (
    SELECT 
        *,
        -- Alpha001 相关计算
        
    -- 使用ROW_NUMBER()来找到最大值的位置
    (5 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (CASE WHEN returns < 0 THEN returns_std20 ELSE close END = 
    MAX(CASE WHEN returns < 0 THEN returns_std20 ELSE close END) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )
 AS alpha001_argmax,
        
        -- Alpha002 相关计算
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    CASE 
        WHEN volume > 0 THEN LN(volume)
        ELSE NULL
    END
 - 
    LAG(
    CASE 
        WHEN volume > 0 THEN LN(volume)
        ELSE NULL
    END
, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 AS alpha002_rank_delta_log_vol,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN open = 0 OR open IS NULL THEN NULL
        WHEN ABS(open) < 1e-10 THEN NULL
        ELSE close - open / open
    END

    )
 AS alpha002_rank_ret,
        
        -- Alpha005 相关计算
        close_ma10 AS alpha005_mean_vwap,
        
        -- Alpha007 相关计算
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    ABS(close_delta7)

        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )
 AS alpha007_ts_rank,
        
    CASE 
        WHEN close_delta7 > 0 THEN 1
        WHEN close_delta7 < 0 THEN -1
        ELSE 0
    END
 AS alpha007_sign,
        
        -- Alpha008 相关计算
        (open * 5 + returns_sum250 / 50) AS alpha008_sum_open_returns,  -- 简化计算
        
    LAG((open * 5 + returns_sum250 / 50), 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS alpha008_delay_sum,
        
        -- Alpha009-010 逻辑
        CASE 
            WHEN 
    MIN(close_delta1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 > 0 THEN close_delta1
            WHEN 
    MAX(close_delta1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 < 0 THEN close_delta1
            ELSE -1 * close_delta1
        END AS alpha009_logic,
        
        -- Alpha011 相关计算
        
    MAX(vwap - close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha011_max_vwap_close,
        
    MIN(vwap - close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha011_min_vwap_close,
        
        -- Alpha014 相关计算
        
    returns - 
    LAG(returns, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS alpha014_delta_returns,
        
        -- Alpha015 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(high_rank, volume_rank) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha015_corr_high_vol,
        
        -- Alpha017 相关计算
        
    close_delta1 - 
    LAG(close_delta1, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS alpha017_delta_delta_close,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END

        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha017_ts_rank_vol_adv,
        
        -- Alpha018 相关计算
        
    STDDEV(
    ABS(close - open)
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha018_stddev,
        close - open AS alpha018_close_open_diff,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, open) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS alpha018_corr_close_open,
        
        -- Alpha019 相关计算
        (close - close_lag7) + close_delta7 AS alpha019_close_diff_plus_delta,
        1 + returns_sum250 AS alpha019_sum_returns,
        
        -- Alpha020 相关计算
        open - high_lag1 AS alpha020_open_delay_high,
        open - close_lag1 AS alpha020_open_delay_close,
        open - low_lag1 AS alpha020_open_delay_low
        
    FROM base_data
),

-- 计算Alpha因子
alpha_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- Alpha 001: RANK(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha001_argmax
    )
 - 0.5 AS alpha001,
        
        -- Alpha 002: (-1 * correlation(rank(delta(log(volume), 2)), rank(((close - open) / open)), 6))
        -1 * 
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha002_rank_delta_log_vol, alpha002_rank_ret) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS alpha002,
        
        -- Alpha 003: (-1 * correlation(rank(open), rank(volume), 10))
        -1 * corr_open_volume_10 AS alpha003,
        
        -- Alpha 004: (-1 * Ts_Rank(rank(low), 9))
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY low_rank
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
 AS alpha004,
        
        -- Alpha 005: (rank((open - (sum(vwap, 10) / 10))) * (-1 * abs(rank((close - vwap)))))
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open - alpha005_mean_vwap
    )
 * (-1 * 
    ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close - vwap
    )
)
) AS alpha005,
        
        -- Alpha 006: (-1 * correlation(open, volume, 10))
        -1 * corr_open_volume_10 AS alpha006,
        
        -- Alpha 007: ((adv20 < volume) ? ((-1 * ts_rank(abs(delta(close, 7)), 60)) * sign(delta(close, 7))) : (-1))
        CASE 
            WHEN adv20 < volume THEN (-1 * alpha007_ts_rank) * alpha007_sign
            ELSE -1
        END AS alpha007,
        
        -- Alpha 008: (-1 * rank(((sum(open, 5) * sum(returns, 5)) - delay((sum(open, 5) * sum(returns, 5)), 10))))
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha008_sum_open_returns - alpha008_delay_sum
    )
 AS alpha008,
        
        -- Alpha 009: ((0 < ts_min(delta(close, 1), 5)) ? delta(close, 1) : ((ts_max(delta(close, 1), 5) < 0) ? delta(close, 1) : (-1 * delta(close, 1))))
        alpha009_logic AS alpha009,
        
        -- Alpha 010: rank(((0 < ts_min(delta(close, 1), 4)) ? delta(close, 1) : ((ts_max(delta(close, 1), 4) < 0) ? delta(close, 1) : (-1 * delta(close, 1)))))
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha009_logic
    )
 AS alpha010,
        
        -- Alpha 011: ((rank(ts_max((vwap - close), 3)) + rank(ts_min((vwap - close), 3))) * rank(delta(volume, 3)))
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha011_max_vwap_close
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha011_min_vwap_close
    )
) * 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume_delta3
    )
 AS alpha011,
        
        -- Alpha 012: (sign(delta(volume, 1)) * (-1 * delta(close, 1)))
        
    CASE 
        WHEN volume_delta1 > 0 THEN 1
        WHEN volume_delta1 < 0 THEN -1
        ELSE 0
    END
 * (-1 * close_delta1) AS alpha012,
        
        -- Alpha 013: (-1 * rank(covariance(rank(close), rank(volume), 5)))
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY cov_close_volume_5
    )
 AS alpha013,
        
        -- Alpha 014: ((-1 * rank(delta(returns, 3))) * correlation(open, volume, 10))
        (-1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha014_delta_returns
    )
) * corr_open_volume_10 AS alpha014,
        
        -- Alpha 015: (-1 * sum(rank(correlation(rank(high), rank(volume), 3)), 3))
        -1 * 
    SUM(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha015_corr_high_vol
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha015,
        
        -- Alpha 016: (-1 * rank(covariance(rank(high), rank(volume), 5)))
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY cov_high_volume_5
    )
 AS alpha016,
        
        -- Alpha 017: (((-1 * rank(ts_rank(close, 10))) * rank(delta(delta(close, 1), 1))) * rank(ts_rank((volume / adv20), 5)))
        ((-1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close_ts_rank10
    )
) * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha017_delta_delta_close
    )
) * 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha017_ts_rank_vol_adv
    )
 AS alpha017,
        
        -- Alpha 018: (-1 * rank(((stddev(abs((close - open)), 5) + (close - open)) + correlation(close, open, 10))))
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha018_stddev + alpha018_close_open_diff + alpha018_corr_close_open
    )
 AS alpha018,
        
        -- Alpha 019: ((-1 * sign(((close - delay(close, 7)) + delta(close, 7)))) * (1 + rank((1 + sum(returns, 250)))))
        (-1 * 
    CASE 
        WHEN alpha019_close_diff_plus_delta > 0 THEN 1
        WHEN alpha019_close_diff_plus_delta < 0 THEN -1
        ELSE 0
    END
) * 
        (1 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha019_sum_returns
    )
) AS alpha019,
        
        -- Alpha 020: (((-1 * rank((open - delay(high, 1)))) * rank((open - delay(close, 1)))) * rank((open - delay(low, 1))))
        ((-1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha020_open_delay_high
    )
) * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha020_open_delay_close
    )
) * 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha020_open_delay_low
    )
 AS alpha020
        
    FROM intermediate_calcs
)

SELECT * FROM alpha_factors
    );
  
  
[0m17:56:40.415183 [debug] [Thread-2 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_factors_051_075"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_factors_051_075__dbt_tmp"
  
    as (
      

-- Alpha 101 因子计算 (051-075)

WITH base_data AS (
    SELECT * FROM "quant_features"."main"."alpha_base_data"
),

-- 预计算复杂的中间变量
intermediate_calcs AS (
    SELECT 
        *,
        -- Alpha051 相关计算
        (close_lag20 - close_lag10) / 10 - (close_lag10 - close) / 10 AS alpha051_slope_diff,
        
        -- Alpha052 相关计算
        
    LAG(
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS alpha052_delay_min_low,
        (returns_sum250 - close_sum20) / 220 AS alpha052_returns_diff,
        
        -- Alpha053 相关计算
        
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE close - low / high - low
    END
 AS alpha053_hl_position,
        
        -- Alpha054 相关计算
        POWER(open, 5) AS alpha054_open_power5,
        POWER(close, 5) AS alpha054_close_power5,
        
        -- Alpha055 相关计算
        
    CASE 
        WHEN 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE close - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 / 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )

    END
 AS alpha055_stoch_like,
        
        -- Alpha056 相关计算
        
    CASE 
        WHEN 
    SUM(
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    SUM(
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    SUM(
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE 
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 / 
    SUM(
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )

    END
 AS alpha056_returns_ratio,
        returns * volume * close AS alpha056_weighted_returns,
        
        -- Alpha057 相关计算
        
    -- 使用ROW_NUMBER()来找到最大值的位置
    (30 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (close = 
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )
 AS alpha057_argmax_close,
        
        -- Alpha060 相关计算
        
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE (close - low) - (high - close) / high - low
    END
 * volume AS alpha060_price_vol_product,
        
        -- Alpha061 相关计算
        vwap - 
    MIN(vwap) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    )
 AS alpha061_vwap_min_diff,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 179 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 17 PRECEDING AND CURRENT ROW
    )
 AS alpha061_vwap_adv_corr,
        
        -- Alpha062 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 21 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS alpha062_corr1,
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
) < (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY (high + low) / 2
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
) AS alpha062_condition,
        
        -- Alpha063 相关计算
        close * 0.607 + open * 0.393 AS alpha063_weighted_price,
        vwap * 0.318 + open * 0.682 AS alpha063_weighted_vwap_open,
        
        -- Alpha064 相关计算
        open * 0.178 + low * 0.822 AS alpha064_weighted_open_low,
        (high + low) / 2 * 0.178 + vwap * 0.822 AS alpha064_weighted_hl_vwap,
        
        -- Alpha065 相关计算
        open * 0.008 + vwap * 0.992 AS alpha065_weighted_open_vwap,
        open - 
    MIN(open) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 AS alpha065_open_min_diff,
        
        -- Alpha066 相关计算
        low - vwap AS alpha066_low_vwap_diff,
        open - (high + low) / 2 AS alpha066_open_hl_mid_diff,
        
        -- Alpha067 相关计算
        high - 
    MIN(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    )
 AS alpha067_high_min_diff,
        
        -- Alpha068 相关计算
        close * 0.518 + low * 0.482 AS alpha068_weighted_close_low,
        
        -- Alpha069 相关计算
        close * 0.491 + vwap * 0.509 AS alpha069_weighted_close_vwap,
        
        -- Alpha070-075 相关计算
        low + open - 2 * vwap AS alpha071_price_diff,
        (high + low) / 2 AS alpha072_hl_mid,
        open * 0.147 + low * 0.853 AS alpha073_weighted_open_low,
        high * 0.026 + vwap * 0.974 AS alpha074_weighted_high_vwap,
        
        -- 预计算一些复杂的衰减线性加权值
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    vwap - 
    LAG(vwap, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)
 AS alpha073_decay_vwap_delta,
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
 * 
        (8 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (8 * (8 + 1) / 2)
 AS alpha058_decay_corr,
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR((high + low) / 2, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 * 
        (6 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (6 * (6 + 1) / 2)
 AS alpha077_decay_corr
        
    FROM base_data
),

-- 计算Alpha因子 (051-075)
alpha_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- Alpha 051: 价格趋势变化因子
        CASE 
            WHEN alpha051_slope_diff < -0.05 THEN 1
            ELSE -1 * (close - close_lag1)
        END AS alpha051,
        
        -- Alpha 052: 低价位与收益率关系因子
        ((-1 * 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
) + alpha052_delay_min_low) * 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha052_returns_diff
    )
 * 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha052,
        
        -- Alpha 053: 价格位置变化因子
        -1 * 
    alpha053_hl_position - 
    LAG(alpha053_hl_position, 9) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS alpha053,
        
        -- Alpha 054: 开盘收盘价格关系因子
        
    CASE 
        WHEN (low - high) * alpha054_close_power5 = 0 OR (low - high) * alpha054_close_power5 IS NULL THEN NULL
        WHEN ABS((low - high) * alpha054_close_power5) < 1e-10 THEN NULL
        ELSE -1 * (low - close) * alpha054_open_power5 / (low - high) * alpha054_close_power5
    END
 AS alpha054,
        
        -- Alpha 055: 随机指标与成交量相关性
        -1 * 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha055_stoch_like
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS alpha055,
        
        -- Alpha 056: 收益率比率与加权收益因子
        0 - (1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha056_returns_ratio
    )
 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha056_weighted_returns
    )
) AS alpha056,
        
        -- Alpha 057: VWAP偏离与价格位置因子
        0 - (1 * 
    CASE 
        WHEN 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha057_argmax_close
    )
 * 
        (2 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (2 * (2 + 1) / 2)
 = 0 OR 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha057_argmax_close
    )
 * 
        (2 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (2 * (2 + 1) / 2)
 IS NULL THEN NULL
        WHEN ABS(
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha057_argmax_close
    )
 * 
        (2 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (2 * (2 + 1) / 2)
) < 1e-10 THEN NULL
        ELSE close - vwap / 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha057_argmax_close
    )
 * 
        (2 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 1 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (2 * (2 + 1) / 2)

    END
) AS alpha057,
        
        -- Alpha 058: 简化的衰减相关性因子
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha058_decay_corr
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS alpha058,
        
        -- Alpha 059: 简化版本
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha058_decay_corr
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS alpha059,
        
        -- Alpha 060: 价格位置与成交量综合因子
        0 - (1 * (2 * 
    
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha060_price_vol_product
    )
 / NULLIF(
        SUM(ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha060_price_vol_product
    )
)) OVER (PARTITION BY timestamp), 0
    )
 - 
        
    
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用ROW_NUMBER()来找到最大值的位置
    (10 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (close = 
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )

    )
 / NULLIF(
        SUM(ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用ROW_NUMBER()来找到最大值的位置
    (10 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (close = 
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )

    )
)) OVER (PARTITION BY timestamp), 0
    )
)) AS alpha060,
        
        -- Alpha 061: VWAP最小值比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha061_vwap_min_diff
    )
 < 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha061_vwap_adv_corr
    )

            THEN 1 
            ELSE 0 
        END AS alpha061,
        
        -- Alpha 062: 复合条件因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha062_corr1
    )
 < 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha062_condition
    )

            THEN -1 
            ELSE 1 
        END AS alpha062,
        
        -- Alpha 063: 加权价格衰减因子
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha063_weighted_price - 
    LAG(alpha063_weighted_price, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (8 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (8 * (8 + 1) / 2)

    )
 - 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha063_weighted_vwap_open, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 179 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 36 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 * 
        (12 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (12 * (12 + 1) / 2)

    )
) * -1 AS alpha063,
        
        -- Alpha 064: 复合加权因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    SUM(alpha064_weighted_open_low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )
, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 119 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    )

    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    alpha064_weighted_hl_vwap - 
    LAG(alpha064_weighted_hl_vwap, 4) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )

            THEN -1 
            ELSE 1 
        END AS alpha064,
        
        -- Alpha 065: 开盘价最小值比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha065_weighted_open_vwap, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha065_open_min_diff
    )

            THEN -1 
            ELSE 1 
        END AS alpha065,
        
        -- Alpha 066: VWAP衰减与低价关系因子
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    vwap - 
    LAG(vwap, 4) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (7 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (7 * (7 + 1) / 2)

    )
 + 
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    CASE 
        WHEN alpha066_open_hl_mid_diff = 0 OR alpha066_open_hl_mid_diff IS NULL THEN NULL
        WHEN ABS(alpha066_open_hl_mid_diff) < 1e-10 THEN NULL
        ELSE alpha066_low_vwap_diff / alpha066_open_hl_mid_diff
    END
 * 
        (11 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 10 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 10 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (11 * (11 + 1) / 2)

        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
) * -1 AS alpha066,
        
        -- Alpha 067: 高价最小值幂函数因子
        POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha067_high_min_diff
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

    )
) * -1 AS alpha067,
        
        -- Alpha 068: 高价与平均日成交量关系因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    alpha068_weighted_close_low - 
    LAG(alpha068_weighted_close_low, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )

            THEN -1 
            ELSE 1 
        END AS alpha068,
        
        -- Alpha 069: VWAP最大值幂函数因子
        POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    MAX(
    vwap - 
    LAG(vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

    )
, 
              
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha069_weighted_close_vwap, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
) * -1 AS alpha069,
        
        -- Alpha 070: VWAP变化幂函数因子
        POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    vwap - 
    LAG(vwap, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(close, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 49 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 17 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 17 PRECEDING AND CURRENT ROW
    )
) * -1 AS alpha070,
        
        -- Alpha 071: 复合最大值因子
        GREATEST(
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 179 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 17 PRECEDING AND CURRENT ROW
    )
 * 
        (4 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (4 * (4 + 1) / 2)

        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha071_price_diff
    )
, 2) * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )

        ) AS alpha071,
        
        -- Alpha 072: 中价与VWAP关系比率因子
        
    CASE 
        WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

    )
 = 0 OR 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

    )
 IS NULL THEN NULL
        WHEN ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

    )
) < 1e-10 THEN NULL
        ELSE 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha072_hl_mid, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
 * 
        (10 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (10 * (10 + 1) / 2)

    )
 / 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

    )

    END
 AS alpha072,
        
        -- Alpha 073: 复合最大值衰减因子
        GREATEST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha073_decay_vwap_delta
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    CASE 
        WHEN alpha073_weighted_open_low = 0 OR alpha073_weighted_open_low IS NULL THEN NULL
        WHEN ABS(alpha073_weighted_open_low) < 1e-10 THEN NULL
        ELSE 
    alpha073_weighted_open_low - 
    LAG(alpha073_weighted_open_low, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 / alpha073_weighted_open_low
    END
 * -1 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha073,
        
        -- Alpha 074: 收盘价与高价VWAP关系比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(close, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 36 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )

    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha074_weighted_high_vwap
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 10 PRECEDING AND CURRENT ROW
    )

    )

            THEN -1 
            ELSE 1 
        END AS alpha074,
        
        -- Alpha 075: VWAP成交量与低价平均日成交量关系因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )

    )
 < 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 49 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )

    )

            THEN 1 
            ELSE 0 
        END AS alpha075
        
    FROM intermediate_calcs
)

SELECT * FROM alpha_factors
    );
  
  
[0m17:56:40.416836 [info ] [Thread-4 (]: 8 of 11 START sql table model main.alpha_factors_076_101 ....................... [RUN]
[0m17:56:40.418215 [debug] [Thread-1 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_factors_001_020"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_factors_001_020__dbt_tmp"
  
    as (
      

-- Alpha 101 因子计算 (001-020)
-- 基于预处理的基础数据计算前20个Alpha因子

WITH base_data AS (
    SELECT * FROM "quant_features"."main"."alpha_base_data"
),

-- 预计算一些复杂的中间变量
intermediate_calcs AS (
    SELECT 
        *,
        -- Alpha001 相关计算
        
    -- 使用ROW_NUMBER()来找到最大值的位置
    (5 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (CASE WHEN returns < 0 THEN returns_std20 ELSE close END = 
    MAX(CASE WHEN returns < 0 THEN returns_std20 ELSE close END) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )
 AS alpha001_argmax,
        
        -- Alpha002 相关计算
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    CASE 
        WHEN volume > 0 THEN LN(volume)
        ELSE NULL
    END
 - 
    LAG(
    CASE 
        WHEN volume > 0 THEN LN(volume)
        ELSE NULL
    END
, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 AS alpha002_rank_delta_log_vol,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN open = 0 OR open IS NULL THEN NULL
        WHEN ABS(open) < 1e-10 THEN NULL
        ELSE close - open / open
    END

    )
 AS alpha002_rank_ret,
        
        -- Alpha005 相关计算
        close_ma10 AS alpha005_mean_vwap,
        
        -- Alpha007 相关计算
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    ABS(close_delta7)

        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )
 AS alpha007_ts_rank,
        
    CASE 
        WHEN close_delta7 > 0 THEN 1
        WHEN close_delta7 < 0 THEN -1
        ELSE 0
    END
 AS alpha007_sign,
        
        -- Alpha008 相关计算
        (open * 5 + returns_sum250 / 50) AS alpha008_sum_open_returns,  -- 简化计算
        
    LAG((open * 5 + returns_sum250 / 50), 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS alpha008_delay_sum,
        
        -- Alpha009-010 逻辑
        CASE 
            WHEN 
    MIN(close_delta1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 > 0 THEN close_delta1
            WHEN 
    MAX(close_delta1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 < 0 THEN close_delta1
            ELSE -1 * close_delta1
        END AS alpha009_logic,
        
        -- Alpha011 相关计算
        
    MAX(vwap - close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha011_max_vwap_close,
        
    MIN(vwap - close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha011_min_vwap_close,
        
        -- Alpha014 相关计算
        
    returns - 
    LAG(returns, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS alpha014_delta_returns,
        
        -- Alpha015 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(high_rank, volume_rank) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha015_corr_high_vol,
        
        -- Alpha017 相关计算
        
    close_delta1 - 
    LAG(close_delta1, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS alpha017_delta_delta_close,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END

        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha017_ts_rank_vol_adv,
        
        -- Alpha018 相关计算
        
    STDDEV(
    ABS(close - open)
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha018_stddev,
        close - open AS alpha018_close_open_diff,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, open) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS alpha018_corr_close_open,
        
        -- Alpha019 相关计算
        (close - close_lag7) + close_delta7 AS alpha019_close_diff_plus_delta,
        1 + returns_sum250 AS alpha019_sum_returns,
        
        -- Alpha020 相关计算
        open - high_lag1 AS alpha020_open_delay_high,
        open - close_lag1 AS alpha020_open_delay_close,
        open - low_lag1 AS alpha020_open_delay_low
        
    FROM base_data
),

-- 计算Alpha因子
alpha_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- Alpha 001: RANK(Ts_ArgMax(SignedPower(((returns < 0) ? stddev(returns, 20) : close), 2.), 5)) - 0.5
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha001_argmax
    )
 - 0.5 AS alpha001,
        
        -- Alpha 002: (-1 * correlation(rank(delta(log(volume), 2)), rank(((close - open) / open)), 6))
        -1 * 
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha002_rank_delta_log_vol, alpha002_rank_ret) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS alpha002,
        
        -- Alpha 003: (-1 * correlation(rank(open), rank(volume), 10))
        -1 * corr_open_volume_10 AS alpha003,
        
        -- Alpha 004: (-1 * Ts_Rank(rank(low), 9))
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY low_rank
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
 AS alpha004,
        
        -- Alpha 005: (rank((open - (sum(vwap, 10) / 10))) * (-1 * abs(rank((close - vwap)))))
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open - alpha005_mean_vwap
    )
 * (-1 * 
    ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close - vwap
    )
)
) AS alpha005,
        
        -- Alpha 006: (-1 * correlation(open, volume, 10))
        -1 * corr_open_volume_10 AS alpha006,
        
        -- Alpha 007: ((adv20 < volume) ? ((-1 * ts_rank(abs(delta(close, 7)), 60)) * sign(delta(close, 7))) : (-1))
        CASE 
            WHEN adv20 < volume THEN (-1 * alpha007_ts_rank) * alpha007_sign
            ELSE -1
        END AS alpha007,
        
        -- Alpha 008: (-1 * rank(((sum(open, 5) * sum(returns, 5)) - delay((sum(open, 5) * sum(returns, 5)), 10))))
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha008_sum_open_returns - alpha008_delay_sum
    )
 AS alpha008,
        
        -- Alpha 009: ((0 < ts_min(delta(close, 1), 5)) ? delta(close, 1) : ((ts_max(delta(close, 1), 5) < 0) ? delta(close, 1) : (-1 * delta(close, 1))))
        alpha009_logic AS alpha009,
        
        -- Alpha 010: rank(((0 < ts_min(delta(close, 1), 4)) ? delta(close, 1) : ((ts_max(delta(close, 1), 4) < 0) ? delta(close, 1) : (-1 * delta(close, 1)))))
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha009_logic
    )
 AS alpha010,
        
        -- Alpha 011: ((rank(ts_max((vwap - close), 3)) + rank(ts_min((vwap - close), 3))) * rank(delta(volume, 3)))
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha011_max_vwap_close
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha011_min_vwap_close
    )
) * 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume_delta3
    )
 AS alpha011,
        
        -- Alpha 012: (sign(delta(volume, 1)) * (-1 * delta(close, 1)))
        
    CASE 
        WHEN volume_delta1 > 0 THEN 1
        WHEN volume_delta1 < 0 THEN -1
        ELSE 0
    END
 * (-1 * close_delta1) AS alpha012,
        
        -- Alpha 013: (-1 * rank(covariance(rank(close), rank(volume), 5)))
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY cov_close_volume_5
    )
 AS alpha013,
        
        -- Alpha 014: ((-1 * rank(delta(returns, 3))) * correlation(open, volume, 10))
        (-1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha014_delta_returns
    )
) * corr_open_volume_10 AS alpha014,
        
        -- Alpha 015: (-1 * sum(rank(correlation(rank(high), rank(volume), 3)), 3))
        -1 * 
    SUM(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha015_corr_high_vol
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha015,
        
        -- Alpha 016: (-1 * rank(covariance(rank(high), rank(volume), 5)))
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY cov_high_volume_5
    )
 AS alpha016,
        
        -- Alpha 017: (((-1 * rank(ts_rank(close, 10))) * rank(delta(delta(close, 1), 1))) * rank(ts_rank((volume / adv20), 5)))
        ((-1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close_ts_rank10
    )
) * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha017_delta_delta_close
    )
) * 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha017_ts_rank_vol_adv
    )
 AS alpha017,
        
        -- Alpha 018: (-1 * rank(((stddev(abs((close - open)), 5) + (close - open)) + correlation(close, open, 10))))
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha018_stddev + alpha018_close_open_diff + alpha018_corr_close_open
    )
 AS alpha018,
        
        -- Alpha 019: ((-1 * sign(((close - delay(close, 7)) + delta(close, 7)))) * (1 + rank((1 + sum(returns, 250)))))
        (-1 * 
    CASE 
        WHEN alpha019_close_diff_plus_delta > 0 THEN 1
        WHEN alpha019_close_diff_plus_delta < 0 THEN -1
        ELSE 0
    END
) * 
        (1 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha019_sum_returns
    )
) AS alpha019,
        
        -- Alpha 020: (((-1 * rank((open - delay(high, 1)))) * rank((open - delay(close, 1)))) * rank((open - delay(low, 1))))
        ((-1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha020_open_delay_high
    )
) * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha020_open_delay_close
    )
) * 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha020_open_delay_low
    )
 AS alpha020
        
    FROM intermediate_calcs
)

SELECT * FROM alpha_factors
    );
  
  
[0m17:56:40.419336 [debug] [Thread-2 (]: DuckDB adapter: Rolling back transaction.
[0m17:56:40.419878 [debug] [Thread-4 (]: Re-using an available connection from the pool (formerly model.quant_features.features_ohlc_technical, now model.quant_features.alpha_factors_076_101)
[0m17:56:40.420414 [debug] [Thread-1 (]: DuckDB adapter: Rolling back transaction.
[0m17:56:40.420950 [debug] [Thread-2 (]: On model.quant_features.alpha_factors_051_075: ROLLBACK
[0m17:56:40.421604 [debug] [Thread-4 (]: Began compiling node model.quant_features.alpha_factors_076_101
[0m17:56:40.423755 [debug] [Thread-3 (]: Failed to rollback 'model.quant_features.alpha_factors_021_050'
[0m17:56:40.424226 [debug] [Thread-1 (]: On model.quant_features.alpha_factors_001_020: ROLLBACK
[0m17:56:40.431918 [debug] [Thread-2 (]: Failed to rollback 'model.quant_features.alpha_factors_051_075'
[0m17:56:40.432440 [debug] [Thread-3 (]: On model.quant_features.alpha_factors_021_050: Close
[0m17:56:40.434858 [debug] [Thread-1 (]: Failed to rollback 'model.quant_features.alpha_factors_001_020'
[0m17:56:40.435314 [debug] [Thread-2 (]: On model.quant_features.alpha_factors_051_075: Close
[0m17:56:40.459193 [debug] [Thread-4 (]: Writing injected SQL for node "model.quant_features.alpha_factors_076_101"
[0m17:56:40.459589 [debug] [Thread-1 (]: On model.quant_features.alpha_factors_001_020: Close
[0m17:56:40.463248 [debug] [Thread-3 (]: Runtime Error in model alpha_factors_021_050 (models/alpha101/alpha_factors_021_050.sql)
  Parser Error: window functions are not allowed in window definitions
[0m17:56:40.465408 [debug] [Thread-2 (]: Runtime Error in model alpha_factors_051_075 (models/alpha101/alpha_factors_051_075.sql)
  Parser Error: window functions are not allowed in window definitions
[0m17:56:40.465824 [debug] [Thread-4 (]: Began executing node model.quant_features.alpha_factors_076_101
[0m17:56:40.468499 [debug] [Thread-1 (]: Runtime Error in model alpha_factors_001_020 (models/alpha101/alpha_factors_001_020.sql)
  Parser Error: window functions are not allowed in window definitions
[0m17:56:40.469061 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff88051add0>]}
[0m17:56:40.469723 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff880519cc0>]}
[0m17:56:40.472196 [debug] [Thread-4 (]: Writing runtime sql for node "model.quant_features.alpha_factors_076_101"
[0m17:56:40.472737 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8805a6210>]}
[0m17:56:40.473493 [error] [Thread-3 (]: 6 of 11 ERROR creating sql table model main.alpha_factors_021_050 .............. [[31mERROR[0m in 0.14s]
[0m17:56:40.474157 [error] [Thread-2 (]: 7 of 11 ERROR creating sql table model main.alpha_factors_051_075 .............. [[31mERROR[0m in 0.14s]
[0m17:56:40.474833 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.alpha_factors_076_101"
[0m17:56:40.475362 [error] [Thread-1 (]: 5 of 11 ERROR creating sql table model main.alpha_factors_001_020 .............. [[31mERROR[0m in 0.15s]
[0m17:56:40.475918 [debug] [Thread-3 (]: Finished running node model.quant_features.alpha_factors_021_050
[0m17:56:40.476467 [debug] [Thread-2 (]: Finished running node model.quant_features.alpha_factors_051_075
[0m17:56:40.476834 [debug] [Thread-4 (]: On model.quant_features.alpha_factors_076_101: BEGIN
[0m17:56:40.477403 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha_factors_001_020
[0m17:56:40.477800 [debug] [Thread-3 (]: Began running node model.quant_features.alpha_factors_advanced
[0m17:56:40.478551 [debug] [Thread-7 (]: Marking all children of 'model.quant_features.alpha_factors_021_050' to be skipped because of status 'error'.  Reason: Runtime Error in model alpha_factors_021_050 (models/alpha101/alpha_factors_021_050.sql)
  Parser Error: window functions are not allowed in window definitions.
[0m17:56:40.478855 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m17:56:40.479652 [info ] [Thread-3 (]: 9 of 11 START sql table model main.alpha_factors_advanced ...................... [RUN]
[0m17:56:40.480623 [debug] [Thread-7 (]: Marking all children of 'model.quant_features.alpha_factors_051_075' to be skipped because of status 'error'.  Reason: Runtime Error in model alpha_factors_051_075 (models/alpha101/alpha_factors_051_075.sql)
  Parser Error: window functions are not allowed in window definitions.
[0m17:56:40.481347 [debug] [Thread-3 (]: Re-using an available connection from the pool (formerly model.quant_features.alpha_factors_021_050, now model.quant_features.alpha_factors_advanced)
[0m17:56:40.481787 [debug] [Thread-7 (]: Marking all children of 'model.quant_features.alpha_factors_001_020' to be skipped because of status 'error'.  Reason: Runtime Error in model alpha_factors_001_020 (models/alpha101/alpha_factors_001_020.sql)
  Parser Error: window functions are not allowed in window definitions.
[0m17:56:40.482098 [debug] [Thread-3 (]: Began compiling node model.quant_features.alpha_factors_advanced
[0m17:56:40.482433 [debug] [Thread-4 (]: SQL status: OK in 0.003 seconds
[0m17:56:40.498584 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.alpha_factors_076_101"
[0m17:56:40.501205 [debug] [Thread-3 (]: Writing injected SQL for node "model.quant_features.alpha_factors_advanced"
[0m17:56:40.503355 [debug] [Thread-4 (]: On model.quant_features.alpha_factors_076_101: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_factors_076_101"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_factors_076_101__dbt_tmp"
  
    as (
      

-- Alpha 101 因子计算 (076-101)

WITH base_data AS (
    SELECT * FROM "quant_features"."main"."alpha_base_data"
),

-- 预计算复杂的中间变量
intermediate_calcs AS (
    SELECT 
        *,
        -- Alpha076 相关计算
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    vwap - 
    LAG(vwap, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (12 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (12 * (12 + 1) / 2)
 AS alpha076_decay_vwap_delta,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(low, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 80 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS alpha076_ts_rank_corr,
        
        -- Alpha077 相关计算
        ((high + low) / 2 + high) - (vwap + high) AS alpha077_price_diff,
        
    -- 使用DuckDB的CORR窗口函数
    CORR((high + low) / 2, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha077_corr_hl_adv,
        
        -- Alpha078 相关计算
        low * 0.352 + vwap * 0.648 AS alpha078_weighted_low_vwap,
        
        -- Alpha079 相关计算
        close * 0.607 + open * 0.393 AS alpha079_weighted_close_open,
        
        -- Alpha080 相关计算
        open * 0.868 + high * 0.132 AS alpha080_weighted_open_high,
        
        -- Alpha081 相关计算
        POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 49 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )

    )
, 4) AS alpha081_rank_corr_power,
        
        -- Alpha082 相关计算
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    open - 
    LAG(open, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (15 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (15 * (15 + 1) / 2)
 AS alpha082_decay_open_delta,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(volume, open) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    )
 AS alpha082_corr_vol_open,
        
        -- Alpha083 相关计算
        
    CASE 
        WHEN 
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE high - low / 
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

    END
 AS alpha083_hl_close_ratio,
        vwap - close AS alpha083_vwap_close_diff,
        
        -- Alpha084 相关计算
        vwap - 
    MAX(vwap) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )
 AS alpha084_vwap_max_diff,
        
        -- Alpha085 相关计算
        high * 0.877 + close * 0.123 AS alpha085_weighted_high_close,
        
        -- Alpha086 相关计算
        (open + close) - (vwap + open) AS alpha086_price_diff,
        
        -- Alpha087 相关计算
        close * 0.370 + vwap * 0.630 AS alpha087_weighted_close_vwap,
        
        -- Alpha088 相关计算
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
) - (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
) AS alpha088_rank_diff,
        
        -- Alpha089 相关计算
        low AS alpha089_low,  -- 简化，因为 low * 0.967285 + low * (1 - 0.967285) = low
        
        -- Alpha090 相关计算
        close - 
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha090_close_max_diff,
        
        -- Alpha091 相关计算
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)
 AS alpha091_decay_corr1,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 49 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
 AS alpha091_corr2,
        
        -- Alpha092 相关计算
        ((high + low) / 2 + close) < (low + open) AS alpha092_condition,
        
        -- Alpha093 相关计算
        close * 0.524 + vwap * 0.476 AS alpha093_weighted_close_vwap,
        
        -- Alpha094 相关计算
        vwap - 
    MIN(vwap) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 AS alpha094_vwap_min_diff,
        
        -- Alpha095 相关计算
        open - 
    MIN(open) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 AS alpha095_open_min_diff,
        
        -- Alpha096 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
 AS alpha096_corr_close_adv,
        
        -- Alpha097 相关计算
        low * 0.721 + vwap * 0.279 AS alpha097_weighted_low_vwap,
        
        -- Alpha098 相关计算
        
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 25 PRECEDING AND CURRENT ROW
    )
 AS alpha098_sum_adv5,
        
    (9 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
 = 
    MIN(
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )
 AS alpha098_argmin_corr,
        
        -- Alpha099 相关计算
        
    SUM((high + low) / 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS alpha099_sum_hl_mid,
        
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS alpha099_sum_adv60,
        
        -- Alpha100 相关计算
        
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE (close - low) - (high - close) / high - low
    END
 * volume AS alpha100_price_vol,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    (30 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (close = 
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )

    )
 AS alpha100_corr_diff,
        
        -- Alpha101 相关计算
        close - open AS alpha101_close_open_diff,
        high - low + 0.001 AS alpha101_hl_range
        
    FROM base_data
),

-- 最终Alpha因子计算
final_alpha_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- Alpha 076: VWAP变化与低价相关性最大值因子
        GREATEST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha076_decay_vwap_delta
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha076_ts_rank_corr * 
        (17 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (17 * (17 + 1) / 2)

        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha076,
        
        -- Alpha 077: 价格差异与中价相关性最小值因子
        LEAST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha077_price_diff * 
        (20 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (20 * (20 + 1) / 2)

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha077_corr_hl_adv * 
        (6 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (6 * (6 + 1) / 2)

    )

        ) AS alpha077,
        
        -- Alpha 078: 加权低价VWAP与VWAP成交量相关性幂函数因子
        POWER(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    SUM(alpha078_weighted_low_vwap) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

    )

        ) AS alpha078,
        
        -- Alpha 079: 加权收盘开盘价与VWAP关系比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    alpha079_weighted_close_open - 
    LAG(alpha079_weighted_close_open, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 149 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )

    )

            THEN 1 
            ELSE 0 
        END AS alpha079,
        
        -- Alpha 080: 加权开盘高价符号与高价平均日成交量相关性幂函数因子
        POWER(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN 
    alpha080_weighted_open_high - 
    LAG(alpha080_weighted_open_high, 4) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 > 0 THEN 1
        WHEN 
    alpha080_weighted_open_high - 
    LAG(alpha080_weighted_open_high, 4) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 < 0 THEN -1
        ELSE 0
    END

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(high, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha080,
        
        -- Alpha 081: VWAP平均日成交量相关性对数与VWAP成交量相关性比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN alpha081_rank_corr_power > 0 THEN LN(alpha081_rank_corr_power)
        ELSE NULL
    END

    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

    )

            THEN -1 
            ELSE 1 
        END AS alpha081,
        
        -- Alpha 082: 开盘价变化与成交量相关性最小值因子
        LEAST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha082_decay_open_delta
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha082_corr_vol_open * 
        (7 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (7 * (7 + 1) / 2)

        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha082,
        
        -- Alpha 083: 高低价收盘价比率延迟与成交量关系因子
        
    CASE 
        WHEN 
    CASE 
        WHEN alpha083_vwap_close_diff = 0 OR alpha083_vwap_close_diff IS NULL THEN NULL
        WHEN ABS(alpha083_vwap_close_diff) < 1e-10 THEN NULL
        ELSE alpha083_hl_close_ratio / alpha083_vwap_close_diff
    END
 = 0 OR 
    CASE 
        WHEN alpha083_vwap_close_diff = 0 OR alpha083_vwap_close_diff IS NULL THEN NULL
        WHEN ABS(alpha083_vwap_close_diff) < 1e-10 THEN NULL
        ELSE alpha083_hl_close_ratio / alpha083_vwap_close_diff
    END
 IS NULL THEN NULL
        WHEN ABS(
    CASE 
        WHEN alpha083_vwap_close_diff = 0 OR alpha083_vwap_close_diff IS NULL THEN NULL
        WHEN ABS(alpha083_vwap_close_diff) < 1e-10 THEN NULL
        ELSE alpha083_hl_close_ratio / alpha083_vwap_close_diff
    END
) < 1e-10 THEN NULL
        ELSE 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    LAG(alpha083_hl_close_ratio, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

    )
 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )

    )
 / 
    CASE 
        WHEN alpha083_vwap_close_diff = 0 OR alpha083_vwap_close_diff IS NULL THEN NULL
        WHEN ABS(alpha083_vwap_close_diff) < 1e-10 THEN NULL
        ELSE alpha083_hl_close_ratio / alpha083_vwap_close_diff
    END

    END
 AS alpha083,
        
        -- Alpha 084: VWAP排序幂函数因子
        
    
    CASE 
        WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha084_vwap_max_diff
        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
 > 0 THEN 1
        WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha084_vwap_max_diff
        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
 < 0 THEN -1
        ELSE 0
    END
 * POWER(ABS(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha084_vwap_max_diff
        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
), 
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

)
 AS alpha084,
        
        -- Alpha 085: 加权高价收盘价与中价成交量相关性幂函数因子
        POWER(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha085_weighted_high_close, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY (high + low) / 2
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )

    )

        ) AS alpha085,
        
        -- Alpha 086: 收盘价平均日成交量相关性与价格差异比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(close, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha086_price_diff
    )

            THEN -1 
            ELSE 1 
        END AS alpha086,
        
        -- Alpha 087: 加权收盘VWAP与平均日成交量相关性最大值因子
        GREATEST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha087_weighted_close_vwap - 
    LAG(alpha087_weighted_close_vwap, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    ABS(
    -- 使用DuckDB的CORR窗口函数
    CORR(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 80 PRECEDING AND CURRENT ROW
    )

, close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )
)
 * 
        (5 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (5 * (5 + 1) / 2)

        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha087,
        
        -- Alpha 088: 开盘低价与高价收盘价排序差异最小值因子
        LEAST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha088_rank_diff * 
        (8 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (8 * (8 + 1) / 2)

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 * 
        (7 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (7 * (7 + 1) / 2)

        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )

        ) AS alpha088,
        
        -- Alpha 089: 低价平均日成交量相关性与VWAP变化差异因子
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha089_low, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (6 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (6 * (6 + 1) / 2)

        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
 - 
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    vwap - 
    LAG(vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (10 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (10 * (10 + 1) / 2)

        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )
 AS alpha089,
        
        -- Alpha 090: 收盘价最大值与平均日成交量低价相关性幂函数因子
        POWER(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha090_close_max_diff
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha090,
        
        -- Alpha 091: 复合衰减相关性差异因子
        (
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha091_decay_corr1 * 
        (4 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (4 * (4 + 1) / 2)

        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 - 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha091_corr2 * 
        (4 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (4 * (4 + 1) / 2)

    )
) * -1 AS alpha091,
        
        -- Alpha 092: 价格条件与低价平均日成交量相关性最小值因子
        LEAST(
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        CASE WHEN alpha092_condition THEN 1 ELSE 0 END * 
        (15 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (15 * (15 + 1) / 2)

        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 * 
        (7 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (7 * (7 + 1) / 2)

        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )

        ) AS alpha092,
        
        -- Alpha 093: VWAP平均日成交量相关性与加权收盘VWAP变化比率因子
        
    CASE 
        WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha093_weighted_close_vwap - 
    LAG(alpha093_weighted_close_vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

    )
 = 0 OR 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha093_weighted_close_vwap - 
    LAG(alpha093_weighted_close_vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

    )
 IS NULL THEN NULL
        WHEN ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha093_weighted_close_vwap - 
    LAG(alpha093_weighted_close_vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

    )
) < 1e-10 THEN NULL
        ELSE 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 80 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    )
 * 
        (20 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (20 * (20 + 1) / 2)

        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 / 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha093_weighted_close_vwap - 
    LAG(alpha093_weighted_close_vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

    )

    END
 AS alpha093,
        
        -- Alpha 094: VWAP最小值与VWAP平均日成交量相关性幂函数因子
        POWER(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha094_vwap_min_diff
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 17 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha094,
        
        -- Alpha 095: 开盘价最小值与中价平均日成交量相关性幂函数比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha095_open_min_diff
    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    SUM((high + low) / 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )

    )
, 5)
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )

            THEN 1 
            ELSE 0 
        END AS alpha095,
        
        -- Alpha 096: VWAP成交量相关性与收盘价平均日成交量相关性最大值因子
        GREATEST(
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
 * 
        (4 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (4 * (4 + 1) / 2)

        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用ROW_NUMBER()来找到最大值的位置
    (13 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (alpha096_corr_close_adv = 
    MAX(alpha096_corr_close_adv) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )
 * 
        (14 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (14 * (14 + 1) / 2)

        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha096,
        
        -- Alpha 097: 加权低价VWAP变化与低价平均日成交量相关性差异因子
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha097_weighted_low_vwap - 
    LAG(alpha097_weighted_low_vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (20 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (20 * (20 + 1) / 2)

    )
 - 
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY low
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
) * -1 AS alpha097,
        
        -- Alpha 098: VWAP平均日成交量相关性与开盘价平均日成交量相关性最小值差异因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, alpha098_sum_adv5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 * 
        (7 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (7 * (7 + 1) / 2)

    )
 - 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha098_argmin_corr
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (8 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (8 * (8 + 1) / 2)

    )
 AS alpha098,
        
        -- Alpha 099: 中价平均日成交量相关性与低价成交量相关性比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha099_sum_hl_mid, alpha099_sum_adv60) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )

    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(low, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

    )

            THEN -1 
            ELSE 1 
        END AS alpha099,
        
        -- Alpha 100: 复合标准化因子
        0 - (1 * (1.5 * 
    
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha100_price_vol
    )
 / NULLIF(
        SUM(ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha100_price_vol
    )
)) OVER (PARTITION BY timestamp), 0
    )
 - 
        
    alpha100_corr_diff / NULLIF(
        SUM(ABS(alpha100_corr_diff)) OVER (PARTITION BY timestamp), 0
    )
 * 
    CASE 
        WHEN 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 = 0 OR 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 IS NULL THEN NULL
        WHEN ABS(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

) < 1e-10 THEN NULL
        ELSE volume / 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )


    END
)) AS alpha100,
        
        -- Alpha 101: 收盘开盘价差与高低价范围比率因子
        
    CASE 
        WHEN alpha101_hl_range = 0 OR alpha101_hl_range IS NULL THEN NULL
        WHEN ABS(alpha101_hl_range) < 1e-10 THEN NULL
        ELSE alpha101_close_open_diff / alpha101_hl_range
    END
 AS alpha101
        
    FROM base_data
),

-- 最终计算所有Alpha因子
final_alpha_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- Alpha 076-101
        alpha076, alpha077, alpha078, alpha079, alpha080,
        alpha081, alpha082, alpha083, alpha084, alpha085,
        alpha086, alpha087, alpha088, alpha089, alpha090,
        alpha091, alpha092, alpha093, alpha094, alpha095,
        alpha096, alpha097, alpha098, alpha099, alpha100,
        alpha101,
        
        -- 添加一些质量控制指标
        CASE 
            WHEN alpha076 IS NOT NULL AND ABS(alpha076) < 100 THEN 1 ELSE 0 
        END AS alpha076_valid,
        
        CASE 
            WHEN alpha085 IS NOT NULL AND ABS(alpha085) < 100 THEN 1 ELSE 0 
        END AS alpha085_valid,
        
        CASE 
            WHEN alpha101 IS NOT NULL AND ABS(alpha101) < 10 THEN 1 ELSE 0 
        END AS alpha101_valid,
        
        -- 计算有效因子数量
        (
            CASE WHEN alpha076 IS NOT NULL AND ABS(alpha076) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha077 IS NOT NULL AND ABS(alpha077) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha078 IS NOT NULL AND ABS(alpha078) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha079 IS NOT NULL AND ABS(alpha079) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha080 IS NOT NULL AND ABS(alpha080) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha081 IS NOT NULL AND ABS(alpha081) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha082 IS NOT NULL AND ABS(alpha082) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha083 IS NOT NULL AND ABS(alpha083) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha084 IS NOT NULL AND ABS(alpha084) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha085 IS NOT NULL AND ABS(alpha085) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha086 IS NOT NULL AND ABS(alpha086) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha087 IS NOT NULL AND ABS(alpha087) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha088 IS NOT NULL AND ABS(alpha088) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha089 IS NOT NULL AND ABS(alpha089) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha090 IS NOT NULL AND ABS(alpha090) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha091 IS NOT NULL AND ABS(alpha091) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha092 IS NOT NULL AND ABS(alpha092) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha093 IS NOT NULL AND ABS(alpha093) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha094 IS NOT NULL AND ABS(alpha094) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha095 IS NOT NULL AND ABS(alpha095) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha096 IS NOT NULL AND ABS(alpha096) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha097 IS NOT NULL AND ABS(alpha097) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha098 IS NOT NULL AND ABS(alpha098) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha099 IS NOT NULL AND ABS(alpha099) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha100 IS NOT NULL AND ABS(alpha100) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha101 IS NOT NULL AND ABS(alpha101) < 10 THEN 1 ELSE 0 END
        ) AS valid_factors_count
        
    FROM intermediate_calcs
)

SELECT * FROM final_alpha_factors
    );
  
  
[0m17:56:40.505741 [debug] [Thread-3 (]: Began executing node model.quant_features.alpha_factors_advanced
[0m17:56:40.508703 [debug] [Thread-4 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_factors_076_101"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_factors_076_101__dbt_tmp"
  
    as (
      

-- Alpha 101 因子计算 (076-101)

WITH base_data AS (
    SELECT * FROM "quant_features"."main"."alpha_base_data"
),

-- 预计算复杂的中间变量
intermediate_calcs AS (
    SELECT 
        *,
        -- Alpha076 相关计算
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    vwap - 
    LAG(vwap, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (12 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (12 * (12 + 1) / 2)
 AS alpha076_decay_vwap_delta,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(low, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 80 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS alpha076_ts_rank_corr,
        
        -- Alpha077 相关计算
        ((high + low) / 2 + high) - (vwap + high) AS alpha077_price_diff,
        
    -- 使用DuckDB的CORR窗口函数
    CORR((high + low) / 2, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS alpha077_corr_hl_adv,
        
        -- Alpha078 相关计算
        low * 0.352 + vwap * 0.648 AS alpha078_weighted_low_vwap,
        
        -- Alpha079 相关计算
        close * 0.607 + open * 0.393 AS alpha079_weighted_close_open,
        
        -- Alpha080 相关计算
        open * 0.868 + high * 0.132 AS alpha080_weighted_open_high,
        
        -- Alpha081 相关计算
        POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 49 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )

    )
, 4) AS alpha081_rank_corr_power,
        
        -- Alpha082 相关计算
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    open - 
    LAG(open, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (15 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (15 * (15 + 1) / 2)
 AS alpha082_decay_open_delta,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(volume, open) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    )
 AS alpha082_corr_vol_open,
        
        -- Alpha083 相关计算
        
    CASE 
        WHEN 
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE high - low / 
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

    END
 AS alpha083_hl_close_ratio,
        vwap - close AS alpha083_vwap_close_diff,
        
        -- Alpha084 相关计算
        vwap - 
    MAX(vwap) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )
 AS alpha084_vwap_max_diff,
        
        -- Alpha085 相关计算
        high * 0.877 + close * 0.123 AS alpha085_weighted_high_close,
        
        -- Alpha086 相关计算
        (open + close) - (vwap + open) AS alpha086_price_diff,
        
        -- Alpha087 相关计算
        close * 0.370 + vwap * 0.630 AS alpha087_weighted_close_vwap,
        
        -- Alpha088 相关计算
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
) - (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
 + 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
) AS alpha088_rank_diff,
        
        -- Alpha089 相关计算
        low AS alpha089_low,  -- 简化，因为 low * 0.967285 + low * (1 - 0.967285) = low
        
        -- Alpha090 相关计算
        close - 
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS alpha090_close_max_diff,
        
        -- Alpha091 相关计算
        
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)
 AS alpha091_decay_corr1,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 49 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
 AS alpha091_corr2,
        
        -- Alpha092 相关计算
        ((high + low) / 2 + close) < (low + open) AS alpha092_condition,
        
        -- Alpha093 相关计算
        close * 0.524 + vwap * 0.476 AS alpha093_weighted_close_vwap,
        
        -- Alpha094 相关计算
        vwap - 
    MIN(vwap) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 AS alpha094_vwap_min_diff,
        
        -- Alpha095 相关计算
        open - 
    MIN(open) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 AS alpha095_open_min_diff,
        
        -- Alpha096 相关计算
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
 AS alpha096_corr_close_adv,
        
        -- Alpha097 相关计算
        low * 0.721 + vwap * 0.279 AS alpha097_weighted_low_vwap,
        
        -- Alpha098 相关计算
        
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 25 PRECEDING AND CURRENT ROW
    )
 AS alpha098_sum_adv5,
        
    (9 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
 = 
    MIN(
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )
 AS alpha098_argmin_corr,
        
        -- Alpha099 相关计算
        
    SUM((high + low) / 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS alpha099_sum_hl_mid,
        
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS alpha099_sum_adv60,
        
        -- Alpha100 相关计算
        
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE (close - low) - (high - close) / high - low
    END
 * volume AS alpha100_price_vol,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 - 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    (30 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (close = 
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )

    )
 AS alpha100_corr_diff,
        
        -- Alpha101 相关计算
        close - open AS alpha101_close_open_diff,
        high - low + 0.001 AS alpha101_hl_range
        
    FROM base_data
),

-- 最终Alpha因子计算
final_alpha_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- Alpha 076: VWAP变化与低价相关性最大值因子
        GREATEST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha076_decay_vwap_delta
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha076_ts_rank_corr * 
        (17 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (17 * (17 + 1) / 2)

        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha076,
        
        -- Alpha 077: 价格差异与中价相关性最小值因子
        LEAST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha077_price_diff * 
        (20 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (20 * (20 + 1) / 2)

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha077_corr_hl_adv * 
        (6 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (6 * (6 + 1) / 2)

    )

        ) AS alpha077,
        
        -- Alpha 078: 加权低价VWAP与VWAP成交量相关性幂函数因子
        POWER(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    SUM(alpha078_weighted_low_vwap) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

    )

        ) AS alpha078,
        
        -- Alpha 079: 加权收盘开盘价与VWAP关系比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    alpha079_weighted_close_open - 
    LAG(alpha079_weighted_close_open, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 149 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )

    )

            THEN 1 
            ELSE 0 
        END AS alpha079,
        
        -- Alpha 080: 加权开盘高价符号与高价平均日成交量相关性幂函数因子
        POWER(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN 
    alpha080_weighted_open_high - 
    LAG(alpha080_weighted_open_high, 4) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 > 0 THEN 1
        WHEN 
    alpha080_weighted_open_high - 
    LAG(alpha080_weighted_open_high, 4) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 < 0 THEN -1
        ELSE 0
    END

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(high, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha080,
        
        -- Alpha 081: VWAP平均日成交量相关性对数与VWAP成交量相关性比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN alpha081_rank_corr_power > 0 THEN LN(alpha081_rank_corr_power)
        ELSE NULL
    END

    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

    )

            THEN -1 
            ELSE 1 
        END AS alpha081,
        
        -- Alpha 082: 开盘价变化与成交量相关性最小值因子
        LEAST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha082_decay_open_delta
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha082_corr_vol_open * 
        (7 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (7 * (7 + 1) / 2)

        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha082,
        
        -- Alpha 083: 高低价收盘价比率延迟与成交量关系因子
        
    CASE 
        WHEN 
    CASE 
        WHEN alpha083_vwap_close_diff = 0 OR alpha083_vwap_close_diff IS NULL THEN NULL
        WHEN ABS(alpha083_vwap_close_diff) < 1e-10 THEN NULL
        ELSE alpha083_hl_close_ratio / alpha083_vwap_close_diff
    END
 = 0 OR 
    CASE 
        WHEN alpha083_vwap_close_diff = 0 OR alpha083_vwap_close_diff IS NULL THEN NULL
        WHEN ABS(alpha083_vwap_close_diff) < 1e-10 THEN NULL
        ELSE alpha083_hl_close_ratio / alpha083_vwap_close_diff
    END
 IS NULL THEN NULL
        WHEN ABS(
    CASE 
        WHEN alpha083_vwap_close_diff = 0 OR alpha083_vwap_close_diff IS NULL THEN NULL
        WHEN ABS(alpha083_vwap_close_diff) < 1e-10 THEN NULL
        ELSE alpha083_hl_close_ratio / alpha083_vwap_close_diff
    END
) < 1e-10 THEN NULL
        ELSE 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    LAG(alpha083_hl_close_ratio, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

    )
 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )

    )
 / 
    CASE 
        WHEN alpha083_vwap_close_diff = 0 OR alpha083_vwap_close_diff IS NULL THEN NULL
        WHEN ABS(alpha083_vwap_close_diff) < 1e-10 THEN NULL
        ELSE alpha083_hl_close_ratio / alpha083_vwap_close_diff
    END

    END
 AS alpha083,
        
        -- Alpha 084: VWAP排序幂函数因子
        
    
    CASE 
        WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha084_vwap_max_diff
        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
 > 0 THEN 1
        WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha084_vwap_max_diff
        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
 < 0 THEN -1
        ELSE 0
    END
 * POWER(ABS(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha084_vwap_max_diff
        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
), 
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

)
 AS alpha084,
        
        -- Alpha 085: 加权高价收盘价与中价成交量相关性幂函数因子
        POWER(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha085_weighted_high_close, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY (high + low) / 2
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )

    )

        ) AS alpha085,
        
        -- Alpha 086: 收盘价平均日成交量相关性与价格差异比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(close, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha086_price_diff
    )

            THEN -1 
            ELSE 1 
        END AS alpha086,
        
        -- Alpha 087: 加权收盘VWAP与平均日成交量相关性最大值因子
        GREATEST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha087_weighted_close_vwap - 
    LAG(alpha087_weighted_close_vwap, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (3 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (3 * (3 + 1) / 2)

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    ABS(
    -- 使用DuckDB的CORR窗口函数
    CORR(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 80 PRECEDING AND CURRENT ROW
    )

, close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )
)
 * 
        (5 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (5 * (5 + 1) / 2)

        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha087,
        
        -- Alpha 088: 开盘低价与高价收盘价排序差异最小值因子
        LEAST(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha088_rank_diff * 
        (8 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (8 * (8 + 1) / 2)

    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 20 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 * 
        (7 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (7 * (7 + 1) / 2)

        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )

        ) AS alpha088,
        
        -- Alpha 089: 低价平均日成交量相关性与VWAP变化差异因子
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha089_low, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (6 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (6 * (6 + 1) / 2)

        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
 - 
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    vwap - 
    LAG(vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (10 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (10 * (10 + 1) / 2)

        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    )
 AS alpha089,
        
        -- Alpha 090: 收盘价最大值与平均日成交量低价相关性幂函数因子
        POWER(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha090_close_max_diff
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

, low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha090,
        
        -- Alpha 091: 复合衰减相关性差异因子
        (
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha091_decay_corr1 * 
        (4 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (4 * (4 + 1) / 2)

        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 - 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        alpha091_corr2 * 
        (4 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (4 * (4 + 1) / 2)

    )
) * -1 AS alpha091,
        
        -- Alpha 092: 价格条件与低价平均日成交量相关性最小值因子
        LEAST(
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        CASE WHEN alpha092_condition THEN 1 ELSE 0 END * 
        (15 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 14 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (15 * (15 + 1) / 2)

        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 29 PRECEDING AND CURRENT ROW
    )


    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 * 
        (7 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (7 * (7 + 1) / 2)

        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )

        ) AS alpha092,
        
        -- Alpha 093: VWAP平均日成交量相关性与加权收盘VWAP变化比率因子
        
    CASE 
        WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha093_weighted_close_vwap - 
    LAG(alpha093_weighted_close_vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

    )
 = 0 OR 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha093_weighted_close_vwap - 
    LAG(alpha093_weighted_close_vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

    )
 IS NULL THEN NULL
        WHEN ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha093_weighted_close_vwap - 
    LAG(alpha093_weighted_close_vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

    )
) < 1e-10 THEN NULL
        ELSE 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 80 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    )
 * 
        (20 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (20 * (20 + 1) / 2)

        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 / 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha093_weighted_close_vwap - 
    LAG(alpha093_weighted_close_vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

    )

    END
 AS alpha093,
        
        -- Alpha 094: VWAP最小值与VWAP平均日成交量相关性幂函数因子
        POWER(
            
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha094_vwap_min_diff
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY vwap
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 17 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha094,
        
        -- Alpha 095: 开盘价最小值与中价平均日成交量相关性幂函数比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha095_open_min_diff
    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY POWER(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    SUM((high + low) / 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
, 
    SUM(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 39 PRECEDING AND CURRENT ROW
    )

) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )

    )
, 5)
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )

            THEN 1 
            ELSE 0 
        END AS alpha095,
        
        -- Alpha 096: VWAP成交量相关性与收盘价平均日成交量相关性最大值因子
        GREATEST(
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    )
 * 
        (4 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 3 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (4 * (4 + 1) / 2)

        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
,
            
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用ROW_NUMBER()来找到最大值的位置
    (13 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (alpha096_corr_close_adv = 
    MAX(alpha096_corr_close_adv) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )
 * 
        (14 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (14 * (14 + 1) / 2)

        ROWS BETWEEN 12 PRECEDING AND CURRENT ROW
    )

        ) * -1 AS alpha096,
        
        -- Alpha 097: 加权低价VWAP变化与低价平均日成交量相关性差异因子
        (
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    alpha097_weighted_low_vwap - 
    LAG(alpha097_weighted_low_vwap, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 * 
        (20 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (20 * (20 + 1) / 2)

    )
 - 
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY low
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )


        ROWS BETWEEN 16 PRECEDING AND CURRENT ROW
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

        ROWS BETWEEN 18 PRECEDING AND CURRENT ROW
    )
 * 
        (16 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 15 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (16 * (16 + 1) / 2)

        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
) * -1 AS alpha097,
        
        -- Alpha 098: VWAP平均日成交量相关性与开盘价平均日成交量相关性最小值差异因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, alpha098_sum_adv5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 * 
        (7 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (7 * (7 + 1) / 2)

    )
 - 
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 实现线性衰减权重的加权平均
    SUM(
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY alpha098_argmin_corr
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    )
 * 
        (8 - ROW_NUMBER() OVER (
            PARTITION BY symbol 
            ORDER BY timestamp DESC
            ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
        ) + 1)
    ) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    ) / 
    -- 权重总和 = d*(d+1)/2
    (8 * (8 + 1) / 2)

    )
 AS alpha098,
        
        -- Alpha 099: 中价平均日成交量相关性与低价成交量相关性比较因子
        CASE 
            WHEN 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(alpha099_sum_hl_mid, alpha099_sum_adv60) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )

    )
 < 
                 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(low, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )

    )

            THEN -1 
            ELSE 1 
        END AS alpha099,
        
        -- Alpha 100: 复合标准化因子
        0 - (1 * (1.5 * 
    
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha100_price_vol
    )
 / NULLIF(
        SUM(ABS(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY alpha100_price_vol
    )
)) OVER (PARTITION BY timestamp), 0
    )
 - 
        
    alpha100_corr_diff / NULLIF(
        SUM(ABS(alpha100_corr_diff)) OVER (PARTITION BY timestamp), 0
    )
 * 
    CASE 
        WHEN 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 = 0 OR 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 IS NULL THEN NULL
        WHEN ABS(
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

) < 1e-10 THEN NULL
        ELSE volume / 
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )


    END
)) AS alpha100,
        
        -- Alpha 101: 收盘开盘价差与高低价范围比率因子
        
    CASE 
        WHEN alpha101_hl_range = 0 OR alpha101_hl_range IS NULL THEN NULL
        WHEN ABS(alpha101_hl_range) < 1e-10 THEN NULL
        ELSE alpha101_close_open_diff / alpha101_hl_range
    END
 AS alpha101
        
    FROM base_data
),

-- 最终计算所有Alpha因子
final_alpha_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- Alpha 076-101
        alpha076, alpha077, alpha078, alpha079, alpha080,
        alpha081, alpha082, alpha083, alpha084, alpha085,
        alpha086, alpha087, alpha088, alpha089, alpha090,
        alpha091, alpha092, alpha093, alpha094, alpha095,
        alpha096, alpha097, alpha098, alpha099, alpha100,
        alpha101,
        
        -- 添加一些质量控制指标
        CASE 
            WHEN alpha076 IS NOT NULL AND ABS(alpha076) < 100 THEN 1 ELSE 0 
        END AS alpha076_valid,
        
        CASE 
            WHEN alpha085 IS NOT NULL AND ABS(alpha085) < 100 THEN 1 ELSE 0 
        END AS alpha085_valid,
        
        CASE 
            WHEN alpha101 IS NOT NULL AND ABS(alpha101) < 10 THEN 1 ELSE 0 
        END AS alpha101_valid,
        
        -- 计算有效因子数量
        (
            CASE WHEN alpha076 IS NOT NULL AND ABS(alpha076) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha077 IS NOT NULL AND ABS(alpha077) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha078 IS NOT NULL AND ABS(alpha078) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha079 IS NOT NULL AND ABS(alpha079) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha080 IS NOT NULL AND ABS(alpha080) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha081 IS NOT NULL AND ABS(alpha081) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha082 IS NOT NULL AND ABS(alpha082) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha083 IS NOT NULL AND ABS(alpha083) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha084 IS NOT NULL AND ABS(alpha084) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha085 IS NOT NULL AND ABS(alpha085) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha086 IS NOT NULL AND ABS(alpha086) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha087 IS NOT NULL AND ABS(alpha087) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha088 IS NOT NULL AND ABS(alpha088) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha089 IS NOT NULL AND ABS(alpha089) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha090 IS NOT NULL AND ABS(alpha090) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha091 IS NOT NULL AND ABS(alpha091) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha092 IS NOT NULL AND ABS(alpha092) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha093 IS NOT NULL AND ABS(alpha093) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha094 IS NOT NULL AND ABS(alpha094) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha095 IS NOT NULL AND ABS(alpha095) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha096 IS NOT NULL AND ABS(alpha096) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha097 IS NOT NULL AND ABS(alpha097) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha098 IS NOT NULL AND ABS(alpha098) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha099 IS NOT NULL AND ABS(alpha099) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha100 IS NOT NULL AND ABS(alpha100) < 100 THEN 1 ELSE 0 END +
            CASE WHEN alpha101 IS NOT NULL AND ABS(alpha101) < 10 THEN 1 ELSE 0 END
        ) AS valid_factors_count
        
    FROM intermediate_calcs
)

SELECT * FROM final_alpha_factors
    );
  
  
[0m17:56:40.512175 [debug] [Thread-3 (]: Writing runtime sql for node "model.quant_features.alpha_factors_advanced"
[0m17:56:40.513019 [debug] [Thread-4 (]: DuckDB adapter: Rolling back transaction.
[0m17:56:40.513580 [debug] [Thread-4 (]: On model.quant_features.alpha_factors_076_101: ROLLBACK
[0m17:56:40.515947 [debug] [Thread-4 (]: Failed to rollback 'model.quant_features.alpha_factors_076_101'
[0m17:56:40.516221 [debug] [Thread-4 (]: On model.quant_features.alpha_factors_076_101: Close
[0m17:56:40.517244 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.alpha_factors_advanced"
[0m17:56:40.517600 [debug] [Thread-3 (]: On model.quant_features.alpha_factors_advanced: BEGIN
[0m17:56:40.517800 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m17:56:40.518243 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m17:56:40.518464 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.alpha_factors_advanced"
[0m17:56:40.519294 [debug] [Thread-3 (]: On model.quant_features.alpha_factors_advanced: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_factors_advanced"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_factors_advanced__dbt_tmp"
  
    as (
      

-- Alpha 101 高级因子计算 (精选重要因子)
-- 包含一些最有效和最常用的Alpha因子

WITH base_data AS (
    SELECT * FROM "quant_features"."main"."alpha_base_data"
),

-- 计算一些经典的高频使用因子
classic_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- ========================================
        -- 价格动量类因子
        -- ========================================
        
        -- 价格反转因子 (类似Alpha001的简化版)
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用ROW_NUMBER()来找到最大值的位置
    (5 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (close = 
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )

    )
 - 0.5 AS momentum_reversal,
        
        -- 短期价格动量
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 AS short_momentum,
        
        -- 中期价格动量  
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 AS medium_momentum,
        
        -- 长期价格动量
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    close - 
    LAG(close, 20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 AS long_momentum,
        
        -- 价格加速度因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 - 
    LAG(
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 AS price_acceleration,
        
        -- ========================================
        -- 成交量价格关系因子
        -- ========================================
        
        -- 量价背离因子 (类似Alpha003)
        -1 * 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS volume_price_divergence,
        
        -- 量价确认因子 (类似Alpha006)
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS volume_price_confirmation,
        
        -- 成交量突破因子 (类似Alpha007)
        CASE 
            WHEN adv20 < volume THEN 
    CASE 
        WHEN 
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 > 0 THEN 1
        WHEN 
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 < 0 THEN -1
        ELSE 0
    END

            ELSE 0
        END AS volume_breakout,
        
        -- 相对成交量因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END

    )
 AS relative_volume,
        
        -- ========================================
        -- 波动率相关因子
        -- ========================================
        
        -- 波动率排序因子 (类似Alpha004)
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )

        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
 AS volatility_rank,
        
        -- 价格波动率因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

    )
 AS price_volatility,
        
        -- 收益率波动率因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

    )
 AS return_volatility,
        
        -- 波动率突破因子
        CASE 
            WHEN 
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 > 
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 THEN 1
            ELSE -1
        END AS volatility_breakout,
        
        -- ========================================
        -- 趋势跟踪因子
        -- ========================================
        
        -- 移动平均趋势因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close - close_ma20
    )
 AS ma_trend,
        
        -- 多重时间框架趋势
        
    CASE 
        WHEN close - close_ma5 > 0 THEN 1
        WHEN close - close_ma5 < 0 THEN -1
        ELSE 0
    END
 + 
    CASE 
        WHEN close_ma5 - close_ma10 > 0 THEN 1
        WHEN close_ma5 - close_ma10 < 0 THEN -1
        ELSE 0
    END
 + 
        
    CASE 
        WHEN close_ma10 - close_ma20 > 0 THEN 1
        WHEN close_ma10 - close_ma20 < 0 THEN -1
        ELSE 0
    END
 AS multi_timeframe_trend,
        
        -- 趋势强度因子
        
    ABS(close - close_ma20)
 / 
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS trend_strength,
        
        -- ========================================
        -- 均值回归因子
        -- ========================================
        
        -- 布林带位置因子
        
    CASE 
        WHEN 4 * close_std20 = 0 OR 4 * close_std20 IS NULL THEN NULL
        WHEN ABS(4 * close_std20) < 1e-10 THEN NULL
        ELSE close - (close_ma20 - 2 * close_std20) / 4 * close_std20
    END
 AS bollinger_position,
        
        -- 价格偏离因子
        (close - close_ma20) / close_ma20 AS price_deviation,
        
        -- RSI类因子 (简化版)
        CASE 
            WHEN 
    AVG(CASE WHEN returns > 0 THEN returns ELSE 0 END) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 = 0 THEN 0
            ELSE 
    AVG(CASE WHEN returns > 0 THEN returns ELSE 0 END) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 / 
                 (
    AVG(CASE WHEN returns > 0 THEN returns ELSE 0 END) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 + 
                  
    AVG(CASE WHEN returns < 0 THEN ABS(returns) ELSE 0 END) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
)
        END AS rsi_like_factor,
        
        -- ========================================
        -- 高低价相关因子
        -- ========================================
        
        -- 高低价位置因子
        
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE close - low / high - low
    END
 AS hl_position,
        
        -- 高低价范围因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high - low
    )
 AS hl_range,
        
        -- 影线长度因子
        (high - GREATEST(open, close)) + (LEAST(open, close) - low) AS shadow_length,
        
        -- ========================================
        -- 组合技术因子
        -- ========================================
        
        -- MACD类因子
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 - 
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 25 PRECEDING AND CURRENT ROW
    )
 AS macd_like,
        
        -- 随机震荡因子
        
    CASE 
        WHEN 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE close - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 / 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )

    END
 AS stoch_like,
        
        -- 威廉指标类因子
        
    CASE 
        WHEN 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - close / 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )

    END
 AS williams_like,
        
        -- ========================================
        -- 市场微观结构因子
        -- ========================================
        
        -- 开盘缺口因子
        
    CASE 
        WHEN close_lag1 = 0 OR close_lag1 IS NULL THEN NULL
        WHEN ABS(close_lag1) < 1e-10 THEN NULL
        ELSE open - close_lag1 / close_lag1
    END
 AS opening_gap,
        
        -- 收盘强度因子
        
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE close - open / high - low
    END
 AS closing_strength,
        
        -- 日内动量因子
        
    CASE 
        WHEN open = 0 OR open IS NULL THEN NULL
        WHEN ABS(open) < 1e-10 THEN NULL
        ELSE close - open / open
    END
 AS intraday_momentum,
        
        -- 日内波动率因子
        
    CASE 
        WHEN close = 0 OR close IS NULL THEN NULL
        WHEN ABS(close) < 1e-10 THEN NULL
        ELSE high - low / close
    END
 AS intraday_volatility,
        
        -- ========================================
        -- 跨期套利因子
        -- ========================================
        
        -- 期限结构因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(close, 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

    )
 AS term_structure,
        
        -- 基差因子 (现货与期货价差的代理)
        close - 
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS basis_like,
        
        -- 便利收益因子
        
    CASE 
        WHEN 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 = 0 OR 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 IS NULL THEN NULL
        WHEN ABS(
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) < 1e-10 THEN NULL
        ELSE close - delay(close, 1) / 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

    END
 - 
        
    AVG(
    CASE 
        WHEN 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 = 0 OR 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 IS NULL THEN NULL
        WHEN ABS(
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) < 1e-10 THEN NULL
        ELSE close - delay(close, 1) / 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

    END
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS convenience_yield,
        
        -- ========================================
        -- 情绪和行为因子
        -- ========================================
        
        -- 投资者情绪因子 (基于成交量)
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END

    )
 * 
    CASE 
        WHEN returns > 0 THEN 1
        WHEN returns < 0 THEN -1
        ELSE 0
    END
 AS sentiment_volume,
        
        -- 羊群效应因子
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END

    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS herding_effect,
        
        -- 过度反应因子
        
    CASE 
        WHEN returns > 0 THEN 1
        WHEN returns < 0 THEN -1
        ELSE 0
    END
 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    ABS(returns)

    )
 AS overreaction,
        
        -- ========================================
        -- 质量和盈利能力代理因子
        -- ========================================
        
        -- 价格质量因子 (价格稳定性)
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )

    )
 AS price_quality,
        
        -- 流动性因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE volume * close / high - low
    END

    )
 AS liquidity,
        
        -- 效率因子 (价格发现效率)
        
    ABS(
    -- 使用DuckDB的CORR窗口函数
    CORR(returns, 
    LAG(returns, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
)
 AS efficiency
        
    FROM more_intermediate
),

-- 因子后处理：标准化和去极值
processed_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- 对所有因子进行标准化处理
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY momentum_reversal
    )

    
 AS momentum_reversal_norm,
        
    
        -- Z-score标准化
        (short_momentum - AVG(short_momentum) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(short_momentum) OVER (PARTITION BY timestamp), 0)
    
 AS short_momentum_norm,
        
    
        -- Z-score标准化
        (medium_momentum - AVG(medium_momentum) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(medium_momentum) OVER (PARTITION BY timestamp), 0)
    
 AS medium_momentum_norm,
        
    
        -- Z-score标准化
        (long_momentum - AVG(long_momentum) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(long_momentum) OVER (PARTITION BY timestamp), 0)
    
 AS long_momentum_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY price_acceleration
    )

    
 AS price_acceleration_norm,
        
        
    
        -- Z-score标准化
        (volume_price_divergence - AVG(volume_price_divergence) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(volume_price_divergence) OVER (PARTITION BY timestamp), 0)
    
 AS volume_price_divergence_norm,
        
    
        -- Z-score标准化
        (volume_price_confirmation - AVG(volume_price_confirmation) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(volume_price_confirmation) OVER (PARTITION BY timestamp), 0)
    
 AS volume_price_confirmation_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume_breakout
    )

    
 AS volume_breakout_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY relative_volume
    )

    
 AS relative_volume_norm,
        
        
    
        -- Z-score标准化
        (volatility_rank - AVG(volatility_rank) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(volatility_rank) OVER (PARTITION BY timestamp), 0)
    
 AS volatility_rank_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY price_volatility
    )

    
 AS price_volatility_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY return_volatility
    )

    
 AS return_volatility_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volatility_breakout
    )

    
 AS volatility_breakout_norm,
        
        
    
        -- Z-score标准化
        (ma_trend - AVG(ma_trend) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(ma_trend) OVER (PARTITION BY timestamp), 0)
    
 AS ma_trend_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY multi_timeframe_trend
    )

    
 AS multi_timeframe_trend_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY trend_strength
    )

    
 AS trend_strength_norm,
        
        
    
        -- Z-score标准化
        (bollinger_position - AVG(bollinger_position) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(bollinger_position) OVER (PARTITION BY timestamp), 0)
    
 AS bollinger_position_norm,
        
    
        -- Z-score标准化
        (price_deviation - AVG(price_deviation) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(price_deviation) OVER (PARTITION BY timestamp), 0)
    
 AS price_deviation_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY rsi_like_factor
    )

    
 AS rsi_like_factor_norm,
        
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY hl_position
    )

    
 AS hl_position_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY hl_range
    )

    
 AS hl_range_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY shadow_length
    )

    
 AS shadow_length_norm,
        
        
    
        -- Z-score标准化
        (macd_like - AVG(macd_like) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(macd_like) OVER (PARTITION BY timestamp), 0)
    
 AS macd_like_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY stoch_like
    )

    
 AS stoch_like_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY williams_like
    )

    
 AS williams_like_norm,
        
        
    
        -- Z-score标准化
        (opening_gap - AVG(opening_gap) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(opening_gap) OVER (PARTITION BY timestamp), 0)
    
 AS opening_gap_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY closing_strength
    )

    
 AS closing_strength_norm,
        
    
        -- Z-score标准化
        (intraday_momentum - AVG(intraday_momentum) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(intraday_momentum) OVER (PARTITION BY timestamp), 0)
    
 AS intraday_momentum_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY intraday_volatility
    )

    
 AS intraday_volatility_norm,
        
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY term_structure
    )

    
 AS term_structure_norm,
        
    
        -- Z-score标准化
        (basis_like - AVG(basis_like) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(basis_like) OVER (PARTITION BY timestamp), 0)
    
 AS basis_like_norm,
        
    
        -- Z-score标准化
        (convenience_yield - AVG(convenience_yield) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(convenience_yield) OVER (PARTITION BY timestamp), 0)
    
 AS convenience_yield_norm,
        
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY sentiment_volume
    )

    
 AS sentiment_volume_norm,
        
    
        -- Z-score标准化
        (herding_effect - AVG(herding_effect) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(herding_effect) OVER (PARTITION BY timestamp), 0)
    
 AS herding_effect_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY overreaction
    )

    
 AS overreaction_norm,
        
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY price_quality
    )

    
 AS price_quality_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY liquidity
    )

    
 AS liquidity_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY efficiency
    )

    
 AS efficiency_norm,
        
        -- 保留原始因子值用于调试
        momentum_reversal,
        volume_price_divergence,
        ma_trend,
        bollinger_position,
        opening_gap,
        sentiment_volume
        
    FROM alpha_factors
)

SELECT * FROM processed_factors
    );
  
  
[0m17:56:40.521441 [debug] [Thread-3 (]: DuckDB adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_factors_advanced"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_factors_advanced__dbt_tmp"
  
    as (
      

-- Alpha 101 高级因子计算 (精选重要因子)
-- 包含一些最有效和最常用的Alpha因子

WITH base_data AS (
    SELECT * FROM "quant_features"."main"."alpha_base_data"
),

-- 计算一些经典的高频使用因子
classic_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- ========================================
        -- 价格动量类因子
        -- ========================================
        
        -- 价格反转因子 (类似Alpha001的简化版)
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用ROW_NUMBER()来找到最大值的位置
    (5 - 1) - (
        ROW_NUMBER() OVER (
            PARTITION BY symbol, 
            (close = 
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
)
            ORDER BY timestamp DESC
        ) - 1
    )

    )
 - 0.5 AS momentum_reversal,
        
        -- 短期价格动量
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 AS short_momentum,
        
        -- 中期价格动量  
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 AS medium_momentum,
        
        -- 长期价格动量
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    close - 
    LAG(close, 20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 AS long_momentum,
        
        -- 价格加速度因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 - 
    LAG(
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )


    )
 AS price_acceleration,
        
        -- ========================================
        -- 成交量价格关系因子
        -- ========================================
        
        -- 量价背离因子 (类似Alpha003)
        -1 * 
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY open
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS volume_price_divergence,
        
        -- 量价确认因子 (类似Alpha006)
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS volume_price_confirmation,
        
        -- 成交量突破因子 (类似Alpha007)
        CASE 
            WHEN adv20 < volume THEN 
    CASE 
        WHEN 
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 > 0 THEN 1
        WHEN 
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 < 0 THEN -1
        ELSE 0
    END

            ELSE 0
        END AS volume_breakout,
        
        -- 相对成交量因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END

    )
 AS relative_volume,
        
        -- ========================================
        -- 波动率相关因子
        -- ========================================
        
        -- 波动率排序因子 (类似Alpha004)
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )

        ROWS BETWEEN 8 PRECEDING AND CURRENT ROW
    )
 AS volatility_rank,
        
        -- 价格波动率因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

    )
 AS price_volatility,
        
        -- 收益率波动率因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

    )
 AS return_volatility,
        
        -- 波动率突破因子
        CASE 
            WHEN 
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 > 
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 THEN 1
            ELSE -1
        END AS volatility_breakout,
        
        -- ========================================
        -- 趋势跟踪因子
        -- ========================================
        
        -- 移动平均趋势因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close - close_ma20
    )
 AS ma_trend,
        
        -- 多重时间框架趋势
        
    CASE 
        WHEN close - close_ma5 > 0 THEN 1
        WHEN close - close_ma5 < 0 THEN -1
        ELSE 0
    END
 + 
    CASE 
        WHEN close_ma5 - close_ma10 > 0 THEN 1
        WHEN close_ma5 - close_ma10 < 0 THEN -1
        ELSE 0
    END
 + 
        
    CASE 
        WHEN close_ma10 - close_ma20 > 0 THEN 1
        WHEN close_ma10 - close_ma20 < 0 THEN -1
        ELSE 0
    END
 AS multi_timeframe_trend,
        
        -- 趋势强度因子
        
    ABS(close - close_ma20)
 / 
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS trend_strength,
        
        -- ========================================
        -- 均值回归因子
        -- ========================================
        
        -- 布林带位置因子
        
    CASE 
        WHEN 4 * close_std20 = 0 OR 4 * close_std20 IS NULL THEN NULL
        WHEN ABS(4 * close_std20) < 1e-10 THEN NULL
        ELSE close - (close_ma20 - 2 * close_std20) / 4 * close_std20
    END
 AS bollinger_position,
        
        -- 价格偏离因子
        (close - close_ma20) / close_ma20 AS price_deviation,
        
        -- RSI类因子 (简化版)
        CASE 
            WHEN 
    AVG(CASE WHEN returns > 0 THEN returns ELSE 0 END) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 = 0 THEN 0
            ELSE 
    AVG(CASE WHEN returns > 0 THEN returns ELSE 0 END) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 / 
                 (
    AVG(CASE WHEN returns > 0 THEN returns ELSE 0 END) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 + 
                  
    AVG(CASE WHEN returns < 0 THEN ABS(returns) ELSE 0 END) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
)
        END AS rsi_like_factor,
        
        -- ========================================
        -- 高低价相关因子
        -- ========================================
        
        -- 高低价位置因子
        
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE close - low / high - low
    END
 AS hl_position,
        
        -- 高低价范围因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high - low
    )
 AS hl_range,
        
        -- 影线长度因子
        (high - GREATEST(open, close)) + (LEAST(open, close) - low) AS shadow_length,
        
        -- ========================================
        -- 组合技术因子
        -- ========================================
        
        -- MACD类因子
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 11 PRECEDING AND CURRENT ROW
    )
 - 
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 25 PRECEDING AND CURRENT ROW
    )
 AS macd_like,
        
        -- 随机震荡因子
        
    CASE 
        WHEN 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE close - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 / 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )

    END
 AS stoch_like,
        
        -- 威廉指标类因子
        
    CASE 
        WHEN 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 = 0 OR 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 IS NULL THEN NULL
        WHEN ABS(
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
) < 1e-10 THEN NULL
        ELSE 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - close / 
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )
 - 
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
    )

    END
 AS williams_like,
        
        -- ========================================
        -- 市场微观结构因子
        -- ========================================
        
        -- 开盘缺口因子
        
    CASE 
        WHEN close_lag1 = 0 OR close_lag1 IS NULL THEN NULL
        WHEN ABS(close_lag1) < 1e-10 THEN NULL
        ELSE open - close_lag1 / close_lag1
    END
 AS opening_gap,
        
        -- 收盘强度因子
        
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE close - open / high - low
    END
 AS closing_strength,
        
        -- 日内动量因子
        
    CASE 
        WHEN open = 0 OR open IS NULL THEN NULL
        WHEN ABS(open) < 1e-10 THEN NULL
        ELSE close - open / open
    END
 AS intraday_momentum,
        
        -- 日内波动率因子
        
    CASE 
        WHEN close = 0 OR close IS NULL THEN NULL
        WHEN ABS(close) < 1e-10 THEN NULL
        ELSE high - low / close
    END
 AS intraday_volatility,
        
        -- ========================================
        -- 跨期套利因子
        -- ========================================
        
        -- 期限结构因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    -- 使用DuckDB的CORR窗口函数
    CORR(close, 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

    )
 AS term_structure,
        
        -- 基差因子 (现货与期货价差的代理)
        close - 
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS basis_like,
        
        -- 便利收益因子
        
    CASE 
        WHEN 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 = 0 OR 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 IS NULL THEN NULL
        WHEN ABS(
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) < 1e-10 THEN NULL
        ELSE close - delay(close, 1) / 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

    END
 - 
        
    AVG(
    CASE 
        WHEN 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 = 0 OR 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 IS NULL THEN NULL
        WHEN ABS(
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) < 1e-10 THEN NULL
        ELSE close - delay(close, 1) / 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

    END
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS convenience_yield,
        
        -- ========================================
        -- 情绪和行为因子
        -- ========================================
        
        -- 投资者情绪因子 (基于成交量)
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END

    )
 * 
    CASE 
        WHEN returns > 0 THEN 1
        WHEN returns < 0 THEN -1
        ELSE 0
    END
 AS sentiment_volume,
        
        -- 羊群效应因子
        
    -- 使用DuckDB的CORR窗口函数
    CORR(
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns
    )
, 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN adv20 = 0 OR adv20 IS NULL THEN NULL
        WHEN ABS(adv20) < 1e-10 THEN NULL
        ELSE volume / adv20
    END

    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS herding_effect,
        
        -- 过度反应因子
        
    CASE 
        WHEN returns > 0 THEN 1
        WHEN returns < 0 THEN -1
        ELSE 0
    END
 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    ABS(returns)

    )
 AS overreaction,
        
        -- ========================================
        -- 质量和盈利能力代理因子
        -- ========================================
        
        -- 价格质量因子 (价格稳定性)
        -1 * 
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 59 PRECEDING AND CURRENT ROW
    )

    )
 AS price_quality,
        
        -- 流动性因子
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY 
    CASE 
        WHEN high - low = 0 OR high - low IS NULL THEN NULL
        WHEN ABS(high - low) < 1e-10 THEN NULL
        ELSE volume * close / high - low
    END

    )
 AS liquidity,
        
        -- 效率因子 (价格发现效率)
        
    ABS(
    -- 使用DuckDB的CORR窗口函数
    CORR(returns, 
    LAG(returns, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
)
 AS efficiency
        
    FROM more_intermediate
),

-- 因子后处理：标准化和去极值
processed_factors AS (
    SELECT 
        symbol,
        timestamp,
        
        -- 对所有因子进行标准化处理
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY momentum_reversal
    )

    
 AS momentum_reversal_norm,
        
    
        -- Z-score标准化
        (short_momentum - AVG(short_momentum) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(short_momentum) OVER (PARTITION BY timestamp), 0)
    
 AS short_momentum_norm,
        
    
        -- Z-score标准化
        (medium_momentum - AVG(medium_momentum) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(medium_momentum) OVER (PARTITION BY timestamp), 0)
    
 AS medium_momentum_norm,
        
    
        -- Z-score标准化
        (long_momentum - AVG(long_momentum) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(long_momentum) OVER (PARTITION BY timestamp), 0)
    
 AS long_momentum_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY price_acceleration
    )

    
 AS price_acceleration_norm,
        
        
    
        -- Z-score标准化
        (volume_price_divergence - AVG(volume_price_divergence) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(volume_price_divergence) OVER (PARTITION BY timestamp), 0)
    
 AS volume_price_divergence_norm,
        
    
        -- Z-score标准化
        (volume_price_confirmation - AVG(volume_price_confirmation) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(volume_price_confirmation) OVER (PARTITION BY timestamp), 0)
    
 AS volume_price_confirmation_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume_breakout
    )

    
 AS volume_breakout_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY relative_volume
    )

    
 AS relative_volume_norm,
        
        
    
        -- Z-score标准化
        (volatility_rank - AVG(volatility_rank) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(volatility_rank) OVER (PARTITION BY timestamp), 0)
    
 AS volatility_rank_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY price_volatility
    )

    
 AS price_volatility_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY return_volatility
    )

    
 AS return_volatility_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volatility_breakout
    )

    
 AS volatility_breakout_norm,
        
        
    
        -- Z-score标准化
        (ma_trend - AVG(ma_trend) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(ma_trend) OVER (PARTITION BY timestamp), 0)
    
 AS ma_trend_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY multi_timeframe_trend
    )

    
 AS multi_timeframe_trend_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY trend_strength
    )

    
 AS trend_strength_norm,
        
        
    
        -- Z-score标准化
        (bollinger_position - AVG(bollinger_position) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(bollinger_position) OVER (PARTITION BY timestamp), 0)
    
 AS bollinger_position_norm,
        
    
        -- Z-score标准化
        (price_deviation - AVG(price_deviation) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(price_deviation) OVER (PARTITION BY timestamp), 0)
    
 AS price_deviation_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY rsi_like_factor
    )

    
 AS rsi_like_factor_norm,
        
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY hl_position
    )

    
 AS hl_position_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY hl_range
    )

    
 AS hl_range_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY shadow_length
    )

    
 AS shadow_length_norm,
        
        
    
        -- Z-score标准化
        (macd_like - AVG(macd_like) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(macd_like) OVER (PARTITION BY timestamp), 0)
    
 AS macd_like_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY stoch_like
    )

    
 AS stoch_like_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY williams_like
    )

    
 AS williams_like_norm,
        
        
    
        -- Z-score标准化
        (opening_gap - AVG(opening_gap) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(opening_gap) OVER (PARTITION BY timestamp), 0)
    
 AS opening_gap_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY closing_strength
    )

    
 AS closing_strength_norm,
        
    
        -- Z-score标准化
        (intraday_momentum - AVG(intraday_momentum) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(intraday_momentum) OVER (PARTITION BY timestamp), 0)
    
 AS intraday_momentum_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY intraday_volatility
    )

    
 AS intraday_volatility_norm,
        
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY term_structure
    )

    
 AS term_structure_norm,
        
    
        -- Z-score标准化
        (basis_like - AVG(basis_like) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(basis_like) OVER (PARTITION BY timestamp), 0)
    
 AS basis_like_norm,
        
    
        -- Z-score标准化
        (convenience_yield - AVG(convenience_yield) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(convenience_yield) OVER (PARTITION BY timestamp), 0)
    
 AS convenience_yield_norm,
        
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY sentiment_volume
    )

    
 AS sentiment_volume_norm,
        
    
        -- Z-score标准化
        (herding_effect - AVG(herding_effect) OVER (PARTITION BY timestamp)) / 
        NULLIF(STDDEV(herding_effect) OVER (PARTITION BY timestamp), 0)
    
 AS herding_effect_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY overreaction
    )

    
 AS overreaction_norm,
        
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY price_quality
    )

    
 AS price_quality_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY liquidity
    )

    
 AS liquidity_norm,
        
    
        -- 排序标准化
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY efficiency
    )

    
 AS efficiency_norm,
        
        -- 保留原始因子值用于调试
        momentum_reversal,
        volume_price_divergence,
        ma_trend,
        bollinger_position,
        opening_gap,
        sentiment_volume
        
    FROM alpha_factors
)

SELECT * FROM processed_factors
    );
  
  
[0m17:56:40.522380 [debug] [Thread-3 (]: DuckDB adapter: Rolling back transaction.
[0m17:56:40.522656 [debug] [Thread-3 (]: On model.quant_features.alpha_factors_advanced: ROLLBACK
[0m17:56:40.524916 [debug] [Thread-3 (]: Failed to rollback 'model.quant_features.alpha_factors_advanced'
[0m17:56:40.525402 [debug] [Thread-3 (]: On model.quant_features.alpha_factors_advanced: Close
[0m17:56:40.527207 [debug] [Thread-4 (]: Runtime Error in model alpha_factors_076_101 (models/alpha101/alpha_factors_076_101.sql)
  Parser Error: window functions are not allowed in window definitions
[0m17:56:40.529826 [debug] [Thread-3 (]: Runtime Error in model alpha_factors_advanced (models/alpha101/alpha_factors_advanced.sql)
  Parser Error: window functions are not allowed in window definitions
[0m17:56:40.530218 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8805c0530>]}
[0m17:56:40.530596 [error] [Thread-3 (]: 9 of 11 ERROR creating sql table model main.alpha_factors_advanced ............. [[31mERROR[0m in 0.05s]
[0m17:56:40.530936 [debug] [Thread-3 (]: Finished running node model.quant_features.alpha_factors_advanced
[0m17:56:40.531610 [debug] [Thread-7 (]: Marking all children of 'model.quant_features.alpha_factors_advanced' to be skipped because of status 'error'.  Reason: Runtime Error in model alpha_factors_advanced (models/alpha101/alpha_factors_advanced.sql)
  Parser Error: window functions are not allowed in window definitions.
[0m17:56:40.531945 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '842ee3ee-a1d7-4f4c-8ea6-a15da5c2ba38', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8805c0530>]}
[0m17:56:40.532851 [error] [Thread-4 (]: 8 of 11 ERROR creating sql table model main.alpha_factors_076_101 .............. [[31mERROR[0m in 0.11s]
[0m17:56:40.533231 [debug] [Thread-4 (]: Finished running node model.quant_features.alpha_factors_076_101
[0m17:56:40.533665 [debug] [Thread-7 (]: Marking all children of 'model.quant_features.alpha_factors_076_101' to be skipped because of status 'error'.  Reason: Runtime Error in model alpha_factors_076_101 (models/alpha101/alpha_factors_076_101.sql)
  Parser Error: window functions are not allowed in window definitions.
[0m17:56:40.534183 [debug] [Thread-1 (]: Began running node model.quant_features.alpha101_complete
[0m17:56:40.534497 [info ] [Thread-1 (]: 11 of 11 SKIP relation main.alpha101_complete .................................. [[33mSKIP[0m]
[0m17:56:40.534850 [debug] [Thread-2 (]: Began running node model.quant_features.alpha_factors_final
[0m17:56:40.535182 [debug] [Thread-1 (]: Finished running node model.quant_features.alpha101_complete
[0m17:56:40.535525 [info ] [Thread-2 (]: 10 of 11 SKIP relation main.alpha_factors_final ................................ [[33mSKIP[0m]
[0m17:56:40.535879 [debug] [Thread-2 (]: Finished running node model.quant_features.alpha_factors_final
[0m17:56:40.537357 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:40.537642 [debug] [MainThread]: On master: BEGIN
[0m17:56:40.537820 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:56:40.538259 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:40.538476 [debug] [MainThread]: On master: COMMIT
[0m17:56:40.538656 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:40.538821 [debug] [MainThread]: On master: COMMIT
[0m17:56:40.539106 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:40.539292 [debug] [MainThread]: On master: Close
[0m17:56:40.539609 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:56:40.539798 [debug] [MainThread]: Connection 'model.quant_features.alpha_factors_001_020' was properly closed.
[0m17:56:40.539948 [debug] [MainThread]: Connection 'model.quant_features.alpha_factors_advanced' was properly closed.
[0m17:56:40.540097 [debug] [MainThread]: Connection 'model.quant_features.alpha_factors_051_075' was properly closed.
[0m17:56:40.540236 [debug] [MainThread]: Connection 'model.quant_features.alpha_factors_076_101' was properly closed.
[0m17:56:40.540490 [info ] [MainThread]: 
[0m17:56:40.540696 [info ] [MainThread]: Finished running 10 table models, 1 view model in 0 hours 0 minutes and 0.51 seconds (0.51s).
[0m17:56:40.541676 [debug] [MainThread]: Command end result
[0m17:56:40.563668 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:56:40.565196 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:56:40.570391 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m17:56:40.570686 [info ] [MainThread]: 
[0m17:56:40.570920 [info ] [MainThread]: [31mCompleted with 5 errors, 0 partial successes, and 0 warnings:[0m
[0m17:56:40.571125 [info ] [MainThread]: 
[0m17:56:40.571349 [error] [MainThread]: [31mFailure in model alpha_factors_021_050 (models/alpha101/alpha_factors_021_050.sql)[0m
[0m17:56:40.571556 [error] [MainThread]:   Runtime Error in model alpha_factors_021_050 (models/alpha101/alpha_factors_021_050.sql)
  Parser Error: window functions are not allowed in window definitions
[0m17:56:40.571707 [info ] [MainThread]: 
[0m17:56:40.571895 [info ] [MainThread]:   compiled code at target/compiled/quant_features/models/alpha101/alpha_factors_021_050.sql
[0m17:56:40.572061 [info ] [MainThread]: 
[0m17:56:40.572254 [error] [MainThread]: [31mFailure in model alpha_factors_051_075 (models/alpha101/alpha_factors_051_075.sql)[0m
[0m17:56:40.572436 [error] [MainThread]:   Runtime Error in model alpha_factors_051_075 (models/alpha101/alpha_factors_051_075.sql)
  Parser Error: window functions are not allowed in window definitions
[0m17:56:40.572583 [info ] [MainThread]: 
[0m17:56:40.572763 [info ] [MainThread]:   compiled code at target/compiled/quant_features/models/alpha101/alpha_factors_051_075.sql
[0m17:56:40.572918 [info ] [MainThread]: 
[0m17:56:40.573121 [error] [MainThread]: [31mFailure in model alpha_factors_001_020 (models/alpha101/alpha_factors_001_020.sql)[0m
[0m17:56:40.573310 [error] [MainThread]:   Runtime Error in model alpha_factors_001_020 (models/alpha101/alpha_factors_001_020.sql)
  Parser Error: window functions are not allowed in window definitions
[0m17:56:40.573455 [info ] [MainThread]: 
[0m17:56:40.573633 [info ] [MainThread]:   compiled code at target/compiled/quant_features/models/alpha101/alpha_factors_001_020.sql
[0m17:56:40.573774 [info ] [MainThread]: 
[0m17:56:40.573982 [error] [MainThread]: [31mFailure in model alpha_factors_advanced (models/alpha101/alpha_factors_advanced.sql)[0m
[0m17:56:40.574194 [error] [MainThread]:   Runtime Error in model alpha_factors_advanced (models/alpha101/alpha_factors_advanced.sql)
  Parser Error: window functions are not allowed in window definitions
[0m17:56:40.574344 [info ] [MainThread]: 
[0m17:56:40.574522 [info ] [MainThread]:   compiled code at target/compiled/quant_features/models/alpha101/alpha_factors_advanced.sql
[0m17:56:40.574669 [info ] [MainThread]: 
[0m17:56:40.574848 [error] [MainThread]: [31mFailure in model alpha_factors_076_101 (models/alpha101/alpha_factors_076_101.sql)[0m
[0m17:56:40.575030 [error] [MainThread]:   Runtime Error in model alpha_factors_076_101 (models/alpha101/alpha_factors_076_101.sql)
  Parser Error: window functions are not allowed in window definitions
[0m17:56:40.575181 [info ] [MainThread]: 
[0m17:56:40.575350 [info ] [MainThread]:   compiled code at target/compiled/quant_features/models/alpha101/alpha_factors_076_101.sql
[0m17:56:40.575496 [info ] [MainThread]: 
[0m17:56:40.575678 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=5 SKIP=2 NO-OP=0 TOTAL=11
[0m17:56:40.576368 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 0.9759967, "process_in_blocks": "0", "process_kernel_time": 0.198715, "process_mem_max_rss": "170316", "process_out_blocks": "5488", "process_user_time": 1.732822}
[0m17:56:40.576735 [debug] [MainThread]: Command `dbt run` failed at 17:56:40.576666 after 0.98 seconds
[0m17:56:40.576992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8805b4e30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8893e24b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8836e9c70>]}
[0m17:56:40.577241 [debug] [MainThread]: Flushing usage events
[0m17:56:40.999102 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:56:51.223401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7046887770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7047eb9a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70456bfd90>]}


============================== 17:56:51.225755 | 8d4f708d-fdcd-4bdc-a94a-7828ad800647 ==============================
[0m17:56:51.225755 [info ] [MainThread]: Running with dbt=1.10.9
[0m17:56:51.226141 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run --exclude alpha_factors_001_020 alpha_factors_021_050 alpha_factors_051_075 alpha_factors_076_101 alpha_factors_advanced alpha_factors_final alpha101_complete', 'write_json': 'True', 'introspect': 'True', 'log_format': 'default', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'debug': 'False', 'target_path': 'None', 'log_path': '/workspace/dbt_project/logs', 'use_colors': 'True', 'empty': 'False', 'static_parser': 'True', 'partial_parse': 'True', 'send_anonymous_usage_stats': 'True', 'profiles_dir': '/workspace/dbt_project', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'warn_error': 'None', 'version_check': 'True', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'log_cache_events': 'False'}
[0m17:56:51.366726 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8d4f708d-fdcd-4bdc-a94a-7828ad800647', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f704640a650>]}
[0m17:56:51.407992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8d4f708d-fdcd-4bdc-a94a-7828ad800647', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70457b6be0>]}
[0m17:56:51.409034 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m17:56:51.437488 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m17:56:51.514920 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:56:51.515163 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:56:51.545035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d4f708d-fdcd-4bdc-a94a-7828ad800647', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7045785450>]}
[0m17:56:51.605139 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:56:51.606330 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:56:51.616556 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d4f708d-fdcd-4bdc-a94a-7828ad800647', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f704172ce60>]}
[0m17:56:51.616909 [info ] [MainThread]: Found 11 models, 37 data tests, 1 source, 565 macros
[0m17:56:51.617133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d4f708d-fdcd-4bdc-a94a-7828ad800647', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7041768050>]}
[0m17:56:51.619373 [info ] [MainThread]: 
[0m17:56:51.619647 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:56:51.619828 [info ] [MainThread]: 
[0m17:56:51.620134 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m17:56:51.623326 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m17:56:51.640308 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m17:56:51.640578 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m17:56:51.640764 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:56:51.653034 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m17:56:51.653917 [debug] [ThreadPool]: On list_quant_features: Close
[0m17:56:51.654872 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m17:56:51.655264 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m17:56:51.659563 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:51.659812 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m17:56:51.659982 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:56:51.660644 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:56:51.661480 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:51.661692 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m17:56:51.662012 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:51.662202 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:51.662354 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m17:56:51.662666 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:51.663216 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:56:51.663416 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:56:51.663578 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:56:51.663954 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:56:51.664160 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m17:56:51.666068 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m17:56:51.669876 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:56:51.670159 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m17:56:51.670329 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:56:51.671080 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:56:51.671339 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:56:51.671515 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m17:56:51.678064 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m17:56:51.678961 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m17:56:51.679627 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m17:56:51.679854 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m17:56:51.681074 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d4f708d-fdcd-4bdc-a94a-7828ad800647', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70412e25b0>]}
[0m17:56:51.681448 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:51.681632 [debug] [MainThread]: On master: BEGIN
[0m17:56:51.681786 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:56:51.682207 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:51.682416 [debug] [MainThread]: On master: COMMIT
[0m17:56:51.682582 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:51.682734 [debug] [MainThread]: On master: COMMIT
[0m17:56:51.682976 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:51.683149 [debug] [MainThread]: On master: Close
[0m17:56:51.685363 [debug] [Thread-1 (]: Began running node model.quant_features.stg_ohlc_data
[0m17:56:51.685999 [info ] [Thread-1 (]: 1 of 4 START sql view model main.stg_ohlc_data ................................. [RUN]
[0m17:56:51.686405 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.stg_ohlc_data)
[0m17:56:51.686635 [debug] [Thread-1 (]: Began compiling node model.quant_features.stg_ohlc_data
[0m17:56:51.692768 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.stg_ohlc_data"
[0m17:56:51.693362 [debug] [Thread-1 (]: Began executing node model.quant_features.stg_ohlc_data
[0m17:56:51.717782 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.stg_ohlc_data"
[0m17:56:51.718352 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:51.718642 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: BEGIN
[0m17:56:51.718829 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:56:51.719592 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m17:56:51.719833 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:51.720064 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

  
  create view "quant_features"."main"."stg_ohlc_data__dbt_tmp" as (
    

with raw_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 数据清洗和验证
        case 
            when open <= 0 or high <= 0 or low <= 0 or close <= 0 then null
            when high < greatest(open, close, low) then null
            when low > least(open, close, high) then null
            else timestamp
        end as valid_timestamp
    from "quant_features"."raw"."ohlc_data"
),

cleaned_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础指标
        (high + low + close) / 3 as typical_price,
        (high - low) as daily_range,
        case when open != 0 then (close - open) / open else 0 end as daily_return,
        case when close != 0 then volume / close else 0 end as volume_price_ratio
    from raw_ohlc
    where valid_timestamp is not null
      and timestamp >= '2020-01-01'
      and timestamp <= '2024-12-31'
)

select * from cleaned_ohlc
  );

[0m17:56:51.721186 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m17:56:51.779678 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:51.779961 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */
alter view "quant_features"."main"."stg_ohlc_data" rename to "stg_ohlc_data__dbt_backup"
[0m17:56:51.780562 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:56:51.782450 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:51.782724 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */
alter view "quant_features"."main"."stg_ohlc_data__dbt_tmp" rename to "stg_ohlc_data"
[0m17:56:51.783219 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:56:51.791008 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m17:56:51.791304 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:51.791500 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m17:56:51.793739 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m17:56:51.797506 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:56:51.797793 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

      drop view if exists "quant_features"."main"."stg_ohlc_data__dbt_backup" cascade
    
[0m17:56:51.799967 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m17:56:51.801616 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: Close
[0m17:56:51.802982 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d4f708d-fdcd-4bdc-a94a-7828ad800647', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70412f3890>]}
[0m17:56:51.803476 [info ] [Thread-1 (]: 1 of 4 OK created sql view model main.stg_ohlc_data ............................ [[32mOK[0m in 0.12s]
[0m17:56:51.803837 [debug] [Thread-1 (]: Finished running node model.quant_features.stg_ohlc_data
[0m17:56:51.804950 [debug] [Thread-2 (]: Began running node model.quant_features.alpha_base_data
[0m17:56:51.805592 [info ] [Thread-2 (]: 2 of 4 START sql table model main.alpha_base_data .............................. [RUN]
[0m17:56:51.806037 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.quant_features.alpha_base_data'
[0m17:56:51.806262 [debug] [Thread-2 (]: Began compiling node model.quant_features.alpha_base_data
[0m17:56:51.806558 [debug] [Thread-3 (]: Began running node model.quant_features.mart_technical_indicators
[0m17:56:51.812252 [info ] [Thread-3 (]: 3 of 4 START sql table model main.mart_technical_indicators .................... [RUN]
[0m17:56:51.812636 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.quant_features.mart_technical_indicators'
[0m17:56:51.812853 [debug] [Thread-3 (]: Began compiling node model.quant_features.mart_technical_indicators
[0m17:56:51.815507 [debug] [Thread-3 (]: Writing injected SQL for node "model.quant_features.mart_technical_indicators"
[0m17:56:51.821222 [debug] [Thread-3 (]: Began executing node model.quant_features.mart_technical_indicators
[0m17:56:51.843529 [debug] [Thread-2 (]: Writing injected SQL for node "model.quant_features.alpha_base_data"
[0m17:56:51.847535 [debug] [Thread-3 (]: Writing runtime sql for node "model.quant_features.mart_technical_indicators"
[0m17:56:51.848093 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:51.848338 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: BEGIN
[0m17:56:51.848535 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m17:56:51.848975 [debug] [Thread-2 (]: Began executing node model.quant_features.alpha_base_data
[0m17:56:51.851120 [debug] [Thread-2 (]: Writing runtime sql for node "model.quant_features.alpha_base_data"
[0m17:56:51.851572 [debug] [Thread-3 (]: SQL status: OK in 0.003 seconds
[0m17:56:51.853310 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:51.853693 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */

  
    
    

    create  table
      "quant_features"."main"."mart_technical_indicators__dbt_tmp"
  
    as (
      

with base_data as (
    select * from "quant_features"."main"."stg_ohlc_data"
),

technical_indicators as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        typical_price,
        daily_range,
        daily_return,
        volume_price_ratio,
        
        -- 移动平均线
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 4 preceding and current row
        ) as ma_5,
        
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 9 preceding and current row
        ) as ma_10,
        
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as ma_20,
        
        -- 波动率 (标准差)
        stddev(daily_return) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as volatility_20d,
        
        -- RSI相关计算
        case when daily_return > 0 then daily_return else 0 end as gain,
        case when daily_return < 0 then abs(daily_return) else 0 end as loss,
        
        -- 价格位置指标
        (close - min(low) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        )) / nullif((max(high) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) - min(low) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        )), 0) as stoch_k_14,
        
        -- 成交量指标
        avg(volume) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as avg_volume_20d
        
    from base_data
),

rsi_calculation as (
    select *,
        -- RSI计算
        avg(gain) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) as avg_gain_14,
        
        avg(loss) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) as avg_loss_14
    from technical_indicators
),

final_indicators as (
    select *,
        case 
            when avg_loss_14 = 0 then 100
            when avg_gain_14 = 0 then 0
            else 100 - (100 / (1 + (avg_gain_14 / avg_loss_14)))
        end as rsi_14,
        
        -- 布林带
        ma_20 + (2 * stddev(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        )) as bollinger_upper,
        
        ma_20 - (2 * stddev(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        )) as bollinger_lower,
        
        -- 价格动量
        case when lag(close, 5) over (partition by symbol order by timestamp) != 0 
            then (close - lag(close, 5) over (partition by symbol order by timestamp)) / 
                 lag(close, 5) over (partition by symbol order by timestamp)
            else 0 
        end as momentum_5d,
        
        case when lag(close, 10) over (partition by symbol order by timestamp) != 0 
            then (close - lag(close, 10) over (partition by symbol order by timestamp)) / 
                 lag(close, 10) over (partition by symbol order by timestamp)
            else 0 
        end as momentum_10d
        
    from rsi_calculation
)

select * from final_indicators
    );
  
  
[0m17:56:51.852002 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:51.856649 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: BEGIN
[0m17:56:51.856915 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:56:51.857413 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m17:56:51.857648 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:51.858131 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_base_data__dbt_tmp"
  
    as (
      

-- Alpha 101 基础数据准备
-- 为Alpha因子计算准备所有必要的基础数据

WITH base_ohlc AS (
    SELECT 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算VWAP (简化版本，假设等权重)
        (high + low + close) / 3 AS vwap,
        -- 计算returns
        CASE 
            WHEN LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp) IS NOT NULL
            THEN (close - LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)) / 
                 LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)
            ELSE 0
        END AS returns
    FROM "quant_features"."main"."stg_ohlc_data"
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
),

enhanced_data AS (
    SELECT 
        *,
        -- 计算ADV (Average Daily Volume)
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 AS adv20,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

 AS adv10,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

 AS adv5,
        
        -- 预计算一些常用的时间序列指标
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_ma5,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ma10,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_ma20,
        
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_ma20,
        
        -- 预计算滚动标准差
        
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_std20,
        
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS returns_std20,
        
        -- 预计算一些延迟项
        
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag1,
        
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag2,
        
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag5,
        
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag10,
        
    LAG(close, 20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag20,
        
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS volume_lag1,
        
    LAG(high, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS high_lag1,
        
    LAG(low, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS low_lag1,
        
    LAG(vwap, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS vwap_lag5,
        
        -- 预计算一些差值项
        
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta1,
        
    close - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta2,
        
    close - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta3,
        
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta5,
        
    close - 
    LAG(close, 7) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta7,
        
    close - 
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta10,
        
    volume - 
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta1,
        
    volume - 
    LAG(volume, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta3,
        
    high - 
    LAG(high, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS high_delta2,
        
        -- 预计算一些排序项
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
 AS close_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
 AS volume_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
 AS high_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
 AS low_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
 AS vwap_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns
    )
 AS returns_rank,
        
        -- 预计算时间序列排序
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ts_rank10,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_ts_rank5,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY high
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_ts_rank5,
        
        -- 预计算一些最值项
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_min100,
        
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS close_max3,
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_min5,
        
    MAX(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_max5,
        
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS low_min5,
        
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS high_max3,
        
        -- 预计算一些求和项
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_sum5,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS close_sum8,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_sum20,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_sum100,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
    )
 AS close_sum200,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_sum5,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_sum20,
        
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 AS returns_sum250,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_sum5,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS high_sum20,
        
        -- 预计算一些相关性
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_close_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(open, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_open_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS corr_high_volume_5,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS corr_vwap_volume_6,
        
        -- 预计算一些协方差
        
    COVAR_SAMP(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_close_volume_5,
        
    COVAR_SAMP(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_high_volume_5
        
    FROM base_ohlc
    WHERE timestamp >= CAST('2020-01-01' AS DATE) - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数据
),

-- 过滤回原始时间范围
final_data AS (
    SELECT *
    FROM enhanced_data
    WHERE timestamp >= '2020-01-01'
      AND timestamp <= '2024-12-31'
)

SELECT * FROM final_data
    );
  
  
[0m17:56:51.876515 [debug] [Thread-3 (]: SQL status: OK in 0.022 seconds
[0m17:56:51.895935 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:51.896297 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */
alter table "quant_features"."main"."mart_technical_indicators" rename to "mart_technical_indicators__dbt_backup"
[0m17:56:51.896856 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m17:56:51.899854 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:51.900169 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */
alter table "quant_features"."main"."mart_technical_indicators__dbt_tmp" rename to "mart_technical_indicators"
[0m17:56:51.900649 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m17:56:51.904103 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: COMMIT
[0m17:56:51.904403 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:51.904606 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: COMMIT
[0m17:56:51.913735 [debug] [Thread-2 (]: SQL status: OK in 0.055 seconds
[0m17:56:51.916147 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:51.916480 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */
alter table "quant_features"."main"."alpha_base_data" rename to "alpha_base_data__dbt_backup"
[0m17:56:51.917112 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m17:56:51.918971 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:51.919298 [debug] [Thread-3 (]: SQL status: OK in 0.014 seconds
[0m17:56:51.921216 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:56:51.921522 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */

      drop table if exists "quant_features"."main"."mart_technical_indicators__dbt_backup" cascade
    
[0m17:56:51.919582 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */
alter table "quant_features"."main"."alpha_base_data__dbt_tmp" rename to "alpha_base_data"
[0m17:56:51.922420 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m17:56:51.923670 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: COMMIT
[0m17:56:51.923923 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:51.924388 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: COMMIT
[0m17:56:51.924145 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m17:56:51.925309 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: Close
[0m17:56:51.926584 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d4f708d-fdcd-4bdc-a94a-7828ad800647', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f704128eaf0>]}
[0m17:56:51.927097 [info ] [Thread-3 (]: 3 of 4 OK created sql table model main.mart_technical_indicators ............... [[32mOK[0m in 0.11s]
[0m17:56:51.927497 [debug] [Thread-3 (]: Finished running node model.quant_features.mart_technical_indicators
[0m17:56:51.929609 [debug] [Thread-4 (]: Began running node model.quant_features.features_ohlc_technical
[0m17:56:51.930107 [info ] [Thread-4 (]: 4 of 4 START sql table model main.features_ohlc_technical ...................... [RUN]
[0m17:56:51.930979 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.quant_features.features_ohlc_technical'
[0m17:56:51.931335 [debug] [Thread-2 (]: SQL status: OK in 0.007 seconds
[0m17:56:51.931685 [debug] [Thread-4 (]: Began compiling node model.quant_features.features_ohlc_technical
[0m17:56:51.933672 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:56:51.936513 [debug] [Thread-4 (]: Writing injected SQL for node "model.quant_features.features_ohlc_technical"
[0m17:56:51.937101 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

      drop table if exists "quant_features"."main"."alpha_base_data__dbt_backup" cascade
    
[0m17:56:51.937922 [debug] [Thread-4 (]: Began executing node model.quant_features.features_ohlc_technical
[0m17:56:51.940713 [debug] [Thread-4 (]: Writing runtime sql for node "model.quant_features.features_ohlc_technical"
[0m17:56:51.941282 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:51.941555 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: BEGIN
[0m17:56:51.941772 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m17:56:51.942685 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m17:56:51.942993 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:51.943316 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

  
    
    

    create  table
      "quant_features"."main"."features_ohlc_technical__dbt_tmp"
  
    as (
      

with technical_data as (
    select * from "quant_features"."main"."mart_technical_indicators"
),

feature_engineering as (
    select 
        symbol,
        timestamp,
        
        -- 基础价格特征
        close as price,
        daily_return,
        volatility_20d,
        
        -- 趋势特征
        ma_5,
        ma_10,
        ma_20,
        case when close > ma_5 then 1 else 0 end as price_above_ma5,
        case when close > ma_10 then 1 else 0 end as price_above_ma10,
        case when close > ma_20 then 1 else 0 end as price_above_ma20,
        case when ma_5 > ma_10 then 1 else 0 end as ma5_above_ma10,
        case when ma_10 > ma_20 then 1 else 0 end as ma10_above_ma20,
        
        -- 技术指标特征
        rsi_14,
        case when rsi_14 > 70 then 1 else 0 end as rsi_overbought,
        case when rsi_14 < 30 then 1 else 0 end as rsi_oversold,
        
        stoch_k_14,
        case when stoch_k_14 > 0.8 then 1 else 0 end as stoch_overbought,
        case when stoch_k_14 < 0.2 then 1 else 0 end as stoch_oversold,
        
        -- 布林带特征
        bollinger_upper,
        bollinger_lower,
        case when close > bollinger_upper then 1 else 0 end as price_above_bb_upper,
        case when close < bollinger_lower then 1 else 0 end as price_below_bb_lower,
        case 
            when bollinger_upper - bollinger_lower != 0 
            then (close - bollinger_lower) / (bollinger_upper - bollinger_lower)
            else 0.5
        end as bb_position,
        
        -- 动量特征
        momentum_5d,
        momentum_10d,
        case when momentum_5d > 0 then 1 else 0 end as momentum_5d_positive,
        case when momentum_10d > 0 then 1 else 0 end as momentum_10d_positive,
        
        -- 成交量特征
        volume,
        avg_volume_20d,
        case when avg_volume_20d != 0 then volume / avg_volume_20d else 0 end as volume_ratio,
        case when volume > avg_volume_20d * 1.5 then 1 else 0 end as high_volume,
        
        -- 价格范围特征
        daily_range,
        case when lag(close) over (partition by symbol order by timestamp) != 0 
            then daily_range / lag(close) over (partition by symbol order by timestamp)
            else 0
        end as range_ratio,
        
        -- 组合特征
        case when rsi_14 > 70 and stoch_k_14 > 0.8 then 1 else 0 end as double_overbought,
        case when rsi_14 < 30 and stoch_k_14 < 0.2 then 1 else 0 end as double_oversold,
        
        -- 时间特征
        extract(hour from timestamp) as hour,
        extract(dow from timestamp) as day_of_week,
        extract(month from timestamp) as month,
        
        -- 标识特征用于Feast
        concat(symbol, '_', date_trunc('day', timestamp)::string) as entity_id,
        timestamp as event_timestamp
        
    from technical_data
    where timestamp >= current_date - interval '20' days
)

select * from feature_engineering
    );
  
  
[0m17:56:51.947868 [debug] [Thread-2 (]: SQL status: OK in 0.009 seconds
[0m17:56:51.948795 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: Close
[0m17:56:51.949399 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d4f708d-fdcd-4bdc-a94a-7828ad800647', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f704067f610>]}
[0m17:56:51.949806 [info ] [Thread-2 (]: 2 of 4 OK created sql table model main.alpha_base_data ......................... [[32mOK[0m in 0.14s]
[0m17:56:51.950201 [debug] [Thread-2 (]: Finished running node model.quant_features.alpha_base_data
[0m17:56:51.950584 [debug] [Thread-4 (]: SQL status: OK in 0.007 seconds
[0m17:56:51.952542 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:51.952880 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */
alter table "quant_features"."main"."features_ohlc_technical" rename to "features_ohlc_technical__dbt_backup"
[0m17:56:51.955729 [debug] [Thread-4 (]: SQL status: OK in 0.003 seconds
[0m17:56:51.957872 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:51.958206 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */
alter table "quant_features"."main"."features_ohlc_technical__dbt_tmp" rename to "features_ohlc_technical"
[0m17:56:51.958739 [debug] [Thread-4 (]: SQL status: OK in 0.000 seconds
[0m17:56:51.959686 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m17:56:51.959991 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:51.960243 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m17:56:51.961710 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m17:56:51.963153 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:56:51.963400 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

      drop table if exists "quant_features"."main"."features_ohlc_technical__dbt_backup" cascade
    
[0m17:56:51.965203 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m17:56:51.966121 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: Close
[0m17:56:51.966594 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d4f708d-fdcd-4bdc-a94a-7828ad800647', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f704076d250>]}
[0m17:56:51.966981 [info ] [Thread-4 (]: 4 of 4 OK created sql table model main.features_ohlc_technical ................. [[32mOK[0m in 0.04s]
[0m17:56:51.967342 [debug] [Thread-4 (]: Finished running node model.quant_features.features_ohlc_technical
[0m17:56:51.969033 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:51.969282 [debug] [MainThread]: On master: BEGIN
[0m17:56:51.969446 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:56:51.969836 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:51.970048 [debug] [MainThread]: On master: COMMIT
[0m17:56:51.970208 [debug] [MainThread]: Using duckdb connection "master"
[0m17:56:51.970356 [debug] [MainThread]: On master: COMMIT
[0m17:56:51.970621 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:56:51.970799 [debug] [MainThread]: On master: Close
[0m17:56:51.971102 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:56:51.971284 [debug] [MainThread]: Connection 'model.quant_features.stg_ohlc_data' was properly closed.
[0m17:56:51.971430 [debug] [MainThread]: Connection 'model.quant_features.alpha_base_data' was properly closed.
[0m17:56:51.971566 [debug] [MainThread]: Connection 'model.quant_features.mart_technical_indicators' was properly closed.
[0m17:56:51.971702 [debug] [MainThread]: Connection 'model.quant_features.features_ohlc_technical' was properly closed.
[0m17:56:51.971919 [info ] [MainThread]: 
[0m17:56:51.972121 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 0.35 seconds (0.35s).
[0m17:56:51.972707 [debug] [MainThread]: Command end result
[0m17:56:51.995910 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:56:51.997161 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:56:52.001288 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m17:56:52.001543 [info ] [MainThread]: 
[0m17:56:52.001755 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:56:52.001946 [info ] [MainThread]: 
[0m17:56:52.002146 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m17:56:52.002788 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 0.81580544, "process_in_blocks": "0", "process_kernel_time": 0.181663, "process_mem_max_rss": "167944", "process_out_blocks": "3672", "process_user_time": 1.520427}
[0m17:56:52.003136 [debug] [MainThread]: Command `dbt run` succeeded at 17:56:52.003072 after 0.82 seconds
[0m17:56:52.003365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70457050f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7049905400>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7046535370>]}
[0m17:56:52.003575 [debug] [MainThread]: Flushing usage events
[0m17:57:02.844694 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:57:33.845917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4152af770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe416905a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4140e3d90>]}


============================== 17:57:33.848285 | 8becb8f6-16e3-444c-ba51-5aede42e27af ==============================
[0m17:57:33.848285 [info ] [MainThread]: Running with dbt=1.10.9
[0m17:57:33.848618 [debug] [MainThread]: running dbt with arguments {'invocation_command': 'dbt run --vars {start_date: "2024-01-01", end_date: "2024-01-02"} --exclude alpha_factors_001_020 alpha_factors_021_050 alpha_factors_051_075 alpha_factors_076_101 alpha_factors_advanced alpha_factors_final alpha101_complete', 'quiet': 'False', 'version_check': 'True', 'partial_parse': 'True', 'printer_width': '80', 'fail_fast': 'False', 'send_anonymous_usage_stats': 'True', 'no_print': 'None', 'indirect_selection': 'eager', 'use_colors': 'True', 'static_parser': 'True', 'debug': 'False', 'target_path': 'None', 'write_json': 'True', 'introspect': 'True', 'log_path': '/workspace/dbt_project/logs', 'use_experimental_parser': 'False', 'log_format': 'default', 'empty': 'False', 'warn_error': 'None', 'profiles_dir': '/workspace/dbt_project', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_cache_events': 'False'}
[0m17:57:33.984370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe414e2e650>]}
[0m17:57:34.025709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4141dacf0>]}
[0m17:57:34.026706 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m17:57:34.055667 [debug] [MainThread]: checksum: bb99d3db909c4f3fdeafba5b560a2410ffcc46315d0d8f46d29d4d1cd16b62d6, vars: {'end_date': '2024-01-02', 'start_date': '2024-01-01'}, profile: , target: , version: 1.10.9
[0m17:57:34.126599 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:57:34.126873 [debug] [MainThread]: previous checksum: bb99d3db909c4f3fdeafba5b560a2410ffcc46315d0d8f46d29d4d1cd16b62d6, current checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23
[0m17:57:34.127077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4141ab550>]}
[0m17:57:35.017837 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values`. Arguments to generic tests
should be nested under the `arguments` property.`
[0m17:57:35.018233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40fd61d60>]}
[0m17:57:35.226043 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40fe59b70>]}
[0m17:57:35.285469 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:57:35.286836 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:57:35.297979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40f387ad0>]}
[0m17:57:35.298293 [info ] [MainThread]: Found 11 models, 37 data tests, 1 source, 565 macros
[0m17:57:35.298500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40f121250>]}
[0m17:57:35.300753 [info ] [MainThread]: 
[0m17:57:35.301063 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:57:35.301258 [info ] [MainThread]: 
[0m17:57:35.301548 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m17:57:35.304906 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m17:57:35.320865 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m17:57:35.321138 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m17:57:35.321324 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:57:35.335286 [debug] [ThreadPool]: SQL status: OK in 0.014 seconds
[0m17:57:35.336221 [debug] [ThreadPool]: On list_quant_features: Close
[0m17:57:35.336916 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m17:57:35.337241 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m17:57:35.341379 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:57:35.341630 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m17:57:35.341823 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:57:35.342619 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:57:35.343457 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:57:35.343665 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m17:57:35.343974 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:57:35.344147 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:57:35.344297 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m17:57:35.344623 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:57:35.345167 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:57:35.345354 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:57:35.345509 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:57:35.345797 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:57:35.346015 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m17:57:35.347988 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m17:57:35.359737 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:57:35.360041 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m17:57:35.360215 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:57:35.361138 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:57:35.361366 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:57:35.361546 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m17:57:35.368920 [debug] [ThreadPool]: SQL status: OK in 0.007 seconds
[0m17:57:35.370110 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m17:57:35.371048 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m17:57:35.371267 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m17:57:35.373005 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40e6e4260>]}
[0m17:57:35.373396 [debug] [MainThread]: Using duckdb connection "master"
[0m17:57:35.373579 [debug] [MainThread]: On master: BEGIN
[0m17:57:35.373737 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:57:35.374230 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:57:35.374451 [debug] [MainThread]: On master: COMMIT
[0m17:57:35.374621 [debug] [MainThread]: Using duckdb connection "master"
[0m17:57:35.374773 [debug] [MainThread]: On master: COMMIT
[0m17:57:35.375031 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:57:35.375202 [debug] [MainThread]: On master: Close
[0m17:57:35.377433 [debug] [Thread-1 (]: Began running node model.quant_features.stg_ohlc_data
[0m17:57:35.377879 [info ] [Thread-1 (]: 1 of 4 START sql view model main.stg_ohlc_data ................................. [RUN]
[0m17:57:35.378214 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.stg_ohlc_data)
[0m17:57:35.378422 [debug] [Thread-1 (]: Began compiling node model.quant_features.stg_ohlc_data
[0m17:57:35.384103 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.stg_ohlc_data"
[0m17:57:35.384588 [debug] [Thread-1 (]: Began executing node model.quant_features.stg_ohlc_data
[0m17:57:35.404968 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.stg_ohlc_data"
[0m17:57:35.405451 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:57:35.405680 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: BEGIN
[0m17:57:35.405862 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:57:35.406321 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:57:35.406534 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:57:35.406742 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

  
  create view "quant_features"."main"."stg_ohlc_data__dbt_tmp" as (
    

with raw_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 数据清洗和验证
        case 
            when open <= 0 or high <= 0 or low <= 0 or close <= 0 then null
            when high < greatest(open, close, low) then null
            when low > least(open, close, high) then null
            else timestamp
        end as valid_timestamp
    from "quant_features"."raw"."ohlc_data"
),

cleaned_ohlc as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算基础指标
        (high + low + close) / 3 as typical_price,
        (high - low) as daily_range,
        case when open != 0 then (close - open) / open else 0 end as daily_return,
        case when close != 0 then volume / close else 0 end as volume_price_ratio
    from raw_ohlc
    where valid_timestamp is not null
      and timestamp >= '2024-01-01'
      and timestamp <= '2024-01-02'
)

select * from cleaned_ohlc
  );

[0m17:57:35.407665 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m17:57:35.411912 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:57:35.412190 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */
alter view "quant_features"."main"."stg_ohlc_data" rename to "stg_ohlc_data__dbt_backup"
[0m17:57:35.412723 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:57:35.414469 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:57:35.414718 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */
alter view "quant_features"."main"."stg_ohlc_data__dbt_tmp" rename to "stg_ohlc_data"
[0m17:57:35.415171 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:57:35.422646 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m17:57:35.422936 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:57:35.423150 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: COMMIT
[0m17:57:35.425963 [debug] [Thread-1 (]: SQL status: OK in 0.003 seconds
[0m17:57:35.429732 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.stg_ohlc_data"
[0m17:57:35.430021 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.stg_ohlc_data"} */

      drop view if exists "quant_features"."main"."stg_ohlc_data__dbt_backup" cascade
    
[0m17:57:35.432603 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m17:57:35.434237 [debug] [Thread-1 (]: On model.quant_features.stg_ohlc_data: Close
[0m17:57:35.435488 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe414de2d50>]}
[0m17:57:35.435928 [info ] [Thread-1 (]: 1 of 4 OK created sql view model main.stg_ohlc_data ............................ [[32mOK[0m in 0.06s]
[0m17:57:35.436292 [debug] [Thread-1 (]: Finished running node model.quant_features.stg_ohlc_data
[0m17:57:35.437140 [debug] [Thread-3 (]: Began running node model.quant_features.mart_technical_indicators
[0m17:57:35.437424 [info ] [Thread-3 (]: 3 of 4 START sql table model main.mart_technical_indicators .................... [RUN]
[0m17:57:35.437740 [debug] [Thread-3 (]: Acquiring new duckdb connection 'model.quant_features.mart_technical_indicators'
[0m17:57:35.437971 [debug] [Thread-3 (]: Began compiling node model.quant_features.mart_technical_indicators
[0m17:57:35.440025 [debug] [Thread-3 (]: Writing injected SQL for node "model.quant_features.mart_technical_indicators"
[0m17:57:35.440577 [debug] [Thread-2 (]: Began running node model.quant_features.alpha_base_data
[0m17:57:35.441012 [info ] [Thread-2 (]: 2 of 4 START sql table model main.alpha_base_data .............................. [RUN]
[0m17:57:35.441843 [debug] [Thread-2 (]: Acquiring new duckdb connection 'model.quant_features.alpha_base_data'
[0m17:57:35.442202 [debug] [Thread-3 (]: Began executing node model.quant_features.mart_technical_indicators
[0m17:57:35.442547 [debug] [Thread-2 (]: Began compiling node model.quant_features.alpha_base_data
[0m17:57:35.463069 [debug] [Thread-2 (]: Writing injected SQL for node "model.quant_features.alpha_base_data"
[0m17:57:35.467002 [debug] [Thread-3 (]: Writing runtime sql for node "model.quant_features.mart_technical_indicators"
[0m17:57:35.468005 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:57:35.468319 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: BEGIN
[0m17:57:35.468628 [debug] [Thread-2 (]: Began executing node model.quant_features.alpha_base_data
[0m17:57:35.468926 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m17:57:35.471051 [debug] [Thread-2 (]: Writing runtime sql for node "model.quant_features.alpha_base_data"
[0m17:57:35.471975 [debug] [Thread-3 (]: SQL status: OK in 0.003 seconds
[0m17:57:35.472309 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:57:35.472650 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */

  
    
    

    create  table
      "quant_features"."main"."mart_technical_indicators__dbt_tmp"
  
    as (
      

with base_data as (
    select * from "quant_features"."main"."stg_ohlc_data"
),

technical_indicators as (
    select 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        typical_price,
        daily_range,
        daily_return,
        volume_price_ratio,
        
        -- 移动平均线
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 4 preceding and current row
        ) as ma_5,
        
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 9 preceding and current row
        ) as ma_10,
        
        avg(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as ma_20,
        
        -- 波动率 (标准差)
        stddev(daily_return) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as volatility_20d,
        
        -- RSI相关计算
        case when daily_return > 0 then daily_return else 0 end as gain,
        case when daily_return < 0 then abs(daily_return) else 0 end as loss,
        
        -- 价格位置指标
        (close - min(low) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        )) / nullif((max(high) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) - min(low) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        )), 0) as stoch_k_14,
        
        -- 成交量指标
        avg(volume) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        ) as avg_volume_20d
        
    from base_data
),

rsi_calculation as (
    select *,
        -- RSI计算
        avg(gain) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) as avg_gain_14,
        
        avg(loss) over (
            partition by symbol 
            order by timestamp 
            rows between 13 preceding and current row
        ) as avg_loss_14
    from technical_indicators
),

final_indicators as (
    select *,
        case 
            when avg_loss_14 = 0 then 100
            when avg_gain_14 = 0 then 0
            else 100 - (100 / (1 + (avg_gain_14 / avg_loss_14)))
        end as rsi_14,
        
        -- 布林带
        ma_20 + (2 * stddev(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        )) as bollinger_upper,
        
        ma_20 - (2 * stddev(close) over (
            partition by symbol 
            order by timestamp 
            rows between 19 preceding and current row
        )) as bollinger_lower,
        
        -- 价格动量
        case when lag(close, 5) over (partition by symbol order by timestamp) != 0 
            then (close - lag(close, 5) over (partition by symbol order by timestamp)) / 
                 lag(close, 5) over (partition by symbol order by timestamp)
            else 0 
        end as momentum_5d,
        
        case when lag(close, 10) over (partition by symbol order by timestamp) != 0 
            then (close - lag(close, 10) over (partition by symbol order by timestamp)) / 
                 lag(close, 10) over (partition by symbol order by timestamp)
            else 0 
        end as momentum_10d
        
    from rsi_calculation
)

select * from final_indicators
    );
  
  
[0m17:57:35.473084 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:57:35.473611 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: BEGIN
[0m17:57:35.473802 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m17:57:35.474245 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m17:57:35.474458 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:57:35.474893 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

  
    
    

    create  table
      "quant_features"."main"."alpha_base_data__dbt_tmp"
  
    as (
      

-- Alpha 101 基础数据准备
-- 为Alpha因子计算准备所有必要的基础数据

WITH base_ohlc AS (
    SELECT 
        symbol,
        timestamp,
        open,
        high,
        low,
        close,
        volume,
        -- 计算VWAP (简化版本，假设等权重)
        (high + low + close) / 3 AS vwap,
        -- 计算returns
        CASE 
            WHEN LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp) IS NOT NULL
            THEN (close - LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)) / 
                 LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp)
            ELSE 0
        END AS returns
    FROM "quant_features"."main"."stg_ohlc_data"
    WHERE timestamp >= '2024-01-01'
      AND timestamp <= '2024-01-02'
),

enhanced_data AS (
    SELECT 
        *,
        -- 计算ADV (Average Daily Volume)
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )

 AS adv20,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )

 AS adv10,
        
    
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )

 AS adv5,
        
        -- 预计算一些常用的时间序列指标
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_ma5,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ma10,
        
    AVG(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_ma20,
        
    AVG(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_ma20,
        
        -- 预计算滚动标准差
        
    STDDEV(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_std20,
        
    STDDEV(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS returns_std20,
        
        -- 预计算一些延迟项
        
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag1,
        
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag2,
        
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag5,
        
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag10,
        
    LAG(close, 20) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS close_lag20,
        
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS volume_lag1,
        
    LAG(high, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS high_lag1,
        
    LAG(low, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS low_lag1,
        
    LAG(vwap, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )
 AS vwap_lag5,
        
        -- 预计算一些差值项
        
    close - 
    LAG(close, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta1,
        
    close - 
    LAG(close, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta2,
        
    close - 
    LAG(close, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta3,
        
    close - 
    LAG(close, 5) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta5,
        
    close - 
    LAG(close, 7) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta7,
        
    close - 
    LAG(close, 10) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS close_delta10,
        
    volume - 
    LAG(volume, 1) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta1,
        
    volume - 
    LAG(volume, 3) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS volume_delta3,
        
    high - 
    LAG(high, 2) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
    )

 AS high_delta2,
        
        -- 预计算一些排序项
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY close
    )
 AS close_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY volume
    )
 AS volume_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY high
    )
 AS high_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY low
    )
 AS low_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY vwap
    )
 AS vwap_rank,
        
    PERCENT_RANK() OVER (
        PARTITION BY timestamp
        ORDER BY returns
    )
 AS returns_rank,
        
        -- 预计算时间序列排序
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY close
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS close_ts_rank10,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY volume
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_ts_rank5,
        
    PERCENT_RANK() OVER (
        PARTITION BY symbol
        ORDER BY high
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_ts_rank5,
        
        -- 预计算一些最值项
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_min100,
        
    MAX(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS close_max3,
        
    MIN(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_min5,
        
    MAX(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_max5,
        
    MIN(low) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS low_min5,
        
    MAX(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 2 PRECEDING AND CURRENT ROW
    )
 AS high_max3,
        
        -- 预计算一些求和项
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS close_sum5,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 7 PRECEDING AND CURRENT ROW
    )
 AS close_sum8,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS close_sum20,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 99 PRECEDING AND CURRENT ROW
    )
 AS close_sum100,
        
    SUM(close) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 199 PRECEDING AND CURRENT ROW
    )
 AS close_sum200,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS volume_sum5,
        
    SUM(volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS volume_sum20,
        
    SUM(returns) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 249 PRECEDING AND CURRENT ROW
    )
 AS returns_sum250,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS high_sum5,
        
    SUM(high) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
    )
 AS high_sum20,
        
        -- 预计算一些相关性
        
    -- 使用DuckDB的CORR窗口函数
    CORR(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_close_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(open, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
    )
 AS corr_open_volume_10,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS corr_high_volume_5,
        
    -- 使用DuckDB的CORR窗口函数
    CORR(vwap, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 5 PRECEDING AND CURRENT ROW
    )
 AS corr_vwap_volume_6,
        
        -- 预计算一些协方差
        
    COVAR_SAMP(close, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_close_volume_5,
        
    COVAR_SAMP(high, volume) OVER (
        PARTITION BY symbol 
        ORDER BY timestamp
        ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
    )
 AS cov_high_volume_5
        
    FROM base_ohlc
    WHERE timestamp >= CAST('2024-01-01' AS DATE) - INTERVAL '250 days'  -- 扩展时间范围以确保有足够的历史数据
),

-- 过滤回原始时间范围
final_data AS (
    SELECT *
    FROM enhanced_data
    WHERE timestamp >= '2024-01-01'
      AND timestamp <= '2024-01-02'
)

SELECT * FROM final_data
    );
  
  
[0m17:57:35.483912 [debug] [Thread-3 (]: SQL status: OK in 0.010 seconds
[0m17:57:35.486305 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:57:35.486596 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */
alter table "quant_features"."main"."mart_technical_indicators" rename to "mart_technical_indicators__dbt_backup"
[0m17:57:35.487196 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m17:57:35.489640 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:57:35.489937 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */
alter table "quant_features"."main"."mart_technical_indicators__dbt_tmp" rename to "mart_technical_indicators"
[0m17:57:35.490441 [debug] [Thread-3 (]: SQL status: OK in 0.000 seconds
[0m17:57:35.494537 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: COMMIT
[0m17:57:35.494907 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:57:35.495209 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: COMMIT
[0m17:57:35.497735 [debug] [Thread-3 (]: SQL status: OK in 0.002 seconds
[0m17:57:35.499572 [debug] [Thread-3 (]: Using duckdb connection "model.quant_features.mart_technical_indicators"
[0m17:57:35.499822 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.mart_technical_indicators"} */

      drop table if exists "quant_features"."main"."mart_technical_indicators__dbt_backup" cascade
    
[0m17:57:35.501053 [debug] [Thread-2 (]: SQL status: OK in 0.026 seconds
[0m17:57:35.501395 [debug] [Thread-3 (]: SQL status: OK in 0.001 seconds
[0m17:57:35.504013 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:57:35.505213 [debug] [Thread-3 (]: On model.quant_features.mart_technical_indicators: Close
[0m17:57:35.505695 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */
alter table "quant_features"."main"."alpha_base_data" rename to "alpha_base_data__dbt_backup"
[0m17:57:35.506996 [debug] [Thread-2 (]: SQL status: OK in 0.000 seconds
[0m17:57:35.507458 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40e52ea50>]}
[0m17:57:35.509421 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:57:35.509910 [info ] [Thread-3 (]: 3 of 4 OK created sql table model main.mart_technical_indicators ............... [[32mOK[0m in 0.07s]
[0m17:57:35.510424 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */
alter table "quant_features"."main"."alpha_base_data__dbt_tmp" rename to "alpha_base_data"
[0m17:57:35.511061 [debug] [Thread-3 (]: Finished running node model.quant_features.mart_technical_indicators
[0m17:57:35.512420 [debug] [Thread-2 (]: SQL status: OK in 0.001 seconds
[0m17:57:35.513516 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: COMMIT
[0m17:57:35.513889 [debug] [Thread-4 (]: Began running node model.quant_features.features_ohlc_technical
[0m17:57:35.514424 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:57:35.514997 [info ] [Thread-4 (]: 4 of 4 START sql table model main.features_ohlc_technical ...................... [RUN]
[0m17:57:35.515518 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: COMMIT
[0m17:57:35.515997 [debug] [Thread-4 (]: Acquiring new duckdb connection 'model.quant_features.features_ohlc_technical'
[0m17:57:35.516415 [debug] [Thread-4 (]: Began compiling node model.quant_features.features_ohlc_technical
[0m17:57:35.518795 [debug] [Thread-4 (]: Writing injected SQL for node "model.quant_features.features_ohlc_technical"
[0m17:57:35.519200 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m17:57:35.520942 [debug] [Thread-2 (]: Using duckdb connection "model.quant_features.alpha_base_data"
[0m17:57:35.521207 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.alpha_base_data"} */

      drop table if exists "quant_features"."main"."alpha_base_data__dbt_backup" cascade
    
[0m17:57:35.521784 [debug] [Thread-4 (]: Began executing node model.quant_features.features_ohlc_technical
[0m17:57:35.523646 [debug] [Thread-4 (]: Writing runtime sql for node "model.quant_features.features_ohlc_technical"
[0m17:57:35.524041 [debug] [Thread-2 (]: SQL status: OK in 0.003 seconds
[0m17:57:35.525073 [debug] [Thread-2 (]: On model.quant_features.alpha_base_data: Close
[0m17:57:35.525364 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:57:35.525720 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: BEGIN
[0m17:57:35.526248 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40e45e190>]}
[0m17:57:35.526572 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m17:57:35.527270 [info ] [Thread-2 (]: 2 of 4 OK created sql table model main.alpha_base_data ......................... [[32mOK[0m in 0.08s]
[0m17:57:35.527981 [debug] [Thread-4 (]: SQL status: OK in 0.001 seconds
[0m17:57:35.528872 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:57:35.528583 [debug] [Thread-2 (]: Finished running node model.quant_features.alpha_base_data
[0m17:57:35.529175 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

  
    
    

    create  table
      "quant_features"."main"."features_ohlc_technical__dbt_tmp"
  
    as (
      

with technical_data as (
    select * from "quant_features"."main"."mart_technical_indicators"
),

feature_engineering as (
    select 
        symbol,
        timestamp,
        
        -- 基础价格特征
        close as price,
        daily_return,
        volatility_20d,
        
        -- 趋势特征
        ma_5,
        ma_10,
        ma_20,
        case when close > ma_5 then 1 else 0 end as price_above_ma5,
        case when close > ma_10 then 1 else 0 end as price_above_ma10,
        case when close > ma_20 then 1 else 0 end as price_above_ma20,
        case when ma_5 > ma_10 then 1 else 0 end as ma5_above_ma10,
        case when ma_10 > ma_20 then 1 else 0 end as ma10_above_ma20,
        
        -- 技术指标特征
        rsi_14,
        case when rsi_14 > 70 then 1 else 0 end as rsi_overbought,
        case when rsi_14 < 30 then 1 else 0 end as rsi_oversold,
        
        stoch_k_14,
        case when stoch_k_14 > 0.8 then 1 else 0 end as stoch_overbought,
        case when stoch_k_14 < 0.2 then 1 else 0 end as stoch_oversold,
        
        -- 布林带特征
        bollinger_upper,
        bollinger_lower,
        case when close > bollinger_upper then 1 else 0 end as price_above_bb_upper,
        case when close < bollinger_lower then 1 else 0 end as price_below_bb_lower,
        case 
            when bollinger_upper - bollinger_lower != 0 
            then (close - bollinger_lower) / (bollinger_upper - bollinger_lower)
            else 0.5
        end as bb_position,
        
        -- 动量特征
        momentum_5d,
        momentum_10d,
        case when momentum_5d > 0 then 1 else 0 end as momentum_5d_positive,
        case when momentum_10d > 0 then 1 else 0 end as momentum_10d_positive,
        
        -- 成交量特征
        volume,
        avg_volume_20d,
        case when avg_volume_20d != 0 then volume / avg_volume_20d else 0 end as volume_ratio,
        case when volume > avg_volume_20d * 1.5 then 1 else 0 end as high_volume,
        
        -- 价格范围特征
        daily_range,
        case when lag(close) over (partition by symbol order by timestamp) != 0 
            then daily_range / lag(close) over (partition by symbol order by timestamp)
            else 0
        end as range_ratio,
        
        -- 组合特征
        case when rsi_14 > 70 and stoch_k_14 > 0.8 then 1 else 0 end as double_overbought,
        case when rsi_14 < 30 and stoch_k_14 < 0.2 then 1 else 0 end as double_oversold,
        
        -- 时间特征
        extract(hour from timestamp) as hour,
        extract(dow from timestamp) as day_of_week,
        extract(month from timestamp) as month,
        
        -- 标识特征用于Feast
        concat(symbol, '_', date_trunc('day', timestamp)::string) as entity_id,
        timestamp as event_timestamp
        
    from technical_data
    where timestamp >= current_date - interval '20' days
)

select * from feature_engineering
    );
  
  
[0m17:57:35.532607 [debug] [Thread-4 (]: SQL status: OK in 0.003 seconds
[0m17:57:35.537524 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:57:35.537793 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */
alter table "quant_features"."main"."features_ohlc_technical" rename to "features_ohlc_technical__dbt_backup"
[0m17:57:35.538296 [debug] [Thread-4 (]: SQL status: OK in 0.000 seconds
[0m17:57:35.540008 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:57:35.540256 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */
alter table "quant_features"."main"."features_ohlc_technical__dbt_tmp" rename to "features_ohlc_technical"
[0m17:57:35.540708 [debug] [Thread-4 (]: SQL status: OK in 0.000 seconds
[0m17:57:35.541590 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m17:57:35.541825 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:57:35.542050 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m17:57:35.544265 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m17:57:35.545937 [debug] [Thread-4 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:57:35.546206 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

      drop table if exists "quant_features"."main"."features_ohlc_technical__dbt_backup" cascade
    
[0m17:57:35.548602 [debug] [Thread-4 (]: SQL status: OK in 0.002 seconds
[0m17:57:35.549496 [debug] [Thread-4 (]: On model.quant_features.features_ohlc_technical: Close
[0m17:57:35.550484 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8becb8f6-16e3-444c-ba51-5aede42e27af', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40e58ebd0>]}
[0m17:57:35.550889 [info ] [Thread-4 (]: 4 of 4 OK created sql table model main.features_ohlc_technical ................. [[32mOK[0m in 0.03s]
[0m17:57:35.551223 [debug] [Thread-4 (]: Finished running node model.quant_features.features_ohlc_technical
[0m17:57:35.553204 [debug] [MainThread]: Using duckdb connection "master"
[0m17:57:35.553447 [debug] [MainThread]: On master: BEGIN
[0m17:57:35.553607 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:57:35.553995 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:57:35.554179 [debug] [MainThread]: On master: COMMIT
[0m17:57:35.554328 [debug] [MainThread]: Using duckdb connection "master"
[0m17:57:35.554466 [debug] [MainThread]: On master: COMMIT
[0m17:57:35.554722 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:57:35.554897 [debug] [MainThread]: On master: Close
[0m17:57:35.555178 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:57:35.555337 [debug] [MainThread]: Connection 'model.quant_features.stg_ohlc_data' was properly closed.
[0m17:57:35.555469 [debug] [MainThread]: Connection 'model.quant_features.mart_technical_indicators' was properly closed.
[0m17:57:35.555598 [debug] [MainThread]: Connection 'model.quant_features.alpha_base_data' was properly closed.
[0m17:57:35.555722 [debug] [MainThread]: Connection 'model.quant_features.features_ohlc_technical' was properly closed.
[0m17:57:35.555930 [info ] [MainThread]: 
[0m17:57:35.556144 [info ] [MainThread]: Finished running 3 table models, 1 view model in 0 hours 0 minutes and 0.25 seconds (0.25s).
[0m17:57:35.556704 [debug] [MainThread]: Command end result
[0m17:57:35.575531 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:57:35.576698 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:57:35.580463 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m17:57:35.580689 [info ] [MainThread]: 
[0m17:57:35.580900 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:57:35.581089 [info ] [MainThread]: 
[0m17:57:35.581274 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m17:57:35.581604 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 12 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m17:57:35.582265 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.7728544, "process_in_blocks": "0", "process_kernel_time": 0.194374, "process_mem_max_rss": "177180", "process_out_blocks": "5064", "process_user_time": 2.507}
[0m17:57:35.582595 [debug] [MainThread]: Command `dbt run` succeeded at 17:57:35.582532 after 1.77 seconds
[0m17:57:35.582856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe4153cf890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40f1f3d70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe40fcb6630>]}
[0m17:57:35.583085 [debug] [MainThread]: Flushing usage events
[0m17:57:35.898010 [debug] [MainThread]: An error was encountered while trying to flush usage events
[0m17:58:15.967111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63760db770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6377725a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6374f4bd90>]}


============================== 17:58:15.969547 | 517fe6b5-c639-4ba3-8d3c-8eaf83bf4a82 ==============================
[0m17:58:15.969547 [info ] [MainThread]: Running with dbt=1.10.9
[0m17:58:15.969879 [debug] [MainThread]: running dbt with arguments {'version_check': 'True', 'fail_fast': 'False', 'quiet': 'False', 'printer_width': '80', 'log_path': '/workspace/dbt_project/logs', 'partial_parse': 'True', 'empty': 'False', 'use_colors': 'True', 'debug': 'False', 'indirect_selection': 'eager', 'cache_selected_only': 'False', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'log_format': 'default', 'send_anonymous_usage_stats': 'True', 'write_json': 'True', 'profiles_dir': '/workspace/dbt_project', 'warn_error': 'None', 'log_cache_events': 'False', 'static_parser': 'True', 'introspect': 'True', 'use_experimental_parser': 'False', 'invocation_command': 'dbt run --select features_ohlc_technical', 'target_path': 'None', 'no_print': 'None'}
[0m17:58:16.105089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '517fe6b5-c639-4ba3-8d3c-8eaf83bf4a82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6375c66650>]}
[0m17:58:16.146162 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '517fe6b5-c639-4ba3-8d3c-8eaf83bf4a82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6375042be0>]}
[0m17:58:16.147169 [info ] [MainThread]: Registered adapter: duckdb=1.9.4
[0m17:58:16.176215 [debug] [MainThread]: checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, vars: {}, profile: , target: , version: 1.10.9
[0m17:58:16.246203 [info ] [MainThread]: Unable to do partial parsing because config vars, config profile, or config target have changed
[0m17:58:16.246477 [debug] [MainThread]: previous checksum: 6543b8b248ceda473ef0d611849d5d909085b6b714afa9b515e9635faea7af23, current checksum: bb99d3db909c4f3fdeafba5b560a2410ffcc46315d0d8f46d29d4d1cd16b62d6
[0m17:58:16.246672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '517fe6b5-c639-4ba3-8d3c-8eaf83bf4a82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f637185f550>]}
[0m17:58:17.116788 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values`. Arguments to generic tests
should be nested under the `arguments` property.`
[0m17:58:17.117113 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '517fe6b5-c639-4ba3-8d3c-8eaf83bf4a82', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6370c85d60>]}
[0m17:58:17.316917 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '517fe6b5-c639-4ba3-8d3c-8eaf83bf4a82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6370d45b70>]}
[0m17:58:17.375750 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:58:17.376962 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:58:17.388498 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '517fe6b5-c639-4ba3-8d3c-8eaf83bf4a82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63702abad0>]}
[0m17:58:17.388833 [info ] [MainThread]: Found 11 models, 37 data tests, 1 source, 565 macros
[0m17:58:17.389059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '517fe6b5-c639-4ba3-8d3c-8eaf83bf4a82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6363f45250>]}
[0m17:58:17.390270 [info ] [MainThread]: 
[0m17:58:17.390540 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m17:58:17.390743 [info ] [MainThread]: 
[0m17:58:17.391078 [debug] [MainThread]: Acquiring new duckdb connection 'master'
[0m17:58:17.391986 [debug] [ThreadPool]: Acquiring new duckdb connection 'list_quant_features'
[0m17:58:17.407157 [debug] [ThreadPool]: Using duckdb connection "list_quant_features"
[0m17:58:17.407416 [debug] [ThreadPool]: On list_quant_features: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features"} */

    
    select schema_name
    from system.information_schema.schemata
    
    where lower(catalog_name) = '"quant_features"'
    
  
  
[0m17:58:17.407622 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:58:17.419567 [debug] [ThreadPool]: SQL status: OK in 0.012 seconds
[0m17:58:17.420465 [debug] [ThreadPool]: On list_quant_features: Close
[0m17:58:17.421135 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_quant_features, now create_quant_features_main)
[0m17:58:17.421425 [debug] [ThreadPool]: Creating schema "database: "quant_features"
schema: "main"
"
[0m17:58:17.425548 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:58:17.425795 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
        select type from duckdb_databases()
        where lower(database_name)='quant_features'
        and type='sqlite'
    
  
[0m17:58:17.426005 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:58:17.426738 [debug] [ThreadPool]: SQL status: OK in 0.001 seconds
[0m17:58:17.427580 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:58:17.427779 [debug] [ThreadPool]: On create_quant_features_main: BEGIN
[0m17:58:17.428095 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:58:17.428266 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:58:17.428418 [debug] [ThreadPool]: On create_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "create_quant_features_main"} */

    
    
        create schema if not exists "quant_features"."main"
    
[0m17:58:17.428951 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:58:17.429488 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:58:17.429687 [debug] [ThreadPool]: Using duckdb connection "create_quant_features_main"
[0m17:58:17.429861 [debug] [ThreadPool]: On create_quant_features_main: COMMIT
[0m17:58:17.430178 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:58:17.430387 [debug] [ThreadPool]: On create_quant_features_main: Close
[0m17:58:17.434698 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create_quant_features_main, now list_quant_features_main)
[0m17:58:17.438405 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:58:17.438650 [debug] [ThreadPool]: On list_quant_features_main: BEGIN
[0m17:58:17.438809 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m17:58:17.439195 [debug] [ThreadPool]: SQL status: OK in 0.000 seconds
[0m17:58:17.439382 [debug] [ThreadPool]: Using duckdb connection "list_quant_features_main"
[0m17:58:17.439535 [debug] [ThreadPool]: On list_quant_features_main: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "connection_name": "list_quant_features_main"} */
select
      'quant_features' as database,
      table_name as name,
      table_schema as schema,
      CASE table_type
        WHEN 'BASE TABLE' THEN 'table'
        WHEN 'VIEW' THEN 'view'
        WHEN 'LOCAL TEMPORARY' THEN 'table'
        END as type
    from system.information_schema.tables
    where lower(table_schema) = 'main'
    and lower(table_catalog) = 'quant_features'
  
[0m17:58:17.446176 [debug] [ThreadPool]: SQL status: OK in 0.006 seconds
[0m17:58:17.447073 [debug] [ThreadPool]: On list_quant_features_main: ROLLBACK
[0m17:58:17.447717 [debug] [ThreadPool]: Failed to rollback 'list_quant_features_main'
[0m17:58:17.447944 [debug] [ThreadPool]: On list_quant_features_main: Close
[0m17:58:17.449477 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '517fe6b5-c639-4ba3-8d3c-8eaf83bf4a82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f63633b41b0>]}
[0m17:58:17.449922 [debug] [MainThread]: Using duckdb connection "master"
[0m17:58:17.450122 [debug] [MainThread]: On master: BEGIN
[0m17:58:17.450276 [debug] [MainThread]: Opening a new connection, currently in state init
[0m17:58:17.450652 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:58:17.450872 [debug] [MainThread]: On master: COMMIT
[0m17:58:17.451043 [debug] [MainThread]: Using duckdb connection "master"
[0m17:58:17.451197 [debug] [MainThread]: On master: COMMIT
[0m17:58:17.451482 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:58:17.451665 [debug] [MainThread]: On master: Close
[0m17:58:17.453886 [debug] [Thread-1 (]: Began running node model.quant_features.features_ohlc_technical
[0m17:58:17.454298 [info ] [Thread-1 (]: 1 of 1 START sql table model main.features_ohlc_technical ...................... [RUN]
[0m17:58:17.454595 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list_quant_features_main, now model.quant_features.features_ohlc_technical)
[0m17:58:17.454812 [debug] [Thread-1 (]: Began compiling node model.quant_features.features_ohlc_technical
[0m17:58:17.459750 [debug] [Thread-1 (]: Writing injected SQL for node "model.quant_features.features_ohlc_technical"
[0m17:58:17.460210 [debug] [Thread-1 (]: Began executing node model.quant_features.features_ohlc_technical
[0m17:58:17.480646 [debug] [Thread-1 (]: Writing runtime sql for node "model.quant_features.features_ohlc_technical"
[0m17:58:17.481169 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:58:17.481407 [debug] [Thread-1 (]: On model.quant_features.features_ohlc_technical: BEGIN
[0m17:58:17.481596 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m17:58:17.482043 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:58:17.482277 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:58:17.482546 [debug] [Thread-1 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

  
    
    

    create  table
      "quant_features"."main"."features_ohlc_technical__dbt_tmp"
  
    as (
      

with technical_data as (
    select * from "quant_features"."main"."mart_technical_indicators"
),

feature_engineering as (
    select 
        symbol,
        timestamp,
        
        -- 基础价格特征
        close as price,
        daily_return,
        volatility_20d,
        
        -- 趋势特征
        ma_5,
        ma_10,
        ma_20,
        case when close > ma_5 then 1 else 0 end as price_above_ma5,
        case when close > ma_10 then 1 else 0 end as price_above_ma10,
        case when close > ma_20 then 1 else 0 end as price_above_ma20,
        case when ma_5 > ma_10 then 1 else 0 end as ma5_above_ma10,
        case when ma_10 > ma_20 then 1 else 0 end as ma10_above_ma20,
        
        -- 技术指标特征
        rsi_14,
        case when rsi_14 > 70 then 1 else 0 end as rsi_overbought,
        case when rsi_14 < 30 then 1 else 0 end as rsi_oversold,
        
        stoch_k_14,
        case when stoch_k_14 > 0.8 then 1 else 0 end as stoch_overbought,
        case when stoch_k_14 < 0.2 then 1 else 0 end as stoch_oversold,
        
        -- 布林带特征
        bollinger_upper,
        bollinger_lower,
        case when close > bollinger_upper then 1 else 0 end as price_above_bb_upper,
        case when close < bollinger_lower then 1 else 0 end as price_below_bb_lower,
        case 
            when bollinger_upper - bollinger_lower != 0 
            then (close - bollinger_lower) / (bollinger_upper - bollinger_lower)
            else 0.5
        end as bb_position,
        
        -- 动量特征
        momentum_5d,
        momentum_10d,
        case when momentum_5d > 0 then 1 else 0 end as momentum_5d_positive,
        case when momentum_10d > 0 then 1 else 0 end as momentum_10d_positive,
        
        -- 成交量特征
        volume,
        avg_volume_20d,
        case when avg_volume_20d != 0 then volume / avg_volume_20d else 0 end as volume_ratio,
        case when volume > avg_volume_20d * 1.5 then 1 else 0 end as high_volume,
        
        -- 价格范围特征
        daily_range,
        case when lag(close) over (partition by symbol order by timestamp) != 0 
            then daily_range / lag(close) over (partition by symbol order by timestamp)
            else 0
        end as range_ratio,
        
        -- 组合特征
        case when rsi_14 > 70 and stoch_k_14 > 0.8 then 1 else 0 end as double_overbought,
        case when rsi_14 < 30 and stoch_k_14 < 0.2 then 1 else 0 end as double_oversold,
        
        -- 时间特征
        extract(hour from timestamp) as hour,
        extract(dow from timestamp) as day_of_week,
        extract(month from timestamp) as month,
        
        -- 标识特征用于Feast
        concat(symbol, '_', date_trunc('day', timestamp)::string) as entity_id,
        timestamp as event_timestamp
        
    from technical_data
    -- 移除时间过滤，使用所有可用数据
    -- where timestamp >= current_date - interval '20' days
)

select * from feature_engineering
    );
  
  
[0m17:58:17.487417 [debug] [Thread-1 (]: SQL status: OK in 0.005 seconds
[0m17:58:17.491563 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:58:17.491835 [debug] [Thread-1 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */
alter table "quant_features"."main"."features_ohlc_technical" rename to "features_ohlc_technical__dbt_backup"
[0m17:58:17.492370 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:58:17.494152 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:58:17.494404 [debug] [Thread-1 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */
alter table "quant_features"."main"."features_ohlc_technical__dbt_tmp" rename to "features_ohlc_technical"
[0m17:58:17.494864 [debug] [Thread-1 (]: SQL status: OK in 0.000 seconds
[0m17:58:17.504433 [debug] [Thread-1 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m17:58:17.504711 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:58:17.504922 [debug] [Thread-1 (]: On model.quant_features.features_ohlc_technical: COMMIT
[0m17:58:17.507454 [debug] [Thread-1 (]: SQL status: OK in 0.002 seconds
[0m17:58:17.511200 [debug] [Thread-1 (]: Using duckdb connection "model.quant_features.features_ohlc_technical"
[0m17:58:17.511473 [debug] [Thread-1 (]: On model.quant_features.features_ohlc_technical: /* {"app": "dbt", "dbt_version": "1.10.9", "profile_name": "quant_features", "target_name": "dev", "node_id": "model.quant_features.features_ohlc_technical"} */

      drop table if exists "quant_features"."main"."features_ohlc_technical__dbt_backup" cascade
    
[0m17:58:17.512985 [debug] [Thread-1 (]: SQL status: OK in 0.001 seconds
[0m17:58:17.514532 [debug] [Thread-1 (]: On model.quant_features.features_ohlc_technical: Close
[0m17:58:17.515942 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '517fe6b5-c639-4ba3-8d3c-8eaf83bf4a82', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6375c1ad50>]}
[0m17:58:17.516400 [info ] [Thread-1 (]: 1 of 1 OK created sql table model main.features_ohlc_technical ................. [[32mOK[0m in 0.06s]
[0m17:58:17.516748 [debug] [Thread-1 (]: Finished running node model.quant_features.features_ohlc_technical
[0m17:58:17.518788 [debug] [MainThread]: Using duckdb connection "master"
[0m17:58:17.519045 [debug] [MainThread]: On master: BEGIN
[0m17:58:17.519211 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m17:58:17.519565 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:58:17.519749 [debug] [MainThread]: On master: COMMIT
[0m17:58:17.519923 [debug] [MainThread]: Using duckdb connection "master"
[0m17:58:17.520077 [debug] [MainThread]: On master: COMMIT
[0m17:58:17.520339 [debug] [MainThread]: SQL status: OK in 0.000 seconds
[0m17:58:17.520513 [debug] [MainThread]: On master: Close
[0m17:58:17.520777 [debug] [MainThread]: Connection 'master' was properly closed.
[0m17:58:17.520953 [debug] [MainThread]: Connection 'model.quant_features.features_ohlc_technical' was properly closed.
[0m17:58:17.521122 [info ] [MainThread]: 
[0m17:58:17.521303 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.13 seconds (0.13s).
[0m17:58:17.521679 [debug] [MainThread]: Command end result
[0m17:58:17.541104 [debug] [MainThread]: Wrote artifact WritableManifest to /workspace/dbt_project/target/manifest.json
[0m17:58:17.542312 [debug] [MainThread]: Wrote artifact SemanticManifest to /workspace/dbt_project/target/semantic_manifest.json
[0m17:58:17.545963 [debug] [MainThread]: Wrote artifact RunExecutionResult to /workspace/dbt_project/target/run_results.json
[0m17:58:17.546216 [info ] [MainThread]: 
[0m17:58:17.546441 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:58:17.546615 [info ] [MainThread]: 
[0m17:58:17.546793 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m17:58:17.547109 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 12 occurrences
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m17:58:17.547677 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.6165617, "process_in_blocks": "0", "process_kernel_time": 0.158485, "process_mem_max_rss": "159780", "process_out_blocks": "4792", "process_user_time": 2.337622}
[0m17:58:17.547987 [debug] [MainThread]: Command `dbt run` succeeded at 17:58:17.547923 after 1.62 seconds
[0m17:58:17.548199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6370234d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f637769d650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6374f950f0>]}
[0m17:58:17.548410 [debug] [MainThread]: Flushing usage events
[0m17:58:17.894652 [debug] [MainThread]: An error was encountered while trying to flush usage events
