#!/usr/bin/env python3
"""
ç¦»çº¿ç‰¹å¾è¡ç”Ÿæ¨¡å—å•å…ƒæµ‹è¯•
"""
import pytest
import pandas as pd
import numpy as np
import duckdb
from datetime import datetime, timedelta
import sys
import os

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from scripts.init_duckdb import init_offline_db, create_sample_data

class TestOfflineFeatures:
    """ç¦»çº¿ç‰¹å¾æµ‹è¯•ç±»"""
    
    @classmethod
    def setup_class(cls):
        """æµ‹è¯•ç±»åˆå§‹åŒ–"""
        cls.test_db_path = "/tmp/test_quant_features.duckdb"
        cls.conn = None
        
    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰çš„åˆå§‹åŒ–"""
        # åˆ é™¤æµ‹è¯•æ•°æ®åº“ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if os.path.exists(self.test_db_path):
            os.remove(self.test_db_path)
        
        # åˆå§‹åŒ–æµ‹è¯•æ•°æ®åº“
        init_offline_db(self.test_db_path)
        self.conn = duckdb.connect(self.test_db_path)
        
        # åˆ›å»ºæ›´å¤šæµ‹è¯•æ•°æ®
        self.create_test_data()
    
    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•åçš„æ¸…ç†"""
        if self.conn:
            self.conn.close()
        if os.path.exists(self.test_db_path):
            os.remove(self.test_db_path)
    
    def create_test_data(self):
        """åˆ›å»ºæµ‹è¯•æ•°æ®"""
        # ç”Ÿæˆ30å¤©çš„OHLCæ•°æ®
        dates = pd.date_range(start='2024-01-01', periods=30, freq='1D')
        
        test_data = []
        base_price = 45000
        
        for i, date in enumerate(dates):
            # æ¨¡æ‹Ÿä»·æ ¼èµ°åŠ¿
            price_change = np.random.normal(0, 0.02) * base_price
            base_price = max(base_price + price_change, base_price * 0.9)
            
            open_price = base_price
            high_price = base_price * (1 + abs(np.random.normal(0, 0.01)))
            low_price = base_price * (1 - abs(np.random.normal(0, 0.01)))
            close_price = base_price + np.random.normal(0, 0.005) * base_price
            volume = int(np.random.exponential(1000000))
            
            test_data.append({
                'symbol': 'BTCUSDT',
                'timestamp': date,
                'open': open_price,
                'high': high_price,
                'low': low_price,
                'close': close_price,
                'volume': volume
            })
        
        # æ’å…¥æµ‹è¯•æ•°æ®
        df = pd.DataFrame(test_data)
        self.conn.execute("DELETE FROM raw.ohlc_data")
        self.conn.execute("INSERT INTO raw.ohlc_data SELECT * FROM df")
    
    def test_data_cleaning(self):
        """æµ‹è¯•æ•°æ®æ¸…æ´—"""
        # æ‰§è¡Œæ•°æ®æ¸…æ´—æŸ¥è¯¢
        query = """
        SELECT 
            symbol,
            timestamp,
            open,
            high,
            low,
            close,
            volume,
            -- æ•°æ®éªŒè¯
            CASE 
                WHEN open <= 0 OR high <= 0 OR low <= 0 OR close <= 0 THEN 'INVALID'
                WHEN high < GREATEST(open, close, low) THEN 'INVALID'
                WHEN low > LEAST(open, close, high) THEN 'INVALID'
                ELSE 'VALID'
            END as data_quality
        FROM raw.ohlc_data
        """
        
        result = self.conn.execute(query).df()
        
        # éªŒè¯ç»“æœ
        assert len(result) > 0, "åº”è¯¥æœ‰æ•°æ®è¿”å›"
        assert all(result['data_quality'] == 'VALID'), "æ‰€æœ‰æ•°æ®éƒ½åº”è¯¥æ˜¯æœ‰æ•ˆçš„"
        
        print(f"âœ… æ•°æ®æ¸…æ´—æµ‹è¯•é€šè¿‡ï¼Œå¤„ç†äº† {len(result)} æ¡æ•°æ®")
    
    def test_basic_features(self):
        """æµ‹è¯•åŸºç¡€ç‰¹å¾è®¡ç®—"""
        query = """
        SELECT 
            symbol,
            timestamp,
            close,
            -- åŸºç¡€ç‰¹å¾
            (high + low + close) / 3 as typical_price,
            (high - low) as daily_range,
            CASE WHEN open != 0 THEN (close - open) / open ELSE 0 END as daily_return,
            CASE WHEN close != 0 THEN volume / close ELSE 0 END as volume_price_ratio
        FROM raw.ohlc_data
        ORDER BY timestamp
        """
        
        result = self.conn.execute(query).df()
        
        # éªŒè¯åŸºç¡€ç‰¹å¾
        assert len(result) > 0, "åº”è¯¥æœ‰ç‰¹å¾æ•°æ®"
        assert not result['typical_price'].isna().any(), "typical_priceä¸åº”æœ‰ç©ºå€¼"
        assert not result['daily_range'].isna().any(), "daily_rangeä¸åº”æœ‰ç©ºå€¼"
        assert all(result['daily_range'] >= 0), "daily_rangeåº”è¯¥éè´Ÿ"
        
        print(f"âœ… åŸºç¡€ç‰¹å¾æµ‹è¯•é€šè¿‡ï¼Œè®¡ç®—äº† {len(result)} æ¡è®°å½•")
        print(f"   å¹³å‡æ—¥æ”¶ç›Šç‡: {result['daily_return'].mean():.4f}")
        print(f"   å¹³å‡æ³¢åŠ¨èŒƒå›´: {result['daily_range'].mean():.2f}")
    
    def test_moving_averages(self):
        """æµ‹è¯•ç§»åŠ¨å¹³å‡çº¿"""
        query = """
        SELECT 
            symbol,
            timestamp,
            close,
            -- ç§»åŠ¨å¹³å‡çº¿
            AVG(close) OVER (
                PARTITION BY symbol 
                ORDER BY timestamp 
                ROWS BETWEEN 4 PRECEDING AND CURRENT ROW
            ) as ma_5,
            AVG(close) OVER (
                PARTITION BY symbol 
                ORDER BY timestamp 
                ROWS BETWEEN 9 PRECEDING AND CURRENT ROW
            ) as ma_10,
            AVG(close) OVER (
                PARTITION BY symbol 
                ORDER BY timestamp 
                ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
            ) as ma_20
        FROM raw.ohlc_data
        ORDER BY timestamp
        """
        
        result = self.conn.execute(query).df()
        
        # éªŒè¯ç§»åŠ¨å¹³å‡çº¿
        assert len(result) > 0, "åº”è¯¥æœ‰ç§»åŠ¨å¹³å‡çº¿æ•°æ®"
        
        # æ£€æŸ¥ç§»åŠ¨å¹³å‡çº¿çš„åˆç†æ€§
        for i in range(5, len(result)):
            ma5 = result.iloc[i]['ma_5']
            ma10 = result.iloc[i]['ma_10'] if i >= 10 else None
            close = result.iloc[i]['close']
            
            assert ma5 > 0, "MA5åº”è¯¥ä¸ºæ­£æ•°"
            if ma10 is not None:
                # MA10åº”è¯¥æ¯”MA5æ›´å¹³æ»‘
                pass
        
        print(f"âœ… ç§»åŠ¨å¹³å‡çº¿æµ‹è¯•é€šè¿‡")
        print(f"   æœ€æ–°MA5: {result.iloc[-1]['ma_5']:.2f}")
        print(f"   æœ€æ–°MA10: {result.iloc[-1]['ma_10']:.2f}")
        print(f"   æœ€æ–°MA20: {result.iloc[-1]['ma_20']:.2f}")
    
    def test_rsi_calculation(self):
        """æµ‹è¯•RSIè®¡ç®—"""
        query = """
        WITH price_changes AS (
            SELECT 
                symbol,
                timestamp,
                close,
                close - LAG(close) OVER (PARTITION BY symbol ORDER BY timestamp) as price_change
            FROM raw.ohlc_data
        ),
        gains_losses AS (
            SELECT 
                *,
                CASE WHEN price_change > 0 THEN price_change ELSE 0 END as gain,
                CASE WHEN price_change < 0 THEN ABS(price_change) ELSE 0 END as loss
            FROM price_changes
            WHERE price_change IS NOT NULL
        ),
        rsi_calc AS (
            SELECT 
                *,
                AVG(gain) OVER (
                    PARTITION BY symbol 
                    ORDER BY timestamp 
                    ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
                ) as avg_gain_14,
                AVG(loss) OVER (
                    PARTITION BY symbol 
                    ORDER BY timestamp 
                    ROWS BETWEEN 13 PRECEDING AND CURRENT ROW
                ) as avg_loss_14
            FROM gains_losses
        )
        SELECT 
            *,
            CASE 
                WHEN avg_loss_14 = 0 THEN 100
                WHEN avg_gain_14 = 0 THEN 0
                ELSE 100 - (100 / (1 + (avg_gain_14 / avg_loss_14)))
            END as rsi_14
        FROM rsi_calc
        ORDER BY timestamp
        """
        
        result = self.conn.execute(query).df()
        
        # éªŒè¯RSI
        assert len(result) > 0, "åº”è¯¥æœ‰RSIæ•°æ®"
        
        # RSIåº”è¯¥åœ¨0-100ä¹‹é—´
        rsi_values = result['rsi_14'].dropna()
        assert all(rsi_values >= 0), "RSIåº”è¯¥ >= 0"
        assert all(rsi_values <= 100), "RSIåº”è¯¥ <= 100"
        
        print(f"âœ… RSIè®¡ç®—æµ‹è¯•é€šè¿‡")
        print(f"   RSIèŒƒå›´: {rsi_values.min():.2f} - {rsi_values.max():.2f}")
        print(f"   æœ€æ–°RSI: {result.iloc[-1]['rsi_14']:.2f}")
    
    def test_bollinger_bands(self):
        """æµ‹è¯•å¸ƒæ—å¸¦è®¡ç®—"""
        query = """
        WITH bb_calc AS (
            SELECT 
                symbol,
                timestamp,
                close,
                AVG(close) OVER (
                    PARTITION BY symbol 
                    ORDER BY timestamp 
                    ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
                ) as ma_20,
                STDDEV(close) OVER (
                    PARTITION BY symbol 
                    ORDER BY timestamp 
                    ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
                ) as std_20
            FROM raw.ohlc_data
        )
        SELECT 
            *,
            ma_20 + (2 * std_20) as bb_upper,
            ma_20 - (2 * std_20) as bb_lower,
            CASE 
                WHEN ma_20 + (2 * std_20) - (ma_20 - (2 * std_20)) != 0 
                THEN (close - (ma_20 - (2 * std_20))) / ((ma_20 + (2 * std_20)) - (ma_20 - (2 * std_20)))
                ELSE 0.5
            END as bb_position
        FROM bb_calc
        ORDER BY timestamp
        """
        
        result = self.conn.execute(query).df()
        
        # éªŒè¯å¸ƒæ—å¸¦
        assert len(result) > 0, "åº”è¯¥æœ‰å¸ƒæ—å¸¦æ•°æ®"
        
        # æ£€æŸ¥å¸ƒæ—å¸¦çš„åˆç†æ€§
        valid_data = result.dropna()
        if len(valid_data) > 0:
            assert all(valid_data['bb_upper'] >= valid_data['ma_20']), "ä¸Šè½¨åº”è¯¥ >= ä¸­è½¨"
            assert all(valid_data['bb_lower'] <= valid_data['ma_20']), "ä¸‹è½¨åº”è¯¥ <= ä¸­è½¨"
            assert all(valid_data['bb_position'] >= 0), "BBä½ç½®åº”è¯¥ >= 0"
            assert all(valid_data['bb_position'] <= 1), "BBä½ç½®åº”è¯¥ <= 1"
        
        print(f"âœ… å¸ƒæ—å¸¦è®¡ç®—æµ‹è¯•é€šè¿‡")
        if len(valid_data) > 0:
            print(f"   æœ€æ–°ä¸Šè½¨: {valid_data.iloc[-1]['bb_upper']:.2f}")
            print(f"   æœ€æ–°ä¸­è½¨: {valid_data.iloc[-1]['ma_20']:.2f}")
            print(f"   æœ€æ–°ä¸‹è½¨: {valid_data.iloc[-1]['bb_lower']:.2f}")
    
    def test_volume_indicators(self):
        """æµ‹è¯•æˆäº¤é‡æŒ‡æ ‡"""
        query = """
        SELECT 
            symbol,
            timestamp,
            close,
            volume,
            -- æˆäº¤é‡ç§»åŠ¨å¹³å‡
            AVG(volume) OVER (
                PARTITION BY symbol 
                ORDER BY timestamp 
                ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
            ) as avg_volume_20d,
            -- æˆäº¤é‡æ¯”ç‡
            volume / NULLIF(AVG(volume) OVER (
                PARTITION BY symbol 
                ORDER BY timestamp 
                ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
            ), 0) as volume_ratio
        FROM raw.ohlc_data
        ORDER BY timestamp
        """
        
        result = self.conn.execute(query).df()
        
        # éªŒè¯æˆäº¤é‡æŒ‡æ ‡
        assert len(result) > 0, "åº”è¯¥æœ‰æˆäº¤é‡æŒ‡æ ‡æ•°æ®"
        
        valid_data = result.dropna()
        if len(valid_data) > 0:
            assert all(valid_data['avg_volume_20d'] > 0), "å¹³å‡æˆäº¤é‡åº”è¯¥ä¸ºæ­£"
            assert all(valid_data['volume_ratio'] > 0), "æˆäº¤é‡æ¯”ç‡åº”è¯¥ä¸ºæ­£"
        
        print(f"âœ… æˆäº¤é‡æŒ‡æ ‡æµ‹è¯•é€šè¿‡")
        if len(valid_data) > 0:
            print(f"   å¹³å‡æˆäº¤é‡æ¯”ç‡: {valid_data['volume_ratio'].mean():.2f}")
    
    def test_feature_completeness(self):
        """æµ‹è¯•ç‰¹å¾å®Œæ•´æ€§"""
        # æ‰§è¡Œå®Œæ•´çš„ç‰¹å¾å·¥ç¨‹æŸ¥è¯¢
        query = """
        WITH base_data AS (
            SELECT 
                symbol,
                timestamp,
                open, high, low, close, volume,
                (high + low + close) / 3 as typical_price,
                (high - low) as daily_range,
                CASE WHEN open != 0 THEN (close - open) / open ELSE 0 END as daily_return
            FROM raw.ohlc_data
        ),
        technical_indicators AS (
            SELECT 
                *,
                -- ç§»åŠ¨å¹³å‡
                AVG(close) OVER (PARTITION BY symbol ORDER BY timestamp ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) as ma_5,
                AVG(close) OVER (PARTITION BY symbol ORDER BY timestamp ROWS BETWEEN 9 PRECEDING AND CURRENT ROW) as ma_10,
                AVG(close) OVER (PARTITION BY symbol ORDER BY timestamp ROWS BETWEEN 19 PRECEDING AND CURRENT ROW) as ma_20,
                -- æ³¢åŠ¨ç‡
                STDDEV(daily_return) OVER (PARTITION BY symbol ORDER BY timestamp ROWS BETWEEN 19 PRECEDING AND CURRENT ROW) as volatility_20d,
                -- æˆäº¤é‡
                AVG(volume) OVER (PARTITION BY symbol ORDER BY timestamp ROWS BETWEEN 19 PRECEDING AND CURRENT ROW) as avg_volume_20d
            FROM base_data
        )
        SELECT 
            COUNT(*) as total_records,
            COUNT(CASE WHEN ma_5 IS NOT NULL THEN 1 END) as ma_5_count,
            COUNT(CASE WHEN ma_20 IS NOT NULL THEN 1 END) as ma_20_count,
            COUNT(CASE WHEN volatility_20d IS NOT NULL THEN 1 END) as volatility_count,
            AVG(CASE WHEN ma_5 IS NOT NULL THEN 1.0 ELSE 0.0 END) as ma_5_completeness,
            AVG(CASE WHEN volatility_20d IS NOT NULL THEN 1.0 ELSE 0.0 END) as volatility_completeness
        FROM technical_indicators
        """
        
        result = self.conn.execute(query).df()
        
        # éªŒè¯ç‰¹å¾å®Œæ•´æ€§
        assert len(result) == 1, "åº”è¯¥è¿”å›ä¸€è¡Œç»Ÿè®¡ç»“æœ"
        
        stats = result.iloc[0]
        assert stats['total_records'] > 0, "åº”è¯¥æœ‰æ€»è®°å½•æ•°"
        assert stats['ma_5_completeness'] > 0.8, "MA5å®Œæ•´æ€§åº”è¯¥ > 80%"
        
        print(f"âœ… ç‰¹å¾å®Œæ•´æ€§æµ‹è¯•é€šè¿‡")
        print(f"   æ€»è®°å½•æ•°: {stats['total_records']}")
        print(f"   MA5å®Œæ•´æ€§: {stats['ma_5_completeness']:.2%}")
        print(f"   æ³¢åŠ¨ç‡å®Œæ•´æ€§: {stats['volatility_completeness']:.2%}")


def run_offline_features_test():
    """è¿è¡Œç¦»çº¿ç‰¹å¾æµ‹è¯•"""
    print("ğŸ§ª å¼€å§‹ç¦»çº¿ç‰¹å¾è¡ç”Ÿæ¨¡å—æµ‹è¯•...")
    
    test_instance = TestOfflineFeatures()
    test_methods = [
        'test_data_cleaning',
        'test_basic_features', 
        'test_moving_averages',
        'test_rsi_calculation',
        'test_bollinger_bands',
        'test_volume_indicators',
        'test_feature_completeness'
    ]
    
    passed = 0
    failed = 0
    
    for method_name in test_methods:
        try:
            print(f"\nğŸ“Š è¿è¡Œæµ‹è¯•: {method_name}")
            test_instance.setup_method()
            method = getattr(test_instance, method_name)
            method()
            test_instance.teardown_method()
            passed += 1
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {method_name} - {str(e)}")
            failed += 1
            test_instance.teardown_method()
    
    print(f"\nğŸ“ˆ æµ‹è¯•ç»“æœ:")
    print(f"   âœ… é€šè¿‡: {passed}")
    print(f"   âŒ å¤±è´¥: {failed}")
    print(f"   ğŸ“Š é€šè¿‡ç‡: {passed/(passed+failed)*100:.1f}%")
    
    return failed == 0


if __name__ == "__main__":
    success = run_offline_features_test()
    exit(0 if success else 1)